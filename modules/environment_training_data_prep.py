#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¯å¢ƒæ£€æµ‹è®­ç»ƒæ•°æ®å‡†å¤‡è„šæœ¬
å°†æ ‡æ³¨æ•°æ®è½¬æ¢ä¸ºYOLOæ ¼å¼ï¼Œå‡†å¤‡è®­ç»ƒæ•°æ®
"""

import os
import json
import shutil
import cv2
import numpy as np
from pathlib import Path

class EnvironmentTrainingDataPrep:
    """ç¯å¢ƒæ£€æµ‹è®­ç»ƒæ•°æ®å‡†å¤‡ç±»"""
    
    def __init__(self):
        self.annotation_dir = "data/environment_annotations"
        self.image_dir = "data/environment_images"
        self.output_dir = "data/yolo_environment_dataset"
        self.classes_file = "data/yolo_environment_dataset/classes.txt"
        
        # ç¯å¢ƒç±»åˆ«å®šä¹‰
        self.environment_classes = {
            0: "æ™´å¤©", 1: "é›¨å¤©", 2: "é›ªå¤©", 3: "é›¾å¤©",
            4: "æ˜äº®", 5: "æ­£å¸¸", 6: "æ˜æš—", 7: "é»‘æš—",
            8: "å¹³æ•´", 9: "æ¹¿æ»‘", 10: "ç»“å†°", 11: "å‘æ´¼",
            12: "æ–½å·¥", 13: "ç›²é“", 14: "äººè¡Œé“", 15: "è·¯å£",
            16: "æ–½å·¥åŒº", 17: "åœè½¦åœº", 18: "æŠ¤æ ", 19: "è­¦ç¤ºç‰Œ",
            20: "çº¢ç»¿ç¯", 21: "æ–‘é©¬çº¿", 22: "æ— éšœç¢è®¾æ–½", 23: "å…¶ä»–"
        }
        
    def prepare_training_data(self):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        print("ğŸš€ å¼€å§‹å‡†å¤‡ç¯å¢ƒæ£€æµ‹è®­ç»ƒæ•°æ®...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.create_output_directories()
        
        # åˆ›å»ºç±»åˆ«æ–‡ä»¶
        self.create_classes_file()
        
        # è½¬æ¢æ ‡æ³¨æ•°æ®
        self.convert_annotations()
        
        # åˆ›å»ºæ•°æ®é›†é…ç½®æ–‡ä»¶
        self.create_dataset_config()
        
        print("âœ… è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"ğŸ“‹ ç±»åˆ«æ–‡ä»¶: {self.classes_file}")
        
    def create_output_directories(self):
        """åˆ›å»ºè¾“å‡ºç›®å½•"""
        directories = [
            self.output_dir,
            os.path.join(self.output_dir, "images"),
            os.path.join(self.output_dir, "labels"),
            os.path.join(self.output_dir, "train"),
            os.path.join(self.output_dir, "val"),
            os.path.join(self.output_dir, "test")
        ]
        
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
            print(f"ğŸ“ åˆ›å»ºç›®å½•: {directory}")
            
    def create_classes_file(self):
        """åˆ›å»ºç±»åˆ«æ–‡ä»¶"""
        with open(self.classes_file, 'w', encoding='utf-8') as f:
            for class_id, class_name in self.environment_classes.items():
                f.write(f"{class_name}\n")
        print(f"ğŸ“‹ åˆ›å»ºç±»åˆ«æ–‡ä»¶: {self.classes_file}")
        
    def convert_annotations(self):
        """è½¬æ¢æ ‡æ³¨æ•°æ®"""
        if not os.path.exists(self.annotation_dir):
            print(f"âŒ æ ‡æ³¨ç›®å½•ä¸å­˜åœ¨: {self.annotation_dir}")
            return
            
        annotation_files = [f for f in os.listdir(self.annotation_dir) if f.endswith('.json')]
        
        if not annotation_files:
            print(f"âŒ æœªæ‰¾åˆ°æ ‡æ³¨æ–‡ä»¶: {self.annotation_dir}")
            return
            
        print(f"ğŸ“Š æ‰¾åˆ° {len(annotation_files)} ä¸ªæ ‡æ³¨æ–‡ä»¶")
        
        for annotation_file in annotation_files:
            self.convert_single_annotation(annotation_file)
            
    def convert_single_annotation(self, annotation_file):
        """è½¬æ¢å•ä¸ªæ ‡æ³¨æ–‡ä»¶"""
        annotation_path = os.path.join(self.annotation_dir, annotation_file)
        
        try:
            with open(annotation_path, 'r', encoding='utf-8') as f:
                annotation_data = json.load(f)
                
            image_path = annotation_data.get('image_path', '')
            annotations = annotation_data.get('annotations', [])
            
            if not os.path.exists(image_path):
                print(f"âš ï¸ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                return
                
            # è·å–å›¾åƒå°ºå¯¸
            image = cv2.imread(image_path)
            if image is None:
                print(f"âš ï¸ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
                return
                
            height, width = image.shape[:2]
            
            # å¤åˆ¶å›¾åƒåˆ°è¾“å‡ºç›®å½•
            image_filename = os.path.basename(image_path)
            output_image_path = os.path.join(self.output_dir, "images", image_filename)
            shutil.copy2(image_path, output_image_path)
            
            # åˆ›å»ºYOLOæ ¼å¼çš„æ ‡æ³¨æ–‡ä»¶
            label_filename = os.path.splitext(image_filename)[0] + '.txt'
            label_path = os.path.join(self.output_dir, "labels", label_filename)
            
            with open(label_path, 'w', encoding='utf-8') as f:
                for annotation in annotations:
                    if 'bbox' in annotation and 'class_id' in annotation:
                        x1, y1, x2, y2 = annotation['bbox']
                        class_id = annotation['class_id']
                        
                        # è½¬æ¢ä¸ºYOLOæ ¼å¼ (å½’ä¸€åŒ–åæ ‡)
                        x_center = (x1 + x2) / 2 / width
                        y_center = (y1 + y2) / 2 / height
                        bbox_width = (x2 - x1) / width
                        bbox_height = (y2 - y1) / height
                        
                        # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
                        x_center = max(0, min(1, x_center))
                        y_center = max(0, min(1, y_center))
                        bbox_width = max(0, min(1, bbox_width))
                        bbox_height = max(0, min(1, bbox_height))
                        
                        f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\n")
                        
            print(f"âœ… è½¬æ¢å®Œæˆ: {image_filename}")
            
        except Exception as e:
            print(f"âŒ è½¬æ¢å¤±è´¥ {annotation_file}: {e}")
            
    def create_dataset_config(self):
        """åˆ›å»ºæ•°æ®é›†é…ç½®æ–‡ä»¶"""
        config = {
            "path": os.path.abspath(self.output_dir),
            "train": "images",
            "val": "images",
            "test": "images",
            "nc": len(self.environment_classes),
            "names": list(self.environment_classes.values())
        }
        
        config_path = os.path.join(self.output_dir, "dataset.yaml")
        with open(config_path, 'w', encoding='utf-8') as f:
            import yaml
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
            
        print(f"ğŸ“‹ åˆ›å»ºæ•°æ®é›†é…ç½®: {config_path}")
        
    def split_dataset(self, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):
        """åˆ†å‰²æ•°æ®é›†"""
        if not os.path.exists(os.path.join(self.output_dir, "images")):
            print("âŒ å›¾åƒç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®è½¬æ¢")
            return
            
        image_files = [f for f in os.listdir(os.path.join(self.output_dir, "images")) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
        
        if not image_files:
            print("âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return
            
        # éšæœºæ‰“ä¹±
        import random
        random.shuffle(image_files)
        
        # è®¡ç®—åˆ†å‰²ç‚¹
        total = len(image_files)
        train_end = int(total * train_ratio)
        val_end = int(total * (train_ratio + val_ratio))
        
        # åˆ†å‰²æ–‡ä»¶
        train_files = image_files[:train_end]
        val_files = image_files[train_end:val_end]
        test_files = image_files[val_end:]
        
        # å¤åˆ¶æ–‡ä»¶åˆ°å¯¹åº”ç›®å½•
        self.copy_files_to_split(train_files, "train")
        self.copy_files_to_split(val_files, "val")
        self.copy_files_to_split(test_files, "test")
        
        print(f"ğŸ“Š æ•°æ®é›†åˆ†å‰²å®Œæˆ:")
        print(f"   è®­ç»ƒé›†: {len(train_files)} å¼ å›¾åƒ")
        print(f"   éªŒè¯é›†: {len(val_files)} å¼ å›¾åƒ")
        print(f"   æµ‹è¯•é›†: {len(test_files)} å¼ å›¾åƒ")
        
    def copy_files_to_split(self, files, split_name):
        """å¤åˆ¶æ–‡ä»¶åˆ°åˆ†å‰²ç›®å½•"""
        split_dir = os.path.join(self.output_dir, split_name)
        os.makedirs(split_dir, exist_ok=True)
        
        for filename in files:
            # å¤åˆ¶å›¾åƒ
            src_image = os.path.join(self.output_dir, "images", filename)
            dst_image = os.path.join(split_dir, filename)
            shutil.copy2(src_image, dst_image)
            
            # å¤åˆ¶æ ‡æ³¨
            label_filename = os.path.splitext(filename)[0] + '.txt'
            src_label = os.path.join(self.output_dir, "labels", label_filename)
            dst_label = os.path.join(split_dir, label_filename)
            if os.path.exists(src_label):
                shutil.copy2(src_label, dst_label)
                
    def generate_statistics(self):
        """ç”Ÿæˆæ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        if not os.path.exists(os.path.join(self.output_dir, "labels")):
            print("âŒ æ ‡æ³¨ç›®å½•ä¸å­˜åœ¨")
            return
            
        label_files = [f for f in os.listdir(os.path.join(self.output_dir, "labels")) 
                      if f.endswith('.txt')]
        
        if not label_files:
            print("âŒ æœªæ‰¾åˆ°æ ‡æ³¨æ–‡ä»¶")
            return
            
        # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„æ•°é‡
        class_counts = {class_id: 0 for class_id in self.environment_classes.keys()}
        total_annotations = 0
        
        for label_file in label_files:
            label_path = os.path.join(self.output_dir, "labels", label_file)
            with open(label_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        class_id = int(line.strip().split()[0])
                        if class_id in class_counts:
                            class_counts[class_id] += 1
                            total_annotations += 1
                            
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        stats_path = os.path.join(self.output_dir, "dataset_statistics.txt")
        with open(stats_path, 'w', encoding='utf-8') as f:
            f.write("ç¯å¢ƒæ£€æµ‹æ•°æ®é›†ç»Ÿè®¡æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"æ€»å›¾åƒæ•°: {len(label_files)}\n")
            f.write(f"æ€»æ ‡æ³¨æ•°: {total_annotations}\n")
            f.write(f"å¹³å‡æ¯å¼ å›¾åƒæ ‡æ³¨æ•°: {total_annotations/len(label_files):.2f}\n\n")
            
            f.write("å„ç±»åˆ«æ ‡æ³¨æ•°é‡:\n")
            f.write("-" * 30 + "\n")
            for class_id, count in class_counts.items():
                class_name = self.environment_classes[class_id]
                percentage = count / total_annotations * 100 if total_annotations > 0 else 0
                f.write(f"{class_id:2d}. {class_name:10s}: {count:4d} ({percentage:5.1f}%)\n")
                
        print(f"ğŸ“Š ç»Ÿè®¡æŠ¥å‘Šå·²ç”Ÿæˆ: {stats_path}")

def main():
    """ä¸»å‡½æ•°"""
    prep = EnvironmentTrainingDataPrep()
    
    print("ğŸ¯ ç¯å¢ƒæ£€æµ‹è®­ç»ƒæ•°æ®å‡†å¤‡å·¥å…·")
    print("=" * 50)
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    prep.prepare_training_data()
    
    # åˆ†å‰²æ•°æ®é›†
    prep.split_dataset()
    
    # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
    prep.generate_statistics()
    
    print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")

if __name__ == "__main__":
    main()







