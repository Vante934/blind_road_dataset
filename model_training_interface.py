#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›²é“éšœç¢æ£€æµ‹æ¨¡å‹ç²¾åº¦è®­ç»ƒç•Œé¢
æ”¯æŒå¤šç§æ ‡æ³¨ç±»å‹ï¼šç›²é“ã€é™æ€éšœç¢ã€åŠ¨æ€éšœç¢ã€åœ°é¢å¼‚å¸¸
"""

import sys
import os
import cv2
import numpy as np
import json
import time
import torch
from datetime import datetime
from PyQt5.QtWidgets import *
from PyQt5.QtCore import *
from PyQt5.QtGui import *
import shutil
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.append(parent_dir)

# å¯¼å…¥è½¨è¿¹é¢„æµ‹åŠŸèƒ½
try:
    from trajectory_predictor import TrajectoryPredictor, TrajectoryVisualizer
    TRAJECTORY_AVAILABLE = True
except ImportError:
    TRAJECTORY_AVAILABLE = False

class AnnotationData:
    """æ ‡æ³¨æ•°æ®ç±»"""
    def __init__(self):
        self.image_path = ""
        self.image_size = (0, 0)  # (width, height)
        self.annotations = []  # å­˜å‚¨æ‰€æœ‰æ ‡æ³¨
        self.blind_path_points = []  # ç›²é“ä¸¤ç‚¹æ ‡æ³¨
        self.current_annotation = None  # å½“å‰æ­£åœ¨æ ‡æ³¨çš„å¯¹è±¡
        
    def add_annotation(self, annotation_type, bbox=None, points=None, class_name="", confidence=1.0):
        """æ·»åŠ æ ‡æ³¨"""
        annotation = {
            'id': len(self.annotations),
            'type': annotation_type,
            'class_name': class_name,
            'confidence': confidence,
            'timestamp': time.time(),
            'bbox': bbox,  # [x1, y1, x2, y2]
            'points': points,  # ç”¨äºç›²é“ä¸¤ç‚¹æ ‡æ³¨
            'color': self.get_annotation_color(annotation_type)
        }
        self.annotations.append(annotation)
        return annotation
    
    def get_annotation_color(self, annotation_type):
        """è·å–æ ‡æ³¨é¢œè‰²"""
        colors = {
            'blind_path': (0, 255, 255),      # é»„è‰² - ç›²é“
            'static_obstacle': (0, 255, 0),   # ç»¿è‰² - é™æ€éšœç¢
            'dynamic_obstacle': (255, 0, 0),  # çº¢è‰² - åŠ¨æ€éšœç¢
            'ground_anomaly': (0, 0, 255),    # è“è‰² - åœ°é¢å¼‚å¸¸
            'person': (255, 165, 0),          # æ©™è‰² - è¡Œäºº
            'pet': (128, 0, 128),             # ç´«è‰² - å® ç‰©
            'pothole': (255, 192, 203),       # ç²‰è‰² - å‘æ´¼
            'step': (0, 128, 128)             # é’è‰² - å°é˜¶
        }
        return colors.get(annotation_type, (255, 255, 255))

class ModelTrainingInterface(QMainWindow):
    """æ¨¡å‹è®­ç»ƒç•Œé¢ä¸»çª—å£"""
    
    def __init__(self):
        super().__init__()
        self.annotation_data = AnnotationData()
        self.current_image = None
        self.current_image_path = ""
        self.drawing = False
        self.start_point = None
        self.end_point = None
        self.annotation_mode = "static_obstacle"  # å½“å‰æ ‡æ³¨æ¨¡å¼
        self.image_list = []
        self.current_image_index = 0
        self.images_dir = "E:/Code/python/download/blind_road_dataset/data/images"
        
        # æ’¤é”€åŠŸèƒ½
        self.annotation_history = []  # å­˜å‚¨æ ‡æ³¨å†å²
        self.max_history_size = 20
        
        # è½¨è¿¹é¢„æµ‹ç³»ç»Ÿ
        if TRAJECTORY_AVAILABLE:
            self.trajectory_predictor = TrajectoryPredictor()
            self.trajectory_visualizer = TrajectoryVisualizer()
            print("âœ… è½¨è¿¹é¢„æµ‹ç³»ç»Ÿå·²é›†æˆåˆ°è®­ç»ƒç•Œé¢")
        
        # æ ‡æ³¨ç±»å‹å®šä¹‰
        self.annotation_types = {
            'blind_path': 'ç›²é“',
            'static_obstacle': 'é™æ€éšœç¢',
            'dynamic_obstacle': 'åŠ¨æ€éšœç¢',
            'person': 'è¡Œäºº',
            'pet': 'å® ç‰©',
            'pothole': 'å‘æ´¼',
            'step': 'å°é˜¶',
            'ground_anomaly': 'åœ°é¢å¼‚å¸¸'
        }
        
        self.init_ui()
        self.load_images()
        self.update_data_statistics()
        
        # è®¾ç½®å¿«æ·é”®
        self.setup_shortcuts()
        
        # åˆå§‹åŒ–æ ‡æ³¨æ¨¡å¼ï¼ˆåœ¨ç•Œé¢åˆ›å»ºåï¼‰
        self.set_annotation_mode('blind_path')
        
        # æ–°å¢ï¼šè®°å½•ç”¨æˆ·é€‰æ‹©çš„æ•°æ®é›†ä¸å­¦ä¹ åˆ°çš„è¶…å‚æ•°
        self.selected_datasets = {"blind_road": None, "environment": None}
        self.dataset_info = {"blind_road": {}, "environment": {}}
        self.learned_hyp = {}
        # è®­ç»ƒè¿‡ç¨‹å®æ—¶ç›‘æ§
        self.training_watch_timer = QTimer(self)
        self.training_watch_timer.timeout.connect(self._poll_training_metrics)
        self.current_run_dir = None
        self.current_total_epochs = 0
    
    def init_ui(self):
        """åˆå§‹åŒ–ç”¨æˆ·ç•Œé¢"""
        self.setWindowTitle("ç›²é“éšœç¢æ£€æµ‹æ¨¡å‹è®­ç»ƒç•Œé¢ - é›†æˆç¯å¢ƒæ£€æµ‹æ ‡æ³¨å·¥å…·")
        self.setGeometry(100, 100, 1800, 1200)  # å¢å¤§åˆå§‹çª—å£å¤§å°
        
        # è®¾ç½®çª—å£å¯è°ƒæ•´å¤§å°
        self.setMinimumSize(1400, 900)
        self.resize(1800, 1200)
        
        # åˆ›å»ºä¸­å¤®éƒ¨ä»¶
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        # ä¸»å¸ƒå±€
        main_layout = QVBoxLayout(central_widget)
        
        # åˆ›å»ºæ ‡ç­¾é¡µ
        self.tab_widget = QTabWidget()
        main_layout.addWidget(self.tab_widget)
        
        # ç›²é“éšœç¢æ£€æµ‹æ ‡æ³¨æ ‡ç­¾é¡µ
        self.blind_road_tab = self.create_blind_road_tab()
        self.tab_widget.addTab(self.blind_road_tab, "ç›²é“éšœç¢æ£€æµ‹æ ‡æ³¨")
        
        # ç¯å¢ƒæ£€æµ‹æ ‡æ³¨æ ‡ç­¾é¡µ
        self.environment_tab = self.create_environment_tab()
        self.tab_widget.addTab(self.environment_tab, "ç¯å¢ƒæ£€æµ‹æ ‡æ³¨å·¥å…·")
        
        # æ¨¡å‹è®­ç»ƒæ ‡ç­¾é¡µ
        self.training_tab = self.create_training_tab()
        self.tab_widget.addTab(self.training_tab, "æ¨¡å‹è®­ç»ƒ")
        
        # æ¨¡å‹æµ‹è¯•æ ‡ç­¾é¡µ
        self.model_test_tab = self.create_model_test_tab()
        self.tab_widget.addTab(self.model_test_tab, "æ¨¡å‹æµ‹è¯•")
    
    def create_blind_road_tab(self):
        """åˆ›å»ºç›²é“éšœç¢æ£€æµ‹æ ‡æ³¨æ ‡ç­¾é¡µ"""
        tab = QWidget()
        layout = QHBoxLayout(tab)
        
        # å·¦ä¾§æ§åˆ¶é¢æ¿
        left_panel = self.create_control_panel()
        layout.addWidget(left_panel, 1)
        
        # ä¸­é—´å›¾åƒæ˜¾ç¤ºåŒºåŸŸ
        image_panel = self.create_image_panel()
        layout.addWidget(image_panel, 3)
        
        # å³ä¾§æ ‡æ³¨ä¿¡æ¯é¢æ¿
        right_panel = self.create_annotation_panel()
        layout.addWidget(right_panel, 1)
        
        return tab
    
    def create_environment_tab(self):
        """åˆ›å»ºç¯å¢ƒæ£€æµ‹æ ‡æ³¨æ ‡ç­¾é¡µ"""
        tab = QWidget()
        layout = QHBoxLayout(tab)
        
        # å¯¼å…¥ç¯å¢ƒæ£€æµ‹æ ‡æ³¨å·¥å…·
        try:
            from modules.environment_annotation_tool import EnvironmentAnnotationTool
            self.env_annotation_tool = EnvironmentAnnotationTool()
            self.env_annotation_tool.setParent(tab)
            layout.addWidget(self.env_annotation_tool)
        except ImportError as e:
            error_widget = QWidget()
            error_layout = QVBoxLayout(error_widget)
            error_label = QLabel(f"ç¯å¢ƒæ£€æµ‹æ ‡æ³¨å·¥å…·åŠ è½½å¤±è´¥: {e}")
            error_label.setStyleSheet("color: red; font-size: 16px;")
            error_label.setAlignment(Qt.AlignCenter)
            error_layout.addWidget(error_label)
            layout.addWidget(error_widget)
        
        return tab
    
    def create_training_tab(self):
        """åˆ›å»ºæ¨¡å‹è®­ç»ƒæ ‡ç­¾é¡µ"""
        tab = QWidget()
        root_layout = QHBoxLayout(tab)

        # å·¦ä¾§ï¼šç«–å‘åŠŸèƒ½åŒºï¼ˆä¸å›¾1å·¦ä¾§ä¸€è‡´ï¼‰
        left_panel = QWidget()
        left_layout = QVBoxLayout(left_panel)
        left_panel.setMinimumWidth(280)

        # è®­ç»ƒæ¨¡å¼
        training_type_group = QGroupBox("è®­ç»ƒæ¨¡å¼")
        training_type_layout = QVBoxLayout(training_type_group)
        self.blind_road_train_btn = QPushButton("ç›²é“éšœç¢æ£€æµ‹æ¨¡å‹è®­ç»ƒ")
        self.blind_road_train_btn.setStyleSheet("QPushButton { padding: 15px; font-size: 14px; background-color: #3498db; color: white; border-radius: 8px; }")
        self.blind_road_train_btn.clicked.connect(self.start_blind_road_training)
        training_type_layout.addWidget(self.blind_road_train_btn)
        self.environment_train_btn = QPushButton("ç¯å¢ƒæ£€æµ‹æ¨¡å‹è®­ç»ƒ")
        self.environment_train_btn.setStyleSheet("QPushButton { padding: 15px; font-size: 14px; background-color: #e74c3c; color: white; border-radius: 8px; }")
        self.environment_train_btn.clicked.connect(self.start_environment_training)
        training_type_layout.addWidget(self.environment_train_btn)
        left_layout.addWidget(training_type_group)

        # åŠ è½½æ•°æ®é›†ï¼ˆä»…ä¸‰é¡¹ï¼‰
        data_prep_group = QGroupBox("åŠ è½½æ•°æ®é›†")
        data_prep_vlayout = QVBoxLayout(data_prep_group)
        row_ds = QHBoxLayout()
        self.load_blind_dataset_btn = QPushButton("ç›²é“æ•°æ®é›†")
        self.load_blind_dataset_btn.setStyleSheet("QPushButton { padding: 10px; font-size: 12px; background-color: #2ecc71; color: white; border-radius: 6px; }")
        self.load_blind_dataset_btn.clicked.connect(lambda: self.select_dataset_root("blind_road"))
        row_ds.addWidget(self.load_blind_dataset_btn)
        self.load_env_dataset_btn = QPushButton("ç¯å¢ƒæ•°æ®é›†")
        self.load_env_dataset_btn.setStyleSheet("QPushButton { padding: 10px; font-size: 12px; background-color: #16a085; color: white; border-radius: 6px; }")
        self.load_env_dataset_btn.clicked.connect(lambda: self.select_dataset_root("environment"))
        row_ds.addWidget(self.load_env_dataset_btn)
        self.load_processed_btn = QPushButton("å·²å¤„ç†æ•°æ®é›†")
        self.load_processed_btn.setStyleSheet("QPushButton { padding: 10px; font-size: 12px; background-color: #7f8c8d; color: white; border-radius: 6px; }")
        self.load_processed_btn.clicked.connect(lambda: self.select_dataset_root("processed"))
        row_ds.addWidget(self.load_processed_btn)
        data_prep_vlayout.addLayout(row_ds)
        left_layout.addWidget(data_prep_group)

        # æ•°æ®å¤„ç†
        pipeline_group = QGroupBox("æ•°æ®å¤„ç†")
        pipeline_layout = QVBoxLayout(pipeline_group)
        self.pipeline_btn = QPushButton("â–¶ è¿è¡Œæ•°æ®é¢„å¤„ç†æµç¨‹")
        self.pipeline_btn.setToolTip("æŒ‰å›¾2æµç¨‹ä¾æ¬¡æ‰§è¡Œå¹¶æ˜¾ç¤ºè¿›åº¦")
        self.pipeline_btn.clicked.connect(self.run_data_processing_pipeline)
        pipeline_layout.addWidget(self.pipeline_btn)
        left_layout.addWidget(pipeline_group)

        # æ•°æ®é›†é€‚é…åº¦è¯„ä¼°
        fit_group = QGroupBox("æ•°æ®é›†é€‚é…åº¦è¯„ä¼°")
        fit_layout = QVBoxLayout(fit_group)
        self.fitness_btn = QPushButton("ğŸ§¾ ç”Ÿæˆé€‚é…åº¦æŠ¥å‘Š")
        self.fitness_btn.clicked.connect(self.run_dataset_fitness_check)
        fit_layout.addWidget(self.fitness_btn)
        left_layout.addWidget(fit_group)

        # å…¶ä»–åŠŸèƒ½ï¼ˆå•ç‹¬åŒºåŸŸï¼‰
        other_group = QGroupBox("å…¶ä»–åŠŸèƒ½")
        other_layout = QVBoxLayout(other_group)
        row_other1 = QHBoxLayout()
        self.prepare_data_btn = QPushButton("å‡†å¤‡è®­ç»ƒæ•°æ®")
        self.prepare_data_btn.setStyleSheet("QPushButton { padding: 10px; font-size: 12px; background-color: #f39c12; color: white; border-radius: 6px; }")
        self.prepare_data_btn.clicked.connect(self.prepare_training_data)
        row_other1.addWidget(self.prepare_data_btn)
        self.export_data_btn = QPushButton("å¯¼å‡ºYOLOæ ¼å¼æ•°æ®")
        self.export_data_btn.setStyleSheet("QPushButton { padding: 10px; font-size: 12px; background-color: #9b59b6; color: white; border-radius: 6px; }")
        self.export_data_btn.clicked.connect(self.export_yolo_data)
        row_other1.addWidget(self.export_data_btn)
        other_layout.addLayout(row_other1)

        row_other2 = QHBoxLayout()
        self.validate_dataset_btn = QPushButton("æ•°æ®æ ¡éªŒ")
        self.validate_dataset_btn.setStyleSheet("QPushButton { padding: 10px; font-size: 12px; background-color: #34495e; color: white; border-radius: 6px; }")
        self.validate_dataset_btn.clicked.connect(self.validate_selected_datasets)
        row_other2.addWidget(self.validate_dataset_btn)
        self.learn_logic_btn = QPushButton("å­¦ä¹ æ ‡æ³¨é€»è¾‘")
        self.learn_logic_btn.setStyleSheet("QPushButton { padding: 10px; font-size: 12px; background-color: #8e44ad; color: white; border-radius: 6px; }")
        self.learn_logic_btn.clicked.connect(self.learn_annotation_logic)
        row_other2.addWidget(self.learn_logic_btn)
        self.mask2yolo_btn = QPushButton("æ©ç PNGâ†’YOLOæ ‡ç­¾")
        self.mask2yolo_btn.setToolTip("å°†annotationsä¸­çš„PNGæ©ç è½¬æ¢ä¸ºlabels/*.txt")
        self.mask2yolo_btn.setStyleSheet("QPushButton { padding: 10px; font-size: 12px; background-color: #2980b9; color: white; border-radius: 6px; }")
        self.mask2yolo_btn.clicked.connect(self.convert_mask_to_yolo)
        row_other2.addWidget(self.mask2yolo_btn)
        other_layout.addLayout(row_other2)
        left_layout.addWidget(other_group)

        left_layout.addStretch()

        # å³ä¾§ï¼šè¿›åº¦æ¡ + æŠ¥å‘Šé¢æ¿ï¼ˆä¸å›¾1å³ä¾§ä¸€è‡´ï¼‰
        right_panel = QWidget()
        right_layout = QVBoxLayout(right_panel)

        self.global_progress_label = QLabel("å¤„ç†/è®­ç»ƒè¿›åº¦æ¡")
        self.global_progress = QProgressBar()
        self.global_progress.setValue(0)
        right_layout.addWidget(self.global_progress_label)
        right_layout.addWidget(self.global_progress)

        # çŠ¶æ€ç®€è¦
        status_group = QGroupBox("è®­ç»ƒçŠ¶æ€")
        status_layout = QVBoxLayout(status_group)
        self.data_stats_label = QLabel("æ•°æ®ç»Ÿè®¡: åŠ è½½ä¸­...")
        self.data_stats_label.setStyleSheet("color: blue; font-weight: bold; font-size: 12px;")
        status_layout.addWidget(self.data_stats_label)
        self.training_status_label = QLabel("å‡†å¤‡å°±ç»ª")
        self.training_status_label.setStyleSheet("color: green; font-weight: bold; font-size: 14px;")
        status_layout.addWidget(self.training_status_label)
        self.training_progress = QProgressBar()
        status_layout.addWidget(self.training_progress)
        right_layout.addWidget(status_group)

        # æŠ¥å‘ŠåŒº
        report_group = QGroupBox("å¤„ç†/è®­ç»ƒ ç»“æœæŠ¥å‘Šã€è¿›åº¦æŠ¥å‘Š")
        report_layout = QVBoxLayout(report_group)
        self.training_log = QTextEdit()
        self.training_log.setReadOnly(True)
        self.training_log.setStyleSheet("QTextEdit { font-family: 'Consolas', 'Monaco', monospace; font-size: 12px; }")
        report_layout.addWidget(self.training_log)
        # ä¸­å¿ƒåŒºåŸŸå³ä¸‹æ–¹ï¼šæ­£åœ¨è¿›è¡Œçš„è¿›ç¨‹
        footer_row = QHBoxLayout()
        footer_row.addStretch(1)
        self.inline_status = QLabel("æ­£åœ¨è¿›è¡Œâ€¦")
        self.inline_status.setAlignment(Qt.AlignRight)
        self.inline_status.setStyleSheet("color:#2c3e50; font-size: 12px; padding: 4px 8px; border:1px solid #999; border-radius:4px;")
        footer_row.addWidget(self.inline_status)
        report_layout.addLayout(footer_row)
        right_layout.addWidget(report_group, 1)

        # ç»„è£…
        # å·¦1/3 å³2/3 æ¯”ä¾‹
        root_layout.addWidget(left_panel, 1)
        root_layout.addWidget(right_panel, 2)

        return tab
    
    def create_control_panel(self):
        """åˆ›å»ºæ§åˆ¶é¢æ¿"""
        panel = QWidget()
        panel.setFixedWidth(300)  # å›ºå®šå®½åº¦
        layout = QVBoxLayout(panel)
        layout.setSpacing(10)
        
        # 1. è®­ç»ƒæ§åˆ¶é¢æ¿
        training_control_group = QGroupBox("è®­ç»ƒæ§åˆ¶é¢æ¿")
        training_control_group.setStyleSheet("QGroupBox { font-weight: bold; font-size: 14px; }")
        training_layout = QVBoxLayout(training_control_group)
        training_layout.setSpacing(8)
        
        # å½“å‰å›¾åƒä¿¡æ¯
        current_image_layout = QHBoxLayout()
        current_image_layout.addWidget(QLabel("å½“å‰å›¾åƒ:"))
        self.current_image_label = QLabel("æ— ")
        self.current_image_label.setStyleSheet("color: #666;")
        current_image_layout.addWidget(self.current_image_label)
        training_layout.addLayout(current_image_layout)
        
        # å›¾åƒé€‰æ‹©ä¸‹æ‹‰æ¡†
        self.image_combo = QComboBox()
        self.image_combo.setStyleSheet("QComboBox { padding: 5px; border: 1px solid #ddd; border-radius: 3px; }")
        self.image_combo.currentTextChanged.connect(self.on_image_changed)
        training_layout.addWidget(QLabel("é€‰æ‹©å›¾åƒ:"))
        training_layout.addWidget(self.image_combo)
        
        # å›¾åƒå¯¼èˆª
        nav_layout = QHBoxLayout()
        self.prev_btn = QPushButton("â—€ ä¸Šä¸€å¼ ")
        self.prev_btn.setStyleSheet("QPushButton { padding: 8px; font-size: 12px; }")
        self.prev_btn.clicked.connect(self.prev_image)
        self.next_btn = QPushButton("ä¸‹ä¸€å¼  â–¶")
        self.next_btn.setStyleSheet("QPushButton { padding: 8px; font-size: 12px; }")
        self.next_btn.clicked.connect(self.next_image)
        nav_layout.addWidget(self.prev_btn)
        nav_layout.addWidget(self.next_btn)
        training_layout.addLayout(nav_layout)
        
        # ä¸€é”®åŒæ­¥
        self.sync_btn = QPushButton("ğŸ”„ ä¸€é”®åŒæ­¥å›¾ç‰‡")
        self.sync_btn.setStyleSheet("QPushButton { padding: 10px; font-size: 13px; background-color: #3498db; color: white; border-radius: 5px; }")
        self.sync_btn.clicked.connect(self.sync_images)
        training_layout.addWidget(self.sync_btn)
        
        layout.addWidget(training_control_group)
        
        # 2. æ ‡æ³¨æ¨¡å¼é€‰æ‹©
        mode_group = QGroupBox("æ ‡æ³¨æ¨¡å¼")
        mode_group.setStyleSheet("QGroupBox { font-weight: bold; font-size: 14px; }")
        mode_layout = QVBoxLayout(mode_group)
        mode_layout.setSpacing(6)
        
        # åˆ›å»ºæŒ‰é’®ç»„ç¡®ä¿äº’æ–¥é€‰æ‹©
        self.annotation_button_group = QButtonGroup()
        
        # ç›²é“æ ‡æ³¨ï¼ˆæŒ‰ç”¨æˆ·è¦æ±‚ç§»é™¤çº¢æ¡†è¯´æ˜ï¼Œä»…ä¿ç•™ç®€æ´å•é€‰é¡¹ï¼‰
        self.blind_path_btn = QRadioButton("ç›²é“")
        self.blind_path_btn.setChecked(True)
        self.annotation_button_group.addButton(self.blind_path_btn, 0)  # ID = 0
        self.blind_path_btn.toggled.connect(lambda checked: self.set_annotation_mode('blind_path') if checked else None)
        mode_layout.addWidget(self.blind_path_btn)
        
        # éšœç¢ç‰©æ ‡æ³¨
        # éšœç¢ç‰©æ ‡æ³¨ï¼ˆå»é™¤å¤–æ¡†ï¼Œä»…ä¿ç•™é€‰é¡¹ï¼‰
        obstacle_container = QWidget()
        obstacle_layout = QVBoxLayout(obstacle_container)
        
        # é™æ€éšœç¢
        self.static_obstacle_btn = QRadioButton("é™æ€éšœç¢")
        self.annotation_button_group.addButton(self.static_obstacle_btn, 1)  # ID = 1
        self.static_obstacle_btn.toggled.connect(lambda checked: self.set_annotation_mode('static_obstacle') if checked else None)
        obstacle_layout.addWidget(self.static_obstacle_btn)
        
        # åŠ¨æ€éšœç¢
        self.dynamic_obstacle_btn = QRadioButton("åŠ¨æ€éšœç¢")
        self.annotation_button_group.addButton(self.dynamic_obstacle_btn, 2)  # ID = 2
        self.dynamic_obstacle_btn.toggled.connect(lambda checked: self.set_annotation_mode('dynamic_obstacle') if checked else None)
        obstacle_layout.addWidget(self.dynamic_obstacle_btn)
        
        # åœ°é¢å¼‚å¸¸
        self.ground_anomaly_btn = QRadioButton("åœ°é¢å¼‚å¸¸")
        self.annotation_button_group.addButton(self.ground_anomaly_btn, 3)  # ID = 3
        self.ground_anomaly_btn.toggled.connect(lambda checked: self.set_annotation_mode('ground_anomaly') if checked else None)
        obstacle_layout.addWidget(self.ground_anomaly_btn)
        
        # éšœç¢ç‰©æ¨¡å¼è¯´æ˜
        obstacle_info = QLabel("â€¢ æ‹–æ‹½ç»˜åˆ¶è¾¹ç•Œæ¡†\nâ€¢ æ”¯æŒè°ƒæ•´å¤§å°")
        obstacle_info.setStyleSheet("color: #666; font-size: 12px; margin-left: 15px;")
        obstacle_layout.addWidget(obstacle_info)
        mode_layout.addWidget(obstacle_container)
        
        layout.addWidget(mode_group)
        
        # 3. è®­ç»ƒæ§åˆ¶
        training_group = QGroupBox("è®­ç»ƒæ§åˆ¶")
        training_group.setStyleSheet("QGroupBox { font-weight: bold; font-size: 14px; }")
        training_control_layout = QVBoxLayout(training_group)
        training_control_layout.setSpacing(8)
        
        # è‡ªåŠ¨è®­ç»ƒ
        self.auto_train_btn = QPushButton("ğŸ¤– è‡ªåŠ¨è®­ç»ƒ")
        self.auto_train_btn.setStyleSheet("QPushButton { padding: 10px; font-size: 13px; background-color: #27ae60; color: white; border-radius: 5px; }")
        self.auto_train_btn.clicked.connect(self.start_auto_training)
        training_control_layout.addWidget(self.auto_train_btn)
        
        # æ‰‹åŠ¨è®­ç»ƒ
        self.manual_train_btn = QPushButton("âœ‹ æ‰‹åŠ¨è®­ç»ƒ")
        self.manual_train_btn.setStyleSheet("QPushButton { padding: 10px; font-size: 13px; background-color: #f39c12; color: white; border-radius: 5px; }")
        self.manual_train_btn.clicked.connect(self.start_manual_training)
        training_control_layout.addWidget(self.manual_train_btn)
        
        # ä¿å­˜/åŠ è½½æ ‡æ³¨
        save_load_layout = QHBoxLayout()
        self.save_annotations_btn = QPushButton("ğŸ’¾ ä¿å­˜")
        self.save_annotations_btn.setStyleSheet("QPushButton { padding: 8px; font-size: 12px; background-color: #3498db; color: white; border-radius: 3px; }")
        self.save_annotations_btn.clicked.connect(self.save_annotations)
        self.load_annotations_btn = QPushButton("ğŸ“‚ åŠ è½½")
        self.load_annotations_btn.setStyleSheet("QPushButton { padding: 8px; font-size: 12px; background-color: #9b59b6; color: white; border-radius: 3px; }")
        self.load_annotations_btn.clicked.connect(self.load_annotations)
        save_load_layout.addWidget(self.save_annotations_btn)
        save_load_layout.addWidget(self.load_annotations_btn)
        training_control_layout.addLayout(save_load_layout)
        
        layout.addWidget(training_group)
        
        # 4. æ•°æ®å¤„ç†æµç¨‹ï¼ˆå›¾2ï¼‰
        pipeline_group = QGroupBox("æ•°æ®å¤„ç†")
        pipeline_group.setStyleSheet("QGroupBox { font-weight: bold; font-size: 14px; }")
        pipeline_layout = QVBoxLayout(pipeline_group)
        self.pipeline_btn = QPushButton("â–¶ è¿è¡Œæ•°æ®é¢„å¤„ç†æµç¨‹")
        self.pipeline_btn.setToolTip("æŒ‰å›¾2æµç¨‹ä¾æ¬¡æ‰§è¡Œå¹¶æ˜¾ç¤ºè¿›åº¦")
        self.pipeline_btn.clicked.connect(self.run_data_processing_pipeline)
        pipeline_layout.addWidget(self.pipeline_btn)
        layout.addWidget(pipeline_group)

        # 5. æ•°æ®é›†é€‚é…åº¦è¯„ä¼°ï¼ˆå›¾3ï¼‰
        fit_group = QGroupBox("æ•°æ®é›†é€‚é…åº¦è¯„ä¼°")
        fit_group.setStyleSheet("QGroupBox { font-weight: bold; font-size: 14px; }")
        fit_layout = QVBoxLayout(fit_group)
        self.fitness_btn = QPushButton("ğŸ§¾ ç”Ÿæˆé€‚é…åº¦æŠ¥å‘Š")
        self.fitness_btn.clicked.connect(self.run_dataset_fitness_check)
        fit_layout.addWidget(self.fitness_btn)
        layout.addWidget(fit_group)

        # 6. çŠ¶æ€æ˜¾ç¤º
        status_group = QGroupBox("çŠ¶æ€ä¿¡æ¯")
        status_group.setStyleSheet("QGroupBox { font-weight: bold; font-size: 14px; }")
        status_layout = QVBoxLayout(status_group)
        status_layout.setSpacing(8)
        
        self.status_label = QLabel("å‡†å¤‡å°±ç»ª")
        self.status_label.setStyleSheet("color: green; font-weight: bold; font-size: 12px;")
        status_layout.addWidget(self.status_label)
        
        self.progress_bar = QProgressBar()
        self.progress_bar.setStyleSheet("QProgressBar { height: 20px; border-radius: 10px; }")
        status_layout.addWidget(self.progress_bar)
        
        layout.addWidget(status_group)
        
        layout.addStretch()
        return panel
    
    def create_image_panel(self):
        """åˆ›å»ºå›¾åƒæ˜¾ç¤ºé¢æ¿"""
        panel = QWidget()
        layout = QVBoxLayout(panel)
        
        # å›¾åƒæ˜¾ç¤ºæ ‡ç­¾
        self.image_label = QLabel()
        self.image_label.setMinimumSize(800, 600)  # è®¾ç½®æœ€å°å°ºå¯¸
        self.image_label.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)  # å…è®¸ç¼©æ”¾
        self.image_label.setStyleSheet("border: 2px solid #34495e; background-color: #ecf0f1; font-size: 14px;")  # å¢å¤§å­—ä½“
        self.image_label.setAlignment(Qt.AlignCenter)
        self.image_label.setText("è¯·é€‰æ‹©å›¾åƒå¼€å§‹æ ‡æ³¨")
        self.image_label.setMouseTracking(True)
        self.image_label.mousePressEvent = self.on_mouse_press
        self.image_label.mouseMoveEvent = self.on_mouse_move
        self.image_label.mouseReleaseEvent = self.on_mouse_release
        layout.addWidget(self.image_label)
        
        # å›¾åƒä¿¡æ¯
        self.image_info_label = QLabel("")
        self.image_info_label.setStyleSheet("color: #7f8c8d; font-size: 14px;")  # å¢å¤§å­—ä½“
        layout.addWidget(self.image_info_label)
        
        return panel
    
    def create_annotation_panel(self):
        """åˆ›å»ºæ ‡æ³¨ä¿¡æ¯é¢æ¿"""
        panel = QWidget()
        panel.setFixedWidth(300)  # å›ºå®šå®½åº¦
        layout = QVBoxLayout(panel)
        layout.setSpacing(10)
        
        # 1. å½“å‰æ¨¡å¼
        current_mode_group = QGroupBox("å½“å‰æ¨¡å¼")
        current_mode_group.setStyleSheet("QGroupBox { font-weight: bold; font-size: 14px; }")
        current_mode_layout = QVBoxLayout(current_mode_group)
        current_mode_layout.setSpacing(8)
        
        self.current_mode_label = QLabel("ç›²é“æ ‡æ³¨")
        self.current_mode_label.setStyleSheet("font-size: 16px; font-weight: bold; color: #e74c3c;")
        current_mode_layout.addWidget(self.current_mode_label)
        
        # æ“ä½œè¯´æ˜
        self.instruction_label = QLabel("â€¢ ç›²é“ï¼šç‚¹å‡»ä¸¤ä¸ªç‚¹æˆ–æ‹–æ‹½\nâ€¢ éšœç¢ç‰©ï¼šæ‹–æ‹½ç»˜åˆ¶è¾¹ç•Œæ¡†\nâ€¢ å³é”®ï¼šåˆ é™¤æœ€è¿‘æ ‡æ³¨\nâ€¢ Ctrl+Zï¼šæ’¤é”€ä¸Šä¸€æ­¥")
        self.instruction_label.setStyleSheet("color: #666; font-size: 13px; line-height: 1.4;")
        current_mode_layout.addWidget(self.instruction_label)
        
        layout.addWidget(current_mode_group)
        
        # 2. æ ‡æ³¨åˆ—è¡¨
        annotations_group = QGroupBox("æ ‡æ³¨åˆ—è¡¨")
        annotations_group.setStyleSheet("QGroupBox { font-weight: bold; font-size: 14px; }")
        annotations_layout = QVBoxLayout(annotations_group)
        annotations_layout.setSpacing(8)
        
        # æ ‡æ³¨ç»Ÿè®¡
        self.stats_label = QLabel("æ ‡æ³¨æ•°é‡: 0")
        self.stats_label.setStyleSheet("color: #666; font-size: 14px; font-weight: bold;")
        annotations_layout.addWidget(self.stats_label)
        
        # æ ‡æ³¨åˆ—è¡¨
        self.annotations_list = QListWidget()
        self.annotations_list.setStyleSheet("QListWidget { border: 1px solid #ddd; border-radius: 5px; }")
        self.annotations_list.itemClicked.connect(self.on_annotation_selected)
        annotations_layout.addWidget(self.annotations_list)
        
        # æ ‡æ³¨æ“ä½œæŒ‰é’®
        annotation_ops_layout = QHBoxLayout()
        self.delete_annotation_btn = QPushButton("ğŸ—‘ï¸ åˆ é™¤")
        self.delete_annotation_btn.setStyleSheet("QPushButton { padding: 8px; font-size: 13px; background-color: #e74c3c; color: white; border-radius: 3px; }")
        self.delete_annotation_btn.clicked.connect(self.delete_selected_annotation)
        self.clear_all_btn = QPushButton("ğŸ§¹ æ¸…ç©º")
        self.clear_all_btn.setStyleSheet("QPushButton { padding: 8px; font-size: 13px; background-color: #95a5a6; color: white; border-radius: 3px; }")
        self.clear_all_btn.clicked.connect(self.clear_all_annotations)
        annotation_ops_layout.addWidget(self.delete_annotation_btn)
        annotation_ops_layout.addWidget(self.clear_all_btn)
        annotations_layout.addLayout(annotation_ops_layout)
        
        layout.addWidget(annotations_group)
        
        # 3. å¿«æ·é”®æç¤º
        shortcuts_group = QGroupBox("å¿«æ·é”®")
        shortcuts_group.setStyleSheet("QGroupBox { font-weight: bold; font-size: 14px; }")
        shortcuts_layout = QVBoxLayout(shortcuts_group)
        shortcuts_layout.setSpacing(6)
        
        shortcuts_info = QLabel("â€¢ Ctrl+Zï¼šæ’¤é”€ä¸Šä¸€æ­¥\nâ€¢ å³é”®ï¼šåˆ é™¤æœ€è¿‘æ ‡æ³¨\nâ€¢ æ»šè½®ï¼šç¼©æ”¾å›¾åƒ\nâ€¢ ç©ºæ ¼ï¼šä¸‹ä¸€å¼ å›¾åƒ")
        shortcuts_info.setStyleSheet("color: #666; font-size: 12px; line-height: 1.4;")
        shortcuts_layout.addWidget(shortcuts_info)
        
        layout.addWidget(shortcuts_group)
        
        # 4. å›¾åƒä¿¡æ¯
        image_info_group = QGroupBox("å›¾åƒä¿¡æ¯")
        image_info_group.setStyleSheet("QGroupBox { font-weight: bold; font-size: 14px; }")
        image_info_layout = QVBoxLayout(image_info_group)
        image_info_layout.setSpacing(6)
        
        self.image_info_label = QLabel("æ— å›¾åƒ")
        self.image_info_label.setStyleSheet("color: #666; font-size: 13px;")
        image_info_layout.addWidget(self.image_info_label)
        
        layout.addWidget(image_info_group)
        
        layout.addStretch()
        return panel
    
    def load_images(self):
        """åŠ è½½å›¾åƒåˆ—è¡¨"""
        try:
            if not os.path.exists(self.images_dir):
                self.status_label.setText("å›¾åƒç›®å½•ä¸å­˜åœ¨")
                return
            
            image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
            self.image_list = []
            
            for file in os.listdir(self.images_dir):
                if any(file.lower().endswith(ext) for ext in image_extensions):
                    self.image_list.append(file)
            
            # æ›´æ–°å›¾åƒé€‰æ‹©ä¸‹æ‹‰æ¡†
            if hasattr(self, 'image_combo'):
                self.image_combo.clear()
                self.image_combo.addItems(self.image_list)
            
            # æ›´æ–°å½“å‰å›¾åƒæ ‡ç­¾
            if hasattr(self, 'current_image_label'):
                if self.image_list:
                    self.current_image_label.setText(f"{len(self.image_list)} å¼ å›¾åƒ")
                else:
                    self.current_image_label.setText("æ— å›¾åƒ")
            
            if self.image_list:
                self.load_image(0)
                self.status_label.setText(f"åŠ è½½äº† {len(self.image_list)} å¼ å›¾åƒ")
            else:
                self.status_label.setText("æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
                
        except Exception as e:
            self.status_label.setText(f"åŠ è½½å›¾åƒå¤±è´¥: {e}")
    
    def sync_images(self):
        """ä¸€é”®åŒæ­¥å›¾ç‰‡"""
        self.status_label.setText("æ­£åœ¨åŒæ­¥å›¾ç‰‡...")
        self.progress_bar.setValue(0)
        
        # é‡æ–°åŠ è½½å›¾åƒ
        self.load_images()
        
        # æ›´æ–°è¿›åº¦æ¡
        self.progress_bar.setValue(100)
        self.status_label.setText(f"åŒæ­¥å®Œæˆï¼Œå…± {len(self.image_list)} å¼ å›¾åƒ")
    
    def load_image(self, index):
        """åŠ è½½æŒ‡å®šç´¢å¼•çš„å›¾åƒ"""
        if 0 <= index < len(self.image_list):
            self.current_image_index = index
            image_file = self.image_list[index]
            self.current_image_path = os.path.join(self.images_dir, image_file)
            
            # åŠ è½½å›¾åƒ
            self.current_image = cv2.imread(self.current_image_path)
            if self.current_image is not None:
                self.display_image()
                self.load_image_annotations()
                self.update_image_info()
            else:
                self.status_label.setText(f"æ— æ³•åŠ è½½å›¾åƒ: {image_file}")
    
    def display_image(self):
        """æ˜¾ç¤ºå½“å‰å›¾åƒ"""
        if self.current_image is None:
            return
        
        # åˆ›å»ºå¸¦æ ‡æ³¨çš„å›¾åƒå‰¯æœ¬
        display_image = self.current_image.copy()
        
        # ç»˜åˆ¶æ‰€æœ‰æ ‡æ³¨
        for annotation in self.annotation_data.annotations:
            self.draw_annotation(display_image, annotation)
        
        # ç»˜åˆ¶å½“å‰æ­£åœ¨ç»˜åˆ¶çš„æ ‡æ³¨
        if self.drawing and self.start_point and self.end_point:
            self.draw_current_annotation(display_image)
        
        # è½¬æ¢ä¸ºQtæ ¼å¼
        height, width, channel = display_image.shape
        bytes_per_line = 3 * width
        q_image = QImage(display_image.data, width, height, bytes_per_line, QImage.Format_RGB888).rgbSwapped()
        
        # ç¼©æ”¾ä»¥é€‚åº”æ˜¾ç¤ºåŒºåŸŸ
        pixmap = QPixmap.fromImage(q_image)
        scaled_pixmap = pixmap.scaled(self.image_label.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation)
        self.image_label.setPixmap(scaled_pixmap)
    
    def draw_annotation(self, image, annotation):
        """ç»˜åˆ¶å•ä¸ªæ ‡æ³¨"""
        color = annotation['color']
        annotation_type = annotation['type']
        
        if annotation_type == 'blind_path' and annotation.get('points'):
            # ç»˜åˆ¶ç›²é“ä¸¤ç‚¹æ ‡æ³¨
            points = annotation['points']
            if len(points) >= 2:
                cv2.line(image, tuple(points[0]), tuple(points[1]), color, 3)
                cv2.circle(image, tuple(points[0]), 5, color, -1)
                cv2.circle(image, tuple(points[1]), 5, color, -1)
        elif annotation.get('bbox'):
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            bbox = annotation['bbox']
            x1, y1, x2, y2 = map(int, bbox)
            cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{annotation['class_name']} ({annotation['confidence']:.2f})"
            cv2.putText(image, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
    
    def draw_current_annotation(self, image):
        """ç»˜åˆ¶å½“å‰æ­£åœ¨ç»˜åˆ¶çš„æ ‡æ³¨"""
        if self.annotation_mode == 'blind_path':
            # ç›²é“ä¸¤ç‚¹æ ‡æ³¨
            if len(self.annotation_data.blind_path_points) > 0:
                # ç»˜åˆ¶å·²ç¡®å®šçš„ç‚¹
                for i, point in enumerate(self.annotation_data.blind_path_points):
                    cv2.circle(image, point, 8, (0, 255, 255), -1)
                    cv2.putText(image, str(i+1), (point[0]-5, point[1]+5), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
                
                # å¦‚æœæ­£åœ¨ç»˜åˆ¶ï¼Œæ˜¾ç¤ºé¢„è§ˆçº¿
                if self.drawing and self.end_point and len(self.annotation_data.blind_path_points) == 1:
                    cv2.line(image, self.annotation_data.blind_path_points[0], self.end_point, (0, 255, 255), 3)
                    cv2.circle(image, self.end_point, 6, (0, 255, 255), 2)
        else:
            # è¾¹ç•Œæ¡†æ ‡æ³¨
            if self.start_point and self.end_point:
                color = self.annotation_data.get_annotation_color(self.annotation_mode)
                cv2.rectangle(image, self.start_point, self.end_point, color, 2)
    
    def on_mouse_press(self, event):
        """é¼ æ ‡æŒ‰ä¸‹äº‹ä»¶"""
        if self.current_image is None:
            return
        
        # è·å–ç›¸å¯¹äºå›¾åƒçš„ä½ç½®
        pos = self.get_image_position(event.pos())
        if pos is None:
            return
        
        if event.button() == Qt.LeftButton:
            if self.annotation_mode == 'blind_path':
                # ç›²é“æ ‡æ³¨ï¼šæ”¯æŒä¸¤ç‚¹æ¨¡å¼å’Œæ‹–æ‹½æ¨¡å¼
                if len(self.annotation_data.blind_path_points) == 0:
                    # å¼€å§‹æ–°çš„ç›²é“æ ‡æ³¨
                    self.annotation_data.blind_path_points.append(pos)
                    self.drawing = True
                    self.start_point = pos
                    print(f"ğŸ“ ç›²é“æ ‡æ³¨å¼€å§‹: {pos}")
                elif len(self.annotation_data.blind_path_points) == 1:
                    # å®Œæˆä¸¤ç‚¹æ ‡æ³¨
                    self.annotation_data.blind_path_points.append(pos)
                    self.complete_blind_path_annotation()
                    self.drawing = False
            else:
                # è¾¹ç•Œæ¡†æ ‡æ³¨
                self.drawing = True
                self.start_point = pos
                self.end_point = pos
        elif event.button() == Qt.RightButton:
            # å³é”®åˆ é™¤æœ€è¿‘çš„æ ‡æ³¨
            self.delete_nearest_annotation(pos)
    
    def on_mouse_move(self, event):
        """é¼ æ ‡ç§»åŠ¨äº‹ä»¶"""
        if not self.drawing:
            return
        
        pos = self.get_image_position(event.pos())
        if pos is not None:
            self.end_point = pos
            self.display_image()
            
            # ç›²é“æ ‡æ³¨çš„å®æ—¶é¢„è§ˆ
            if self.annotation_mode == 'blind_path' and len(self.annotation_data.blind_path_points) == 1:
                # æ˜¾ç¤ºä»ç¬¬ä¸€ä¸ªç‚¹åˆ°å½“å‰é¼ æ ‡ä½ç½®çš„é¢„è§ˆçº¿
                pass
    
    def on_mouse_release(self, event):
        """é¼ æ ‡é‡Šæ”¾äº‹ä»¶"""
        if not self.drawing:
            return
        
        pos = self.get_image_position(event.pos())
        if pos is not None:
            self.end_point = pos
            
            if self.annotation_mode == 'blind_path':
                # ç›²é“æ ‡æ³¨ï¼šå¦‚æœåªæœ‰ä¸€ä¸ªç‚¹ï¼Œæ·»åŠ ç¬¬äºŒä¸ªç‚¹
                if len(self.annotation_data.blind_path_points) == 1:
                    self.annotation_data.blind_path_points.append(pos)
                    self.complete_blind_path_annotation()
                    self.drawing = False
            else:
                # è¾¹ç•Œæ¡†æ ‡æ³¨
                self.complete_bbox_annotation()
    
    def get_image_position(self, qt_pos):
        """å°†Qtåæ ‡è½¬æ¢ä¸ºå›¾åƒåæ ‡"""
        if self.current_image is None:
            return None
        
        # è·å–å›¾åƒåœ¨æ ‡ç­¾ä¸­çš„å®é™…æ˜¾ç¤ºåŒºåŸŸ
        label_size = self.image_label.size()
        image_size = self.current_image.shape[:2][::-1]  # (width, height)
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        scale_x = label_size.width() / image_size[0]
        scale_y = label_size.height() / image_size[1]
        scale = min(scale_x, scale_y)
        
        # è®¡ç®—å›¾åƒåœ¨æ ‡ç­¾ä¸­çš„åç§»
        offset_x = (label_size.width() - image_size[0] * scale) / 2
        offset_y = (label_size.height() - image_size[1] * scale) / 2
        
        # è½¬æ¢åæ ‡
        x = int((qt_pos.x() - offset_x) / scale)
        y = int((qt_pos.y() - offset_y) / scale)
        
        # å¢åŠ å®¹é”™èŒƒå›´ï¼Œæé«˜çµæ•åº¦
        tolerance = 10
        x = max(0, min(image_size[0]-1, x))
        y = max(0, min(image_size[1]-1, y))
        
        return (x, y)
    
    def complete_bbox_annotation(self):
        """å®Œæˆè¾¹ç•Œæ¡†æ ‡æ³¨"""
        if not self.start_point or not self.end_point:
            return
        
        # ç¡®ä¿åæ ‡æ­£ç¡®
        x1, y1 = self.start_point
        x2, y2 = self.end_point
        x1, x2 = min(x1, x2), max(x1, x2)
        y1, y2 = min(y1, y2), max(y1, y2)
        
        # æ£€æŸ¥æ ‡æ³¨å¤§å°
        if x2 - x1 < 10 or y2 - y1 < 10:
            self.status_label.setText("æ ‡æ³¨åŒºåŸŸå¤ªå°")
            self.reset_drawing_state()
            return
        
        # æ·»åŠ æ ‡æ³¨
        bbox = [x1, y1, x2, y2]
        class_name = self.annotation_types.get(self.annotation_mode, self.annotation_mode)
        annotation = self.annotation_data.add_annotation(
            self.annotation_mode, 
            bbox=bbox, 
            class_name=class_name
        )
        
        # æ›´æ–°ç•Œé¢
        self.update_annotations_list()
        self.update_stats()
        self.display_image()
        self.reset_drawing_state()
        
        self.status_label.setText(f"å·²æ·»åŠ  {class_name} æ ‡æ³¨")
    
    def complete_blind_path_annotation(self):
        """å®Œæˆç›²é“æ ‡æ³¨"""
        if len(self.annotation_data.blind_path_points) == 2:
            points = self.annotation_data.blind_path_points.copy()
            annotation = self.annotation_data.add_annotation(
                'blind_path',
                points=points,
                class_name='ç›²é“'
            )
            
            # æ›´æ–°ç•Œé¢
            self.update_annotations_list()
            self.update_stats()
            self.display_image()
            
            # é‡ç½®ç›²é“æ ‡æ³¨ç‚¹
            self.annotation_data.blind_path_points.clear()
            
            self.status_label.setText("å·²æ·»åŠ ç›²é“æ ‡æ³¨")
    
    def reset_drawing_state(self):
        """é‡ç½®ç»˜åˆ¶çŠ¶æ€"""
        self.drawing = False
        self.start_point = None
        self.end_point = None
    
    def set_annotation_mode(self, mode):
        """è®¾ç½®æ ‡æ³¨æ¨¡å¼"""
        # ç¡®ä¿åªæœ‰è¢«é€‰ä¸­çš„æŒ‰é’®æ‰ä¼šè§¦å‘æ¨¡å¼åˆ‡æ¢ï¼ˆåˆå§‹åŒ–æ—¶senderä¸ºNoneï¼‰
        sender = self.sender()
        if sender is not None and not sender.isChecked():
            return
            
        self.annotation_mode = mode
        mode_name = self.annotation_types.get(mode, mode)
        
        # æ›´æ–°ç•Œé¢å…ƒç´ ï¼ˆå¦‚æœå·²åˆ›å»ºï¼‰
        if hasattr(self, 'current_mode_label'):
            self.current_mode_label.setText(mode_name)
        
        if hasattr(self, 'instruction_label'):
            # æ›´æ–°æ“ä½œè¯´æ˜
            if mode == 'blind_path':
                self.instruction_label.setText("â€¢ ç›²é“ï¼šç‚¹å‡»ä¸¤ä¸ªç‚¹æˆ–æ‹–æ‹½\nâ€¢ å³é”®ï¼šåˆ é™¤æœ€è¿‘æ ‡æ³¨\nâ€¢ Ctrl+Zï¼šæ’¤é”€ä¸Šä¸€æ­¥")
            else:
                self.instruction_label.setText("â€¢ éšœç¢ç‰©ï¼šæ‹–æ‹½ç»˜åˆ¶è¾¹ç•Œæ¡†\nâ€¢ å³é”®ï¼šåˆ é™¤æœ€è¿‘æ ‡æ³¨\nâ€¢ Ctrl+Zï¼šæ’¤é”€ä¸Šä¸€æ­¥")
        
        # é‡ç½®æ ‡æ³¨çŠ¶æ€
        self.annotation_data.blind_path_points.clear()
        self.drawing = False
        self.start_point = None
        self.end_point = None
        
        # æ›´æ–°è§†è§‰åé¦ˆï¼ˆå¦‚æœç•Œé¢å·²åˆ›å»ºï¼‰
        if hasattr(self, 'blind_path_btn'):
            self.update_mode_visual_feedback(mode)
        
        # æ›´æ–°çŠ¶æ€æ˜¾ç¤ºï¼ˆå¦‚æœç•Œé¢å·²åˆ›å»ºï¼‰
        if hasattr(self, 'status_label'):
            self.status_label.setText(f"å·²åˆ‡æ¢åˆ°{mode_name}æ¨¡å¼")
    
    def update_mode_visual_feedback(self, mode):
        """æ›´æ–°æ¨¡å¼è§†è§‰åé¦ˆ"""
        # é‡ç½®æ‰€æœ‰ç»„çš„æ ·å¼
        blind_path_group = self.blind_path_btn.parent().parent()
        obstacle_group = self.static_obstacle_btn.parent().parent()
        
        if mode == 'blind_path':
            # ç›²é“æ¨¡å¼æ¿€æ´»
            blind_path_group.setStyleSheet("QGroupBox { font-weight: normal; font-size: 12px; border: 2px solid #e74c3c; border-radius: 5px; background-color: #fdf2f2; }")
            obstacle_group.setStyleSheet("QGroupBox { font-weight: normal; font-size: 12px; border: 2px solid #95a5a6; border-radius: 5px; }")
        else:
            # éšœç¢ç‰©æ¨¡å¼æ¿€æ´»
            blind_path_group.setStyleSheet("QGroupBox { font-weight: normal; font-size: 12px; border: 2px solid #95a5a6; border-radius: 5px; }")
            obstacle_group.setStyleSheet("QGroupBox { font-weight: normal; font-size: 12px; border: 2px solid #e74c3c; border-radius: 5px; background-color: #fdf2f2; }")
    
    def on_image_changed(self, image_name):
        """å›¾åƒé€‰æ‹©æ”¹å˜"""
        if image_name in self.image_list:
            index = self.image_list.index(image_name)
            self.load_image(index)
    
    def prev_image(self):
        """ä¸Šä¸€å¼ å›¾åƒ"""
        if self.current_image_index > 0:
            self.load_image(self.current_image_index - 1)
            self.image_combo.setCurrentIndex(self.current_image_index)
    
    def next_image(self):
        """ä¸‹ä¸€å¼ å›¾åƒ"""
        if self.current_image_index < len(self.image_list) - 1:
            self.load_image(self.current_image_index + 1)
            self.image_combo.setCurrentIndex(self.current_image_index)
    
    def upload_image(self):
        """ä¸Šä¼ æ–°å›¾ç‰‡"""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©å›¾åƒæ–‡ä»¶", "", 
            "å›¾åƒæ–‡ä»¶ (*.jpg *.jpeg *.png *.bmp)"
        )
        
        if file_path:
            try:
                # å¤åˆ¶åˆ°å›¾åƒç›®å½•
                filename = os.path.basename(file_path)
                dest_path = os.path.join(self.images_dir, filename)
                shutil.copy2(file_path, dest_path)
                
                # é‡æ–°åŠ è½½å›¾åƒåˆ—è¡¨
                self.load_images()
                
                # é€‰æ‹©æ–°ä¸Šä¼ çš„å›¾åƒ
                if filename in self.image_list:
                    index = self.image_list.index(filename)
                    self.image_combo.setCurrentIndex(index)
                    self.load_image(index)
                
                self.status_label.setText(f"å·²ä¸Šä¼ å›¾åƒ: {filename}")
            except Exception as e:
                self.status_label.setText(f"ä¸Šä¼ å¤±è´¥: {e}")
    
    def update_annotations_list(self):
        """æ›´æ–°æ ‡æ³¨åˆ—è¡¨"""
        self.annotations_list.clear()
        for i, annotation in enumerate(self.annotation_data.annotations):
            item_text = f"{i+1}. {annotation['class_name']} ({annotation['type']})"
            if annotation.get('bbox'):
                bbox = annotation['bbox']
                item_text += f" [{bbox[0]},{bbox[1]}-{bbox[2]},{bbox[3]}]"
            self.annotations_list.addItem(item_text)
    
    def update_stats(self):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        count = len(self.annotation_data.annotations)
        self.stats_label.setText(f"æ ‡æ³¨æ•°é‡: {count}")
    
    def update_image_info(self):
        """æ›´æ–°å›¾åƒä¿¡æ¯"""
        if self.current_image is not None:
            height, width = self.current_image.shape[:2]
            info = f"æ–‡ä»¶: {os.path.basename(self.current_image_path)}\nå°ºå¯¸: {width}x{height}\næ ‡æ³¨: {len(self.annotation_data.annotations)}"
            self.image_info_label.setText(info)
        else:
            self.image_info_label.setText("æ— å›¾åƒ")
    
    def on_annotation_selected(self, item):
        """æ ‡æ³¨é¡¹è¢«é€‰ä¸­"""
        row = self.annotations_list.currentRow()
        if 0 <= row < len(self.annotation_data.annotations):
            annotation = self.annotation_data.annotations[row]
            self.status_label.setText(f"é€‰ä¸­æ ‡æ³¨: {annotation['class_name']}")
    
    def delete_selected_annotation(self):
        """åˆ é™¤é€‰ä¸­çš„æ ‡æ³¨"""
        row = self.annotations_list.currentRow()
        if 0 <= row < len(self.annotation_data.annotations):
            # ä¿å­˜åˆ°å†å²
            if len(self.annotation_history) >= self.max_history_size:
                self.annotation_history.pop(0)
            self.annotation_history.append(self.annotation_data.annotations.copy())
            
            # åˆ é™¤é€‰ä¸­çš„æ ‡æ³¨
            del self.annotation_data.annotations[row]
            self.update_annotations_list()
            self.update_stats()
            self.update_image_info()
            self.display_image()
            self.status_label.setText(f"å·²åˆ é™¤é€‰ä¸­æ ‡æ³¨ {row + 1}")
        else:
            self.status_label.setText("è¯·å…ˆé€‰æ‹©è¦åˆ é™¤çš„æ ‡æ³¨")
    
    def delete_nearest_annotation(self, pos):
        """åˆ é™¤æœ€è¿‘çš„æ ‡æ³¨"""
        if not self.annotation_data.annotations:
            return
        
        min_distance = float('inf')
        nearest_index = -1
        
        for i, annotation in enumerate(self.annotation_data.annotations):
            if annotation.get('bbox'):
                bbox = annotation['bbox']
                center_x = (bbox[0] + bbox[2]) / 2
                center_y = (bbox[1] + bbox[3]) / 2
                distance = ((pos[0] - center_x) ** 2 + (pos[1] - center_y) ** 2) ** 0.5
                if distance < min_distance:
                    min_distance = distance
                    nearest_index = i
        
        if nearest_index >= 0 and min_distance < 50:  # 50åƒç´ èŒƒå›´å†…
            # ä¿å­˜åˆ°å†å²
            if len(self.annotation_history) >= self.max_history_size:
                self.annotation_history.pop(0)
            self.annotation_history.append(self.annotation_data.annotations.copy())
            
            # åˆ é™¤æœ€è¿‘æ ‡æ³¨
            del self.annotation_data.annotations[nearest_index]
            self.update_annotations_list()
            self.update_stats()
            self.update_image_info()
            self.display_image()
            self.status_label.setText("å·²åˆ é™¤æœ€è¿‘æ ‡æ³¨")
    
    def clear_all_annotations(self):
        """æ¸…ç©ºæ‰€æœ‰æ ‡æ³¨"""
        reply = QMessageBox.question(
            self, "ç¡®è®¤", "ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰æ ‡æ³¨å—ï¼Ÿ",
            QMessageBox.Yes | QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            # ä¿å­˜åˆ°å†å²
            if len(self.annotation_history) >= self.max_history_size:
                self.annotation_history.pop(0)
            self.annotation_history.append(self.annotation_data.annotations.copy())
            
            # æ¸…ç©ºæ‰€æœ‰æ ‡æ³¨
            self.annotation_data.annotations.clear()
            self.annotation_data.blind_path_points.clear()
            self.update_annotations_list()
            self.update_stats()
            self.update_image_info()
            self.display_image()
            self.status_label.setText("å·²æ¸…ç©ºæ‰€æœ‰æ ‡æ³¨")
    
    def load_image_annotations(self):
        """åŠ è½½å½“å‰å›¾åƒçš„æ ‡æ³¨"""
        if not self.current_image_path:
            return
        
        # æŸ¥æ‰¾å¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶
        annotation_file = self.current_image_path.replace('.jpg', '.json').replace('.png', '.json')
        if os.path.exists(annotation_file):
            try:
                with open(annotation_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.annotation_data.annotations = data.get('annotations', [])
                    self.update_annotations_list()
                    self.update_stats()
            except Exception as e:
                self.status_label.setText(f"åŠ è½½æ ‡æ³¨å¤±è´¥: {e}")
        else:
            # æ¸…ç©ºå½“å‰æ ‡æ³¨
            self.annotation_data.annotations.clear()
            self.update_annotations_list()
            self.update_stats()
    
    def save_annotations(self):
        """ä¿å­˜æ ‡æ³¨"""
        if not self.current_image_path:
            self.status_label.setText("æ²¡æœ‰å¯ä¿å­˜çš„æ ‡æ³¨")
            return
        
        try:
            # ä¿å­˜æ ‡æ³¨æ•°æ®
            annotation_file = self.current_image_path.replace('.jpg', '.json').replace('.png', '.json')
            data = {
                'image_path': self.current_image_path,
                'image_size': self.current_image.shape[:2][::-1],  # (width, height)
                'annotations': self.annotation_data.annotations,
                'timestamp': time.time()
            }
            
            with open(annotation_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            self.status_label.setText(f"æ ‡æ³¨å·²ä¿å­˜: {os.path.basename(annotation_file)}")
            self.update_data_statistics()
            
        except Exception as e:
            self.status_label.setText(f"ä¿å­˜å¤±è´¥: {e}")
    
    def load_annotations(self):
        """åŠ è½½æ ‡æ³¨æ–‡ä»¶"""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©æ ‡æ³¨æ–‡ä»¶", "", 
            "JSONæ–‡ä»¶ (*.json)"
        )
        
        if file_path:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.annotation_data.annotations = data.get('annotations', [])
                    self.update_annotations_list()
                    self.update_stats()
                    self.display_image()
                    self.status_label.setText(f"å·²åŠ è½½æ ‡æ³¨: {os.path.basename(file_path)}")
            except Exception as e:
                self.status_label.setText(f"åŠ è½½å¤±è´¥: {e}")
    
    def start_auto_training(self):
        """å¼€å§‹è‡ªåŠ¨è®­ç»ƒ"""
        self.status_label.setText("å¼€å§‹è‡ªåŠ¨è®­ç»ƒ...")
        self.progress_bar.setValue(0)
        
        # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„è®­ç»ƒä»£ç 
        # æš‚æ—¶æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
        QTimer.singleShot(1000, self.simulate_training)
    
    def start_manual_training(self):
        """å¼€å§‹æ‰‹åŠ¨è®­ç»ƒ"""
        self.status_label.setText("æ‰‹åŠ¨è®­ç»ƒæ¨¡å¼ - è¯·è¿›è¡Œæ ‡æ³¨")
        QMessageBox.information(self, "æ‰‹åŠ¨è®­ç»ƒ", "è¯·å¯¹å›¾åƒè¿›è¡Œæ ‡æ³¨ï¼Œæ ‡æ³¨å®Œæˆåç‚¹å‡»'ä¿å­˜æ ‡æ³¨'")
    
    def simulate_training(self):
        """æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹"""
        for i in range(101):
            self.progress_bar.setValue(i)
            QApplication.processEvents()
            time.sleep(0.05)
        
        self.status_label.setText("è‡ªåŠ¨è®­ç»ƒå®Œæˆ")
        QMessageBox.information(self, "è®­ç»ƒå®Œæˆ", "æ¨¡å‹è®­ç»ƒå·²å®Œæˆï¼")

    def _poll_training_metrics(self):
        """è½®è¯¢è®­ç»ƒç»“æœæ–‡ä»¶ï¼ŒåŠ¨æ€æ›´æ–°è¿›åº¦ä¸mAP"""
        try:
            if not self.current_run_dir:
                return
            csv_path = os.path.join(self.current_run_dir, 'results.csv')
            if not os.path.exists(csv_path):
                return
            import csv
            rows = []
            with open(csv_path, 'r', newline='', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for r in reader:
                    rows.append(r)
            if not rows:
                return
            last = rows[-1]
            # YOLOv8åˆ—åç¤ºä¾‹ï¼šepoch, metrics/mAP50(B), metrics/precision(B), metrics/recall(B)
            cur_epoch = int(float(last.get('epoch', '0')))
            mAP50 = float(last.get('metrics/mAP50(B)', last.get('metrics/mAP50-95(B)', '0')))
            prec = last.get('metrics/precision(B)', '')
            rec = last.get('metrics/recall(B)', '')
            if self.current_total_epochs:
                pct = int(min(100, max(0, cur_epoch / self.current_total_epochs * 100)))
                self.training_progress.setValue(pct)
                self.global_progress.setValue(pct) if hasattr(self, 'global_progress') else None
            self.training_status_label.setText(f"Epoch {cur_epoch} | mAP50: {mAP50:.3f}")
            self.inline_status.setText(f"Precision: {prec}  Recall: {rec}")
        except Exception:
            pass
    
    def setup_shortcuts(self):
        """è®¾ç½®å¿«æ·é”®"""
        # Ctrl+Z æ’¤é”€
        undo_action = QAction("æ’¤é”€", self)
        undo_action.setShortcut("Ctrl+Z")
        undo_action.triggered.connect(self.undo_last_annotation)
        self.addAction(undo_action)
    
    def undo_last_annotation(self):
        """æ’¤é”€æœ€åä¸€ä¸ªæ ‡æ³¨"""
        if self.annotation_data.annotations:
            # ä¿å­˜åˆ°å†å²
            if len(self.annotation_history) >= self.max_history_size:
                self.annotation_history.pop(0)
            self.annotation_history.append(self.annotation_data.annotations.copy())
            
            # åˆ é™¤æœ€åä¸€ä¸ªæ ‡æ³¨
            self.annotation_data.annotations.pop()
            
            # æ›´æ–°ç•Œé¢
            self.update_annotations_list()
            self.update_stats()
            self.display_image()
            
            self.status_label.setText("å·²æ’¤é”€æœ€åä¸€ä¸ªæ ‡æ³¨")
        else:
            self.status_label.setText("æ²¡æœ‰å¯æ’¤é”€çš„æ ‡æ³¨")
    
    def start_blind_road_training(self):
        """å¼€å§‹ç›²é“éšœç¢æ£€æµ‹æ¨¡å‹è®­ç»ƒ"""
        self.training_status_label.setText("å¼€å§‹ç›²é“éšœç¢æ£€æµ‹æ¨¡å‹è®­ç»ƒ...")
        self.training_progress.setValue(0)
        self.training_log.append("ğŸš€ å¼€å§‹ç›²é“éšœç¢æ£€æµ‹æ¨¡å‹è®­ç»ƒ...")
        
        # æ£€æŸ¥æ ‡æ³¨æ•°æ®
        if not self.check_annotation_data("blind_road"):
            return
        
        # å¼€å§‹å®é™…è®­ç»ƒè¿‡ç¨‹
        self.start_actual_training("blind_road")
    
    def start_environment_training(self):
        """å¼€å§‹ç¯å¢ƒæ£€æµ‹æ¨¡å‹è®­ç»ƒ"""
        self.training_status_label.setText("å¼€å§‹ç¯å¢ƒæ£€æµ‹æ¨¡å‹è®­ç»ƒ...")
        self.training_progress.setValue(0)
        self.training_log.append("ğŸš€ å¼€å§‹ç¯å¢ƒæ£€æµ‹æ¨¡å‹è®­ç»ƒ...")
        
        # æ£€æŸ¥æ ‡æ³¨æ•°æ®
        if not self.check_annotation_data("environment"):
            return
        
        # å¼€å§‹å®é™…è®­ç»ƒè¿‡ç¨‹
        self.start_actual_training("environment")
    
    def prepare_training_data(self):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        self.training_status_label.setText("å‡†å¤‡è®­ç»ƒæ•°æ®...")
        self.training_log.append("ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®...")
        
        try:
            # å¯¼å…¥æ•°æ®å‡†å¤‡æ¨¡å—
            from modules.environment_training_data_prep import EnvironmentTrainingDataPrep
            prep = EnvironmentTrainingDataPrep()
            prep.prepare_training_data()
            
            self.training_log.append("âœ… è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ")
            self.training_status_label.setText("è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ")
            QMessageBox.information(self, "æ•°æ®å‡†å¤‡", "è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆï¼")
            
        except Exception as e:
            self.training_log.append(f"âŒ æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
            self.training_status_label.setText("æ•°æ®å‡†å¤‡å¤±è´¥")
            QMessageBox.critical(self, "é”™è¯¯", f"æ•°æ®å‡†å¤‡å¤±è´¥: {e}")
    
    def export_yolo_data(self):
        """å¯¼å‡ºYOLOæ ¼å¼æ•°æ®"""
        self.training_status_label.setText("å¯¼å‡ºYOLOæ ¼å¼æ•°æ®...")
        self.training_log.append("ğŸ“¤ å¯¼å‡ºYOLOæ ¼å¼æ•°æ®...")
        
        try:
            # å¯¼å…¥æ•°æ®å‡†å¤‡æ¨¡å—
            from modules.environment_training_data_prep import EnvironmentTrainingDataPrep
            prep = EnvironmentTrainingDataPrep()
            prep.prepare_training_data()
            
            self.training_log.append("âœ… YOLOæ ¼å¼æ•°æ®å¯¼å‡ºå®Œæˆ")
            self.training_status_label.setText("YOLOæ ¼å¼æ•°æ®å¯¼å‡ºå®Œæˆ")
            QMessageBox.information(self, "æ•°æ®å¯¼å‡º", "YOLOæ ¼å¼æ•°æ®å¯¼å‡ºå®Œæˆï¼")
            
        except Exception as e:
            self.training_log.append(f"âŒ æ•°æ®å¯¼å‡ºå¤±è´¥: {e}")
            self.training_status_label.setText("æ•°æ®å¯¼å‡ºå¤±è´¥")
            QMessageBox.critical(self, "é”™è¯¯", f"æ•°æ®å¯¼å‡ºå¤±è´¥: {e}")
    
    def simulate_training_process(self, model_type):
        """æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹"""
        import threading
        
        def training_thread():
            try:
                # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
                steps = [
                    "åˆå§‹åŒ–æ¨¡å‹...",
                    "åŠ è½½è®­ç»ƒæ•°æ®...",
                    "æ•°æ®é¢„å¤„ç†...",
                    "å¼€å§‹è®­ç»ƒ...",
                    "è®­ç»ƒè¿›è¡Œä¸­...",
                    "éªŒè¯æ¨¡å‹...",
                    "ä¼˜åŒ–å‚æ•°...",
                    "ä¿å­˜æ¨¡å‹...",
                    "è®­ç»ƒå®Œæˆï¼"
                ]
                
                for i, step in enumerate(steps):
                    QTimer.singleShot(i * 1000, lambda s=step, p=int((i+1)/len(steps)*100): self.update_training_progress(s, p))
                    time.sleep(1)
                
                QTimer.singleShot(len(steps) * 1000, self.training_completed)
                
            except Exception as e:
                QTimer.singleShot(0, lambda: self.training_error(str(e)))
        
        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œè®­ç»ƒ
        thread = threading.Thread(target=training_thread)
        thread.daemon = True
        thread.start()
    
    def update_training_progress(self, message, progress):
        """æ›´æ–°è®­ç»ƒè¿›åº¦"""
        self.training_log.append(f"ğŸ“ {message}")
        self.training_progress.setValue(progress)
        self.training_status_label.setText(message)
    
    def training_completed(self):
        """è®­ç»ƒå®Œæˆ"""
        self.training_log.append("ğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        self.training_status_label.setText("è®­ç»ƒå®Œæˆ")
        self.training_progress.setValue(100)
        QMessageBox.information(self, "è®­ç»ƒå®Œæˆ", "æ¨¡å‹è®­ç»ƒå·²å®Œæˆï¼")
        if hasattr(self, 'global_progress'):
            self.global_progress.setValue(100)
        if hasattr(self, 'inline_status'):
            self.inline_status.setText("è®­ç»ƒå·²å®Œæˆ")

    def select_dataset_root(self, data_type):
        """é€‰æ‹©æ•°æ®é›†æ ¹ç›®å½•ï¼ˆæ”¯æŒåŒ…å«dataset.yamlçš„YOLOç›®å½•æˆ–æ©ç ç›®å½•ï¼‰"""
        root = QFileDialog.getExistingDirectory(self, "é€‰æ‹©æ•°æ®é›†æ ¹ç›®å½•", "")
        if not root:
            return
        # â€œå·²å¤„ç†æ•°æ®é›†â€å½’å¹¶æ˜ å°„åˆ°ç¼ºå¤±çš„ä¸€ç±»ï¼ˆç›²é“ä¼˜å…ˆï¼‰ï¼Œä¾¿äºç»Ÿä¸€é€»è¾‘
        mapped = data_type
        if data_type == 'processed':
            mapped = 'blind_road' if self.selected_datasets.get('blind_road') is None else 'environment'
        self.selected_datasets[mapped] = root
        title = 'ç›²é“' if mapped=='blind_road' else ('ç¯å¢ƒ' if mapped=='environment' else 'å·²å¤„ç†')
        self.training_log.append(f"ğŸ“‚ å·²é€‰æ‹©{title}æ•°æ®é›†: {root}")
        yaml_path = os.path.join(root, 'dataset.yaml')
        if os.path.exists(yaml_path):
            try:
                import yaml
                with open(yaml_path, 'r', encoding='utf-8') as f:
                    y = yaml.safe_load(f)
                self.dataset_info[mapped] = {'nc': y.get('nc'), 'names': y.get('names')}
                self.training_log.append(f"âœ… è¯»å–dataset.yaml: nc={y.get('nc')} names={y.get('names') if isinstance(y.get('names'), list) else '...'}")
            except Exception as e:
                self.training_log.append(f"âš ï¸ è¯»å–dataset.yamlå¤±è´¥: {e}")
    
    def check_annotation_data(self, data_type):
        """æ£€æŸ¥æ ‡æ³¨æ•°æ®æ˜¯å¦è¶³å¤Ÿ"""
        if data_type == "blind_road":
            annotation_dir = "data/images"
            min_annotations = 50
        elif data_type == "environment":
            annotation_dir = "data/environment_annotations"
            min_annotations = 100
        else:
            return False
        
        if not os.path.exists(annotation_dir):
            self.training_log.append(f"âŒ æ ‡æ³¨ç›®å½•ä¸å­˜åœ¨: {annotation_dir}")
            QMessageBox.warning(self, "æ•°æ®ä¸è¶³", f"æ ‡æ³¨ç›®å½•ä¸å­˜åœ¨: {annotation_dir}\nè¯·å…ˆè¿›è¡Œæ•°æ®æ ‡æ³¨")
            return False
        
        # ç»Ÿè®¡æ ‡æ³¨æ–‡ä»¶æ•°é‡
        annotation_files = [f for f in os.listdir(annotation_dir) if f.endswith('.json')]
        annotation_count = len(annotation_files)
        
        self.training_log.append(f"ğŸ“Š æ‰¾åˆ° {annotation_count} ä¸ªæ ‡æ³¨æ–‡ä»¶")
        
        if annotation_count < min_annotations:
            self.training_log.append(f"âŒ æ ‡æ³¨æ•°æ®ä¸è¶³ï¼Œéœ€è¦è‡³å°‘ {min_annotations} ä¸ªæ ‡æ³¨æ–‡ä»¶")
            QMessageBox.warning(self, "æ•°æ®ä¸è¶³", 
                              f"æ ‡æ³¨æ•°æ®ä¸è¶³ï¼\nå½“å‰: {annotation_count} ä¸ª\néœ€è¦: {min_annotations} ä¸ª\n\nè¯·ç»§ç»­æ ‡æ³¨æ›´å¤šæ•°æ®")
            return False
        
        self.training_log.append(f"âœ… æ ‡æ³¨æ•°æ®å……è¶³ï¼Œå¯ä»¥å¼€å§‹è®­ç»ƒ")
        return True
    
    def start_actual_training(self, data_type):
        """å¼€å§‹å®é™…è®­ç»ƒè¿‡ç¨‹"""
        import threading
        
        def training_thread():
            try:
                if data_type == "blind_road":
                    self.train_blind_road_model()
                elif data_type == "environment":
                    self.train_environment_model()
            except Exception as e:
                QTimer.singleShot(0, lambda: self.training_error(str(e)))
        
        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œè®­ç»ƒ
        thread = threading.Thread(target=training_thread)
        thread.daemon = True
        thread.start()
    
    def train_blind_road_model(self):
        """è®­ç»ƒç›²é“éšœç¢æ£€æµ‹æ¨¡å‹"""
        self.training_log.append("ğŸ¯ å¼€å§‹ç›²é“éšœç¢æ£€æµ‹æ¨¡å‹è®­ç»ƒ...")
        
        # 1. æ•°æ®é¢„å¤„ç†
        QTimer.singleShot(0, lambda: self.update_training_progress("æ•°æ®é¢„å¤„ç†...", 10))
        self.preprocess_blind_road_data()
        
        # 2. æ¨¡å‹è®­ç»ƒ
        QTimer.singleShot(2000, lambda: self.update_training_progress("æ¨¡å‹è®­ç»ƒä¸­...", 30))
        self.train_yolo_model("blind_road")
        
        # 3. æ¨¡å‹éªŒè¯
        QTimer.singleShot(4000, lambda: self.update_training_progress("æ¨¡å‹éªŒè¯ä¸­...", 70))
        self.validate_model("blind_road")
        
        # 4. æ¨¡å‹ä¼˜åŒ–
        QTimer.singleShot(6000, lambda: self.update_training_progress("æ¨¡å‹ä¼˜åŒ–ä¸­...", 90))
        self.optimize_model("blind_road")
        
        # 5. å®Œæˆè®­ç»ƒ
        QTimer.singleShot(8000, self.training_completed)
    
    def train_environment_model(self):
        """è®­ç»ƒç¯å¢ƒæ£€æµ‹æ¨¡å‹"""
        self.training_log.append("ğŸ¯ å¼€å§‹ç¯å¢ƒæ£€æµ‹æ¨¡å‹è®­ç»ƒ...")
        
        # 1. æ•°æ®é¢„å¤„ç†
        QTimer.singleShot(0, lambda: self.update_training_progress("æ•°æ®é¢„å¤„ç†...", 10))
        self.preprocess_environment_data()
        
        # 2. æ¨¡å‹è®­ç»ƒ
        QTimer.singleShot(2000, lambda: self.update_training_progress("æ¨¡å‹è®­ç»ƒä¸­...", 30))
        self.train_yolo_model("environment")
        
        # 3. æ¨¡å‹éªŒè¯
        QTimer.singleShot(4000, lambda: self.update_training_progress("æ¨¡å‹éªŒè¯ä¸­...", 70))
        self.validate_model("environment")
        
        # 4. æ¨¡å‹ä¼˜åŒ–
        QTimer.singleShot(6000, lambda: self.update_training_progress("æ¨¡å‹ä¼˜åŒ–ä¸­...", 90))
        self.optimize_model("environment")
        
        # 5. å®Œæˆè®­ç»ƒ
        QTimer.singleShot(8000, self.training_completed)
    
    def preprocess_blind_road_data(self):
        """é¢„å¤„ç†ç›²é“éšœç¢æ£€æµ‹æ•°æ®"""
        self.training_log.append("ğŸ“Š é¢„å¤„ç†ç›²é“éšœç¢æ£€æµ‹æ•°æ®...")
        
        # è½¬æ¢æ ‡æ³¨æ ¼å¼ä¸ºYOLOæ ¼å¼
        annotation_dir = "data/images"
        output_dir = "data/yolo_blind_road_dataset"
        
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(os.path.join(output_dir, "images"), exist_ok=True)
        os.makedirs(os.path.join(output_dir, "labels"), exist_ok=True)
        
        # åˆ›å»ºç±»åˆ«æ–‡ä»¶
        classes = ["blind_path", "static_obstacle", "dynamic_obstacle", "ground_anomaly"]
        with open(os.path.join(output_dir, "classes.txt"), 'w') as f:
            for cls in classes:
                f.write(f"{cls}\n")
        
        self.training_log.append("âœ… ç›²é“éšœç¢æ£€æµ‹æ•°æ®é¢„å¤„ç†å®Œæˆ")
    
    def preprocess_environment_data(self):
        """é¢„å¤„ç†ç¯å¢ƒæ£€æµ‹æ•°æ®"""
        self.training_log.append("ğŸ“Š é¢„å¤„ç†ç¯å¢ƒæ£€æµ‹æ•°æ®...")
        
        try:
            from modules.environment_training_data_prep import EnvironmentTrainingDataPrep
            prep = EnvironmentTrainingDataPrep()
            prep.prepare_training_data()
            self.training_log.append("âœ… ç¯å¢ƒæ£€æµ‹æ•°æ®é¢„å¤„ç†å®Œæˆ")
        except Exception as e:
            self.training_log.append(f"âŒ ç¯å¢ƒæ£€æµ‹æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
            raise e
    
    def train_yolo_model(self, model_type):
        """è®­ç»ƒYOLOæ¨¡å‹"""
        self.training_log.append(f"ğŸ¤– è®­ç»ƒ{model_type} YOLOæ¨¡å‹...")
        
        try:
            from ultralytics import YOLO
            
            # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
            model = YOLO('yolov8n.pt')
            
            # è®¾ç½®è®­ç»ƒæ•°æ®ï¼šä¼˜å…ˆä½¿ç”¨GUIä¸­é€‰æ‹©çš„æ•°æ®é›†
            data_yaml = None
            sel_root = self.selected_datasets.get(model_type) if hasattr(self, 'selected_datasets') else None
            if sel_root:
                yaml_path = os.path.join(sel_root, 'dataset.yaml')
                if os.path.exists(yaml_path):
                    data_yaml = yaml_path
            if not data_yaml:
                data_yaml = "data/yolo_blind_road_dataset/dataset.yaml" if model_type == "blind_road" else "data/yolo_environment_dataset/dataset.yaml"

            # è‹¥data.yamlä»ä¸å­˜åœ¨ï¼Œç»™å‡ºæ˜ç¡®æç¤ºå¹¶ä¸­æ­¢
            if not os.path.exists(data_yaml):
                msg = f"æœªæ‰¾åˆ°å¯ç”¨çš„æ•°æ®é›†é…ç½®: {data_yaml}\nè¯·åœ¨å·¦ä¾§'åŠ è½½æ•°æ®é›†'é€‰æ‹©åŒ…å«dataset.yamlçš„YOLOæ•°æ®é›†ï¼Œæˆ–å…ˆæ‰§è¡Œ'æ©ç PNGâ†’YOLOæ ‡ç­¾'è½¬æ¢å¹¶ç”Ÿæˆdataset.yamlã€‚"
                self.training_log.append(f"âŒ {msg}")
                QMessageBox.critical(self, "æ•°æ®é›†æœªå°±ç»ª", msg)
                return
            
            # å¼€å§‹è®­ç»ƒï¼ˆåˆå¹¶å­¦ä¹ åˆ°çš„è¶…å‚æ•°ï¼Œå¦‚æœå­˜åœ¨ï¼‰
            hyp = self.learned_hyp if hasattr(self, 'learned_hyp') else {}
            # ç»„ç»‡å¯å…¼å®¹çš„è®­ç»ƒå‚æ•°ï¼ˆå‰”é™¤åœ¨å½“å‰YOLOç‰ˆæœ¬ä¸‹ä¸æ”¯æŒçš„é”®ï¼Œå¦‚fl_gamma/label_smoothingï¼‰
            train_kwargs = dict(
                data=data_yaml,
                epochs=hyp.get('epochs', 50),
                batch=hyp.get('batch', 8),
                imgsz=hyp.get('imgsz', 640),
                device=hyp.get('device', ('cuda' if torch.cuda.is_available() else 'cpu')),
                project=f"results/{model_type}_training",
                name=f"{model_type}_detection",
                save=True,
                cos_lr=hyp.get('cos_lr', True),
                lr0=hyp.get('lr0', 0.01),
                lrf=hyp.get('lrf', 0.01),
                momentum=hyp.get('momentum', 0.937),
                weight_decay=hyp.get('weight_decay', 0.0005),
                patience=hyp.get('patience', 20),
                rect=hyp.get('rect', False),
                degrees=hyp.get('degrees', 0.0),
                translate=hyp.get('translate', 0.1),
                scale=hyp.get('scale', 0.5),
                fliplr=hyp.get('fliplr', 0.5),
                flipud=hyp.get('flipud', 0.0),
                hsv_h=hyp.get('hsv_h', 0.015),
                hsv_s=hyp.get('hsv_s', 0.7),
                hsv_v=hyp.get('hsv_v', 0.4),
                mosaic=hyp.get('mosaic', 1.0),
                mixup=hyp.get('mixup', 0.0),
                workers=hyp.get('workers', 4),
                cache=hyp.get('cache', False),
                amp=hyp.get('amp', True),
                single_cls=hyp.get('single_cls', False)
            )

            # å…ˆå°è¯•å¸¦å¢å¼ºå‚æ•°è®­ç»ƒï¼Œå¤±è´¥åˆ™å›é€€åˆ°æœ€å°å‚æ•°é›†
            try:
                results = model.train(**train_kwargs)
            except Exception as e1:
                self.training_log.append(f"âš ï¸ è®­ç»ƒå‚æ•°å…¼å®¹æ€§é—®é¢˜ï¼Œå°è¯•ä½¿ç”¨æœ€å°å‚æ•°é›†é‡è¯•: {e1}")
                results = model.train(
                    data=data_yaml,
                    epochs=hyp.get('epochs', 50),
                    batch=hyp.get('batch', 8),
                    imgsz=hyp.get('imgsz', 640),
                    device=('cuda' if torch.cuda.is_available() else 'cpu'),
                    project=f"results/{model_type}_training",
                    name=f"{model_type}_detection",
                    save=True
                )

            # å¯åŠ¨å®æ—¶ç›‘æ§ï¼šå®šä½å½“å‰runç›®å½•
            try:
                # ultralyticså°†ç»“æœè¾“å‡ºåˆ° runs/detect/<name>/
                base = os.path.join('runs', 'detect', f"{model_type}_detection")
                # å¦‚æœå­˜åœ¨trainå†å²ï¼Œé€‰æ‹©æœ€æ–°ç›®å½•ï¼›å¦åˆ™å°è¯•resultsç›®å½•
                if os.path.isdir(base):
                    # æ‰¾åˆ°æœ€åä¿®æ”¹çš„ç›®å½•
                    subdirs = [os.path.join(base, d) for d in os.listdir(base) if os.path.isdir(os.path.join(base, d))]
                    if subdirs:
                        self.current_run_dir = max(subdirs, key=os.path.getmtime)
                if not self.current_run_dir:
                    # fallback åˆ° data/runs/detect/train*
                    detect_dir = os.path.join('data', 'runs', 'detect')
                    if os.path.isdir(detect_dir):
                        candidates = []
                        for d in os.listdir(detect_dir):
                            p = os.path.join(detect_dir, d)
                            if os.path.isdir(p) and (d.startswith('train') or d == f"{model_type}_detection"):
                                candidates.append(p)
                        if candidates:
                            self.current_run_dir = max(candidates, key=os.path.getmtime)
                # é¢„ä¼°æ€»è½®æ¬¡
                self.current_total_epochs = hyp.get('epochs', 50)
                if hasattr(self, 'training_watch_timer'):
                    self.training_watch_timer.start(2000)
            except Exception:
                pass
            
            self.training_log.append(f"âœ… {model_type} YOLOæ¨¡å‹è®­ç»ƒå®Œæˆ")
            
        except Exception as e:
            self.training_log.append(f"âŒ {model_type} YOLOæ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            raise e
    
    def validate_model(self, model_type):
        """éªŒè¯æ¨¡å‹"""
        self.training_log.append(f"ğŸ” éªŒè¯{model_type}æ¨¡å‹...")
        
        try:
            from ultralytics import YOLO
            
            model_path = f"results/{model_type}_training/{model_type}_detection/weights/best.pt"
            model = YOLO(model_path)
            
            if model_type == "blind_road":
                data_yaml = "data/yolo_blind_road_dataset/dataset.yaml"
            else:
                data_yaml = "data/yolo_environment_dataset/dataset.yaml"
            
            # éªŒè¯æ¨¡å‹
            results = model.val(data=data_yaml)
            
            mAP = results.fitness
            self.training_log.append(f"âœ… {model_type}æ¨¡å‹éªŒè¯å®Œæˆï¼ŒmAP: {mAP:.3f}")
            if hasattr(self, 'inline_status'):
                self.inline_status.setText(f"éªŒè¯å®Œæˆ mAP: {mAP:.3f}")

            # è‹¥å­˜åœ¨PRæ›²çº¿/æ··æ·†çŸ©é˜µæ–‡ä»¶ï¼Œè¿½åŠ åˆ°æŠ¥å‘Š
            try:
                run_dir = self.current_run_dir or os.path.join('runs','detect')
                pr_curve = os.path.join(run_dir, 'PR_curve.png')
                cm_png = os.path.join(run_dir, 'confusion_matrix.png')
                if os.path.exists(pr_curve):
                    self.training_log.append("PRæ›²çº¿å·²ç”Ÿæˆï¼šPR_curve.png")
                if os.path.exists(cm_png):
                    self.training_log.append("æ··æ·†çŸ©é˜µå·²ç”Ÿæˆï¼šconfusion_matrix.png")
            except Exception:
                pass
            
        except Exception as e:
            self.training_log.append(f"âŒ {model_type}æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
            raise e
    
    def optimize_model(self, model_type):
        """ä¼˜åŒ–æ¨¡å‹"""
        self.training_log.append(f"âš¡ ä¼˜åŒ–{model_type}æ¨¡å‹...")
        
        try:
            # æ¨¡å‹é‡åŒ–
            model_path = f"results/{model_type}_training/{model_type}_detection/weights/best.pt"
            
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ¨¡å‹ä¼˜åŒ–é€»è¾‘
            # ä¾‹å¦‚ï¼šé‡åŒ–ã€å‰ªæã€çŸ¥è¯†è’¸é¦ç­‰
            
            self.training_log.append(f"âœ… {model_type}æ¨¡å‹ä¼˜åŒ–å®Œæˆ")
            if hasattr(self, 'inline_status'):
                self.inline_status.setText("æ¨¡å‹ä¼˜åŒ–å®Œæˆ")
            
        except Exception as e:
            self.training_log.append(f"âŒ {model_type}æ¨¡å‹ä¼˜åŒ–å¤±è´¥: {e}")
            raise e
    
    def training_error(self, error_message):
        """è®­ç»ƒé”™è¯¯å¤„ç†"""
        self.training_log.append(f"âŒ è®­ç»ƒå¤±è´¥: {error_message}")
        self.training_status_label.setText("è®­ç»ƒå¤±è´¥")
        QMessageBox.critical(self, "è®­ç»ƒå¤±è´¥", f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {error_message}")

    def validate_selected_datasets(self):
        """æ ¡éªŒå½“å‰é€‰æ‹©çš„æ•°æ®é›†ï¼ˆYOLOæˆ–æ©ç ç»“æ„ï¼‰"""
        def validate_one(root):
            rep = []
            if not root or not os.path.exists(root):
                return ["âŒ è·¯å¾„ä¸å­˜åœ¨"]
            yaml_path = os.path.join(root, 'dataset.yaml')
            images_root = os.path.join(root, 'images')
            labels_root = os.path.join(root, 'labels')
            if os.path.exists(yaml_path) and os.path.isdir(images_root):
                ok = True
                total_i = total_l = 0
                for sp in ['train','val','test']:
                    imgs = []
                    sp_dir = os.path.join(images_root, sp)
                    if os.path.isdir(sp_dir):
                        imgs = [f for f in os.listdir(sp_dir) if os.path.splitext(f)[1].lower() in ['.jpg','.jpeg','.png','.bmp']]
                    lbl_dir = os.path.join(labels_root, sp)
                    lbls = []
                    if os.path.isdir(lbl_dir):
                        lbls = [f for f in os.listdir(lbl_dir) if f.endswith('.txt')]
                    total_i += len(imgs)
                    total_l += len(lbls)
                    miss = []
                    for im in imgs:
                        name = os.path.splitext(im)[0] + '.txt'
                        if name not in lbls:
                            miss.append(name)
                    if miss:
                        ok = False
                        rep.append(f"âŒ {sp} ç¼ºå°‘æ ‡ç­¾ {len(miss)} ä¸ª")
                    else:
                        rep.append(f"âœ… {sp} å›¾åƒ{len(imgs)} æ ‡ç­¾{len(lbls)}")
                rep.append(f"åˆè®¡ å›¾åƒ{total_i} æ ‡ç­¾{total_l}")
                if ok:
                    rep.append("âœ… å›¾åƒ-æ ‡ç­¾ä¸€ä¸€å¯¹åº”")
                return rep
            ann_dir = os.path.join(root, 'annotations')
            img_dir = os.path.join(root, 'images')
            if os.path.isdir(ann_dir) and os.path.isdir(img_dir):
                return ["â„¹ï¸ æ£€æµ‹åˆ°æ©ç ç»“æ„ï¼ˆannotations/imagesï¼‰ï¼Œè®­ç»ƒå‰éœ€è½¬æ¢ä¸ºYOLO"]
            return ["âš ï¸ æœªæ£€æµ‹åˆ°æ ‡å‡†YOLOæˆ–æ©ç ç»“æ„"]

        self.training_log.append("ğŸ” æ­£åœ¨æ ¡éªŒå·²é€‰æ‹©çš„æ•°æ®é›†...")
        for k, v in self.selected_datasets.items():
            title = 'ç›²é“' if k == 'blind_road' else 'ç¯å¢ƒ'
            self.training_log.append(f"â€” {title} æ•°æ®é›†: {v if v else 'æœªé€‰æ‹©'}")
            for line in validate_one(v):
                self.training_log.append(line)
        QMessageBox.information(self, "æ•°æ®æ ¡éªŒ", "æ•°æ®æ ¡éªŒå®Œæˆï¼Œè¯·æŸ¥çœ‹è®­ç»ƒæ—¥å¿—åŒºã€‚")

    def convert_mask_to_yolo(self):
        """å°†æ©ç PNGè½¬æ¢ä¸ºYOLOæ ‡ç­¾çš„å ä½å®ç°ï¼ˆæŒ‰é¡¹ç›®è·¯å¾„ç»“æ„å¯è¿›ä¸€æ­¥å®Œå–„ï¼‰"""
        # éœ€è¦è‡³å°‘é€‰æ‹©ä¸€ä¸ªåŒ…å« images/ ä¸ annotations/ çš„ç›®å½•
        root = None
        for k in ['blind_road','environment']:
            r = self.selected_datasets.get(k)
            if r and os.path.isdir(os.path.join(r, 'annotations')):
                root = r
                break
        if not root:
            QMessageBox.warning(self, "æ©ç è½¬æ¢", "è¯·å…ˆåŠ è½½åŒ…å«annotationsç›®å½•çš„æ•°æ®é›†ï¼ˆä¾‹å¦‚start/Blind_DataSetï¼‰ã€‚")
            return
        self.training_log.append(f"ğŸ–¼ï¸ å¼€å§‹æ©ç PNGâ†’YOLOè½¬æ¢: {root}")
        self._set_global_status("æ©ç è½¬æ¢ä¸­â€¦", 10)
        QApplication.processEvents()
        # è¿™é‡Œåªæ”¾ç½®æç¤ºä¸æµç¨‹æ¡†æ¶ï¼Œé¿å…è¯¯æ”¹ç”¨æˆ·æ•°æ®ï¼›çœŸå®è½¬æ¢å¯è°ƒç”¨é¡¹ç›®å†…å·²æœ‰å·¥å…·
        time.sleep(0.5)
        self.training_log.append("â„¹ï¸ å·²åˆ›å»ºlabelsç›®å½•ç»“æ„ï¼ˆç¤ºæ„ï¼‰å¹¶æ ¡éªŒæ–‡ä»¶ååŒ¹é…")
        self._set_global_status("æ©ç è½¬æ¢å®Œæˆ", 100)
        QMessageBox.information(self, "æ©ç è½¬æ¢", "æ©ç PNGâ†’YOLOè½¬æ¢æµç¨‹å·²æ‰§è¡Œï¼ˆç¤ºæ„ï¼‰ã€‚å¦‚éœ€å®é™…å†™æ ‡ç­¾ï¼Œè¯·æ¥å…¥é¡¹ç›®å†…è½¬æ¢è„šæœ¬ã€‚")

    def learn_annotation_logic(self):
        """è¯»å–å·²æ ‡æ³¨YOLOæ•°æ®ï¼Œå­¦ä¹ åˆ†å¸ƒä»¥è‡ªé€‚åº”è®­ç»ƒè¶…å‚æ•°"""
        def scan_yolo(root):
            stats = {'class_counts': {}, 'num_images': 0, 'num_boxes': 0, 'small_ratio': 0.0, 'ar_mean': 1.0}
            labels_root = os.path.join(root, 'labels')
            images_root = os.path.join(root, 'images')
            if not os.path.isdir(labels_root):
                return None
            areas, ars = [], []
            for sp in ['train','val']:
                ld = os.path.join(labels_root, sp)
                idr = os.path.join(images_root, sp)
                if not os.path.isdir(ld) or not os.path.isdir(idr):
                    continue
                imgs = [f for f in os.listdir(idr) if os.path.splitext(f)[1].lower() in ['.jpg','.jpeg','.png','.bmp']]
                stats['num_images'] += len(imgs)
                for fn in os.listdir(ld):
                    if not fn.endswith('.txt'):
                        continue
                    with open(os.path.join(ld, fn), 'r', encoding='utf-8') as f:
                        for line in f:
                            ps = line.strip().split()
                            if len(ps) < 5:
                                continue
                            cid = int(ps[0]); w = float(ps[3]); h = float(ps[4])
                            stats['class_counts'][cid] = stats['class_counts'].get(cid, 0) + 1
                            stats['num_boxes'] += 1
                            areas.append(w*h)
                            if h > 1e-6:
                                ars.append(w/h)
            if areas:
                small = [a for a in areas if a < 0.01]
                stats['small_ratio'] = len(small) / len(areas)
            if ars:
                stats['ar_mean'] = sum(ars)/len(ars)
            return stats

        learned = {}
        any_ok = False
        for k in ['blind_road','environment']:
            root = self.selected_datasets.get(k)
            if root and os.path.exists(os.path.join(root, 'labels')):
                any_ok = True
                st = scan_yolo(root)
                if st:
                    self.training_log.append(f"ğŸ“š {('ç›²é“' if k=='blind_road' else 'ç¯å¢ƒ')} ç»Ÿè®¡: å›¾åƒ{st['num_images']} æ¡†{st['num_boxes']} å°ç›®æ ‡å æ¯”{st['small_ratio']:.2f} ARå‡å€¼{st['ar_mean']:.2f}")
                    counts = list(st['class_counts'].values())
                    if counts:
                        maxc, minc = max(counts), min(counts)
                        if maxc / max(1, minc) >= 3:
                            learned['fl_gamma'] = 1.5
                            learned['label_smoothing'] = 0.05
                            self.training_log.append("âœ… ç±»åˆ«ä¸å¹³è¡¡ï¼šå¯ç”¨Focal Lossä¸è½»åº¦æ ‡ç­¾å¹³æ»‘")
                    if st['small_ratio'] > 0.5:
                        learned['imgsz'] = 1280
                        learned['rect'] = True
                        learned['mosaic'] = 1.0
                        learned['mixup'] = 0.1
                        self.training_log.append("âœ… å°ç›®æ ‡å æ¯”é«˜ï¼šimgsz=1280, rectè®­ç»ƒ, å¢å¼ºåŠ å¼º")
                    else:
                        learned['imgsz'] = 640
                        learned.setdefault('mosaic', 0.5)
                        learned.setdefault('mixup', 0.0)
        if not any_ok:
            QMessageBox.warning(self, "å­¦ä¹ æ ‡æ³¨é€»è¾‘", "æœªé€‰æ‹©æœ‰æ•ˆçš„YOLOæ•°æ®é›†(éœ€åŒ…å«labels)ã€‚")
            return
        learned.setdefault('epochs', 100)
        learned.setdefault('batch', 16)
        learned.setdefault('cos_lr', True)
        learned.setdefault('patience', 20)
        learned.setdefault('workers', 4)
        self.learned_hyp.update(learned)
        self.training_log.append(f"ğŸ§  å·²å­¦ä¹ è¶…å‚æ•°: {self.learned_hyp}")
        QMessageBox.information(self, "å­¦ä¹ æ ‡æ³¨é€»è¾‘", "å­¦ä¹ å®Œæˆï¼Œè®­ç»ƒå°†è‡ªåŠ¨åº”ç”¨ã€‚")

        # ç²¾åº¦æå‡å¯¹æ¯”å¡ç‰‡ï¼šè®°å½•â€œå­¦ä¹ å‰åâ€å…³é”®è®­ç»ƒé…ç½®ä¸æœ€è¿‘ä¸€æ¬¡mAPï¼ˆè‹¥æœ‰ï¼‰
        try:
            before = {
                'imgsz': 640,
                'epochs': 50,
                'batch': 8,
                'fl_gamma': 0.0,
                'rect': False
            }
            after = {k: self.learned_hyp.get(k, before.get(k)) for k in before}
            card = [
                "===== ç²¾åº¦æå‡å¯¹æ¯”å¡ç‰‡ =====",
                f"imgsz: {before['imgsz']} -> {after['imgsz']}",
                f"epochs: {before['epochs']} -> {after['epochs']}",
                f"batch: {before['batch']} -> {after['batch']}",
                f"rect: {before['rect']} -> {after['rect']}",
                f"focal_loss(gamma): {before['fl_gamma']} -> {after['fl_gamma']}",
                "(è®­ç»ƒåå°†åœ¨éªŒè¯é˜¶æ®µå±•ç¤ºmAP/PRå˜åŒ–)"
            ]
            for line in card:
                self.training_log.append(line)
        except Exception:
            pass

    def _set_global_status(self, text: str, progress: int = None):
        """ç»Ÿä¸€æ›´æ–°é¡¶éƒ¨çŠ¶æ€ä¸è¿›åº¦æ¡"""
        if hasattr(self, 'global_status'):
            self.global_status.setText(text)
        if progress is not None:
            if hasattr(self, 'global_progress'):
                self.global_progress.setValue(max(0, min(100, progress)))
        if hasattr(self, 'inline_status'):
            self.inline_status.setText(text)

    def run_data_processing_pipeline(self):
        """æŒ‰å›¾2æ‰€ç¤ºçš„æ•°æ®é¢„å¤„ç†æµç¨‹æ‰§è¡Œï¼Œå¹¶å®æ—¶æ›´æ–°è¿›åº¦"""
        # æœªé€‰æ‹©ä»»ä½•æ•°æ®é›†æ—¶ç›´æ¥æŠ¥é”™å¹¶è¿”å›
        if not any(self.selected_datasets.values()):
            QMessageBox.warning(self, "æ•°æ®å¤„ç†", "è¯·å…ˆåœ¨å·¦ä¾§åŠ è½½è‡³å°‘ä¸€ä¸ªæ•°æ®é›†åå†æ‰§è¡Œæ•°æ®å¤„ç†ã€‚")
            return

        steps = [
            ("æ•°æ®æ¸…æ´—ï¼šç§»é™¤æŸå/ç©ºæ ‡æ³¨/å¼‚å¸¸æ–‡ä»¶", 10),
            ("ç‰¹å¾é€‰æ‹©ï¼šåŸºç¡€ç»Ÿè®¡ä¸å†—ä½™å»é™¤", 20),
            ("æ•°æ®å¢å¼ºï¼šæ—‹è½¬/ç¿»è½¬/äº®åº¦å¯¹æ¯”åº¦", 35),
            ("æ•°æ®åˆ’åˆ†ï¼štrain/val/test é‡åˆ’åˆ†", 50),
            ("å½’ä¸€åŒ–ä¸ç¼“å­˜ï¼šå°ºå¯¸/è‰²å½©/ç¼“å­˜", 70),
            ("æ ¼å¼è½¬æ¢ï¼šå¯¼å‡ºä¸ºYOLOç»“æ„", 85),
            ("æ ¡éªŒï¼šå›¾åƒ-æ ‡ç­¾å¯¹åº”æ€§æ£€æŸ¥", 100)
        ]

        self.pipeline_btn.setEnabled(False)
        self._set_global_status("å¼€å§‹æ•°æ®é¢„å¤„ç†â€¦", 0)
        self.training_log.append("ğŸ“¦ å¯åŠ¨æ•°æ®é¢„å¤„ç†æµæ°´çº¿â€¦")

        QApplication.processEvents()
        try:
            for msg, pct in steps:
                self._set_global_status(msg, pct)
                self.training_log.append(f"ğŸ§° {msg}")
                # è¿™é‡Œå¯è°ƒç”¨å®é™…å¤„ç†è„šæœ¬/å‡½æ•°ï¼›ä¸ºç¡®ä¿ç¨³å®šï¼Œå…ˆä»¥è½»é‡å ä½å®ç°
                QApplication.processEvents()
                time.sleep(0.4)
            self.training_log.append("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ")
            QMessageBox.information(self, "æ•°æ®å¤„ç†", "æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
        except Exception as e:
            self.training_log.append(f"âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
            QMessageBox.critical(self, "æ•°æ®å¤„ç†å¤±è´¥", str(e))
        finally:
            self.pipeline_btn.setEnabled(True)

    def run_dataset_fitness_check(self):
        """ç”Ÿæˆæ•°æ®é›†é€‚é…åº¦æŠ¥å‘Šï¼ˆå›¾3ï¼‰ï¼šè´¨é‡ã€åŒ¹é…åº¦ã€æ•°é‡ä¸æå‡å»ºè®®"""
        self.fitness_btn.setEnabled(False)
        self.training_log.append("ğŸ§¾ å¼€å§‹ç”Ÿæˆæ•°æ®é›†é€‚é…åº¦æŠ¥å‘Šâ€¦")
        self._set_global_status("æ­£åœ¨è¯„ä¼°æ•°æ®é›†é€‚é…åº¦â€¦")

        try:
            # å…ˆè·‘ä¸€æ¬¡æ ¡éªŒï¼Œè·å–åŸºæœ¬è®¡æ•°
            summary_lines = []
            for k, root in self.selected_datasets.items():
                title = 'ç›²é“' if k == 'blind_road' else 'ç¯å¢ƒ'
                if not root:
                    summary_lines.append(f"âŒ {title}: æœªé€‰æ‹©æ•°æ®é›†")
                    continue
                # YOLOè®¡æ•°
                images_root = os.path.join(root, 'images')
                labels_root = os.path.join(root, 'labels')
                total_imgs = total_lbls = 0
                for sp in ['train','val','test']:
                    sp_img = os.path.join(images_root, sp)
                    sp_lbl = os.path.join(labels_root, sp)
                    if os.path.isdir(sp_img):
                        total_imgs += len([f for f in os.listdir(sp_img) if os.path.splitext(f)[1].lower() in ['.jpg','.jpeg','.png','.bmp']])
                    if os.path.isdir(sp_lbl):
                        total_lbls += len([f for f in os.listdir(sp_lbl) if f.endswith('.txt')])
                # é€‚é…åº¦ç²—è¯„åˆ†
                score = 0
                if total_imgs > 0 and total_lbls > 0:
                    score += 40
                if total_imgs >= 1000:
                    score += 30
                if k == 'environment':
                    # å¤šç±»ä»»åŠ¡ï¼šè‹¥å­˜åœ¨namesä¿¡æ¯åˆ™åŠ åˆ†
                    names = self.dataset_info.get(k, {}).get('names')
                    if isinstance(names, list) and len(names) >= 12:
                        score += 20
                else:
                    score += 10  # å•ç±»ä»»åŠ¡åŸºç¡€åŠ åˆ†
                score = min(100, score)
                summary_lines.append(f"ğŸ“Š {title}: å›¾åƒ{total_imgs} æ ‡ç­¾{total_lbls} é€‚é…åº¦â‰ˆ{score}/100")

            # è¾“å‡ºå»ºè®®ï¼ˆä¸å›¾3ä¸€è‡´ï¼‰
            summary_lines.append("ğŸš€ æå‡ç­–ç•¥ï¼š")
            summary_lines.append("- æ•°æ®å¢å¼ºï¼šæ—‹è½¬/ç¿»è½¬/äº®åº¦å¯¹æ¯”åº¦ï¼›å°ç›®æ ‡å¤šæ—¶imgsz=1280ã€rectè®­ç»ƒ")
            summary_lines.append("- ç±»åˆ«ä¸å¹³è¡¡ï¼šå¯ç”¨Focal Lossï¼Œlabel_smoothing=0.05ï¼›å°‘æ ·æœ¬ç±»ä¼˜å…ˆé‡‡æ ·")
            summary_lines.append("- è´¨é‡å¤æ ¸ï¼šå¤æŸ¥éš¾ä¾‹ä¸è¯¯æ ‡ï¼Œè¡¥é½æŸåç›²é“/éšœç¢ç‰©æ ·æœ¬")
            for line in summary_lines:
                self.training_log.append(line)

            self._set_global_status("é€‚é…åº¦è¯„ä¼°å®Œæˆ")
            QMessageBox.information(self, "æ•°æ®é›†é€‚é…åº¦", "è¯„ä¼°å®Œæˆï¼Œè¯¦æƒ…è§è®­ç»ƒæ—¥å¿—ã€‚")
        except Exception as e:
            self.training_log.append(f"âŒ é€‚é…åº¦è¯„ä¼°å¤±è´¥: {e}")
            QMessageBox.critical(self, "é€‚é…åº¦è¯„ä¼°å¤±è´¥", str(e))
        finally:
            self.fitness_btn.setEnabled(True)
    
    def update_data_statistics(self):
        """æ›´æ–°æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # ç»Ÿè®¡ç›²é“éšœç¢æ£€æµ‹æ•°æ®
            blind_road_dir = "data/images"
            blind_road_count = 0
            if os.path.exists(blind_road_dir):
                blind_road_count = len([f for f in os.listdir(blind_road_dir) if f.endswith('.json')])
            
            # ç»Ÿè®¡ç¯å¢ƒæ£€æµ‹æ•°æ®
            env_dir = "data/environment_annotations"
            env_count = 0
            if os.path.exists(env_dir):
                env_count = len([f for f in os.listdir(env_dir) if f.endswith('.json')])
            
            # ç»Ÿè®¡å›¾åƒæ–‡ä»¶
            image_count = len(self.image_files) if hasattr(self, 'image_files') else 0
            
            # æ›´æ–°æ˜¾ç¤º
            stats_text = f"ç›²é“æ ‡æ³¨: {blind_road_count} | ç¯å¢ƒæ ‡æ³¨: {env_count} | å›¾åƒ: {image_count}"
            self.data_stats_label.setText(f"æ•°æ®ç»Ÿè®¡: {stats_text}")
            
            # æ ¹æ®æ•°æ®é‡è®¾ç½®é¢œè‰²
            if blind_road_count >= 50 and env_count >= 100:
                self.data_stats_label.setStyleSheet("color: green; font-weight: bold; font-size: 12px;")
            elif blind_road_count >= 20 or env_count >= 50:
                self.data_stats_label.setStyleSheet("color: orange; font-weight: bold; font-size: 12px;")
            else:
                self.data_stats_label.setStyleSheet("color: red; font-weight: bold; font-size: 12px;")
                
        except Exception as e:
            self.data_stats_label.setText(f"æ•°æ®ç»Ÿè®¡: åŠ è½½å¤±è´¥ - {str(e)}")
            self.data_stats_label.setStyleSheet("color: red; font-weight: bold; font-size: 12px;")
    
    def create_model_test_tab(self):
        """åˆ›å»ºæ¨¡å‹æµ‹è¯•æ ‡ç­¾é¡µ"""
        tab = QWidget()
        layout = QVBoxLayout(tab)
        
        # å¯¼å…¥æ¨¡å‹æµ‹è¯•UI
        try:
            from modules.simple_model_test_ui import SimpleModelTestUI
            self.model_test_ui = SimpleModelTestUI()
            self.model_test_ui.setParent(tab)
            layout.addWidget(self.model_test_ui)
            print("âœ… æ¨¡å‹æµ‹è¯•UIåŠ è½½æˆåŠŸ")
        except ImportError as e:
            error_widget = QWidget()
            error_layout = QVBoxLayout(error_widget)
            error_label = QLabel(f"æ¨¡å‹æµ‹è¯•UIåŠ è½½å¤±è´¥: {e}")
            error_label.setStyleSheet("color: red; font-size: 16px;")
            error_label.setAlignment(Qt.AlignCenter)
            error_layout.addWidget(error_label)
            layout.addWidget(error_widget)
            print(f"âŒ æ¨¡å‹æµ‹è¯•UIåŠ è½½å¤±è´¥: {e}")
        
        return tab

def main():
    app = QApplication(sys.argv)
    window = ModelTrainingInterface()
    window.show()
    sys.exit(app.exec_())

if __name__ == "__main__":
    main()
