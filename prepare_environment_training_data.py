#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¯å¢ƒæ£€æµ‹è®­ç»ƒæ•°æ®å‡†å¤‡è„šæœ¬
å°†ç¯å¢ƒäº‹ç‰©æ ‡æ³¨æ•°æ®è½¬æ¢ä¸ºYOLOè®­ç»ƒæ ¼å¼
"""

import os
import json
import shutil
import cv2
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple
import argparse

class EnvironmentTrainingDataPreparer:
    """ç¯å¢ƒæ£€æµ‹è®­ç»ƒæ•°æ®å‡†å¤‡å™¨"""
    
    def __init__(self, input_dir: str, output_dir: str):
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.class_mapping = {}
        self.stats = {
            'total_images': 0,
            'total_annotations': 0,
            'class_counts': {},
            'conversion_errors': 0
        }
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir.mkdir(parents=True, exist_ok=True)
        (self.output_dir / 'images').mkdir(exist_ok=True)
        (self.output_dir / 'labels').mkdir(exist_ok=True)
        
        # åŠ è½½ç±»åˆ«æ˜ å°„
        self.load_class_mapping()
    
    def load_class_mapping(self):
        """åŠ è½½ç±»åˆ«æ˜ å°„"""
        try:
            with open('environment_annotation_classes.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
                classes = data['environment_annotation_classes']
                
                class_id = 0
                for category, items in classes.items():
                    for item_id, info in items.items():
                        self.class_mapping[info['name']] = class_id
                        class_id += 1
                
                print(f"âœ… åŠ è½½äº† {len(self.class_mapping)} ä¸ªç±»åˆ«æ˜ å°„")
        except Exception as e:
            print(f"âŒ åŠ è½½ç±»åˆ«æ˜ å°„å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤æ˜ å°„
            default_classes = ['é›¨æ»´', 'æ¹¿æ¶¦è¡¨é¢', 'é›¾é¢—ç²’', 'é›ªå—', 'é˜´å½±åŒºåŸŸ', 'å¼ºå…‰ç‚¹', 'æš—è§’', 
                             'è£‚ç¼', 'å‘æ´', 'å°é˜¶', 'ä¸å¹³æ•´è·¯é¢', 'æ–½å·¥æ ‡å¿—', 'å®‰å…¨é”¥', 'æ–½å·¥å›´æ ', 
                             'æ–½å·¥æœºæ¢°', 'äº¤é€šä¿¡å·ç¯', 'æ–‘é©¬çº¿', 'åœè½¦æ ‡å¿—', 'è®©è¡Œæ ‡å¿—', 'æ ‘æœ¨', 
                             'è¡—é“è®¾æ–½', 'ç”µçº¿æ†', 'è‡ªè¡Œè½¦']
            self.class_mapping = {name: i for i, name in enumerate(default_classes)}
    
    def process_annotation_file(self, annotation_file: Path) -> bool:
        """å¤„ç†å•ä¸ªæ ‡æ³¨æ–‡ä»¶"""
        try:
            with open(annotation_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # è·å–å›¾åƒä¿¡æ¯
            image_size = data.get('image_size')
            if not image_size:
                print(f"âš ï¸ è·³è¿‡ {annotation_file}: ç¼ºå°‘å›¾åƒå°ºå¯¸ä¿¡æ¯")
                return False
            
            img_height, img_width = image_size
            
            # è·å–æ ‡æ³¨ä¿¡æ¯
            annotations = data.get('annotations', [])
            if not annotations:
                print(f"âš ï¸ è·³è¿‡ {annotation_file}: æ²¡æœ‰æ ‡æ³¨æ•°æ®")
                return False
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            base_name = annotation_file.stem
            image_file = self.input_dir / f"{base_name}.jpg"
            if not image_file.exists():
                image_file = self.input_dir / f"{base_name}.png"
            if not image_file.exists():
                print(f"âš ï¸ è·³è¿‡ {annotation_file}: æ‰¾ä¸åˆ°å¯¹åº”çš„å›¾åƒæ–‡ä»¶")
                return False
            
            # å¤åˆ¶å›¾åƒæ–‡ä»¶
            output_image = self.output_dir / 'images' / f"{base_name}.jpg"
            shutil.copy2(image_file, output_image)
            
            # è½¬æ¢æ ‡æ³¨æ ¼å¼
            yolo_annotations = []
            for annotation in annotations:
                class_name = annotation['class_name']
                if class_name not in self.class_mapping:
                    print(f"âš ï¸ æœªçŸ¥ç±»åˆ«: {class_name}")
                    continue
                
                class_id = self.class_mapping[class_name]
                bbox = annotation['bbox']  # [x1, y1, x2, y2] å½’ä¸€åŒ–åæ ‡
                
                # è½¬æ¢ä¸ºYOLOæ ¼å¼ (class_id x_center y_center width height)
                x_center = (bbox[0] + bbox[2]) / 2
                y_center = (bbox[1] + bbox[3]) / 2
                width = bbox[2] - bbox[0]
                height = bbox[3] - bbox[1]
                
                yolo_annotations.append(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")
                
                # æ›´æ–°ç»Ÿè®¡
                self.stats['class_counts'][class_name] = self.stats['class_counts'].get(class_name, 0) + 1
            
            # ä¿å­˜YOLOæ ¼å¼æ ‡æ³¨
            label_file = self.output_dir / 'labels' / f"{base_name}.txt"
            with open(label_file, 'w') as f:
                f.write('\n'.join(yolo_annotations))
            
            self.stats['total_images'] += 1
            self.stats['total_annotations'] += len(yolo_annotations)
            
            return True
            
        except Exception as e:
            print(f"âŒ å¤„ç† {annotation_file} æ—¶å‡ºé”™: {e}")
            self.stats['conversion_errors'] += 1
            return False
    
    def create_dataset_yaml(self):
        """åˆ›å»ºæ•°æ®é›†é…ç½®æ–‡ä»¶"""
        yaml_content = f"""# ç¯å¢ƒæ£€æµ‹æ•°æ®é›†é…ç½®
path: {self.output_dir.absolute()}
train: images
val: images

# ç±»åˆ«å®šä¹‰
nc: {len(self.class_mapping)}
names: {list(self.class_mapping.keys())}

# ç±»åˆ«è¯¦ç»†ä¿¡æ¯
class_info:
"""
        
        # æ·»åŠ ç±»åˆ«è¯¦ç»†ä¿¡æ¯
        for class_name, class_id in self.class_mapping.items():
            yaml_content += f"  {class_id}: {class_name}\n"
        
        # ä¿å­˜YAMLæ–‡ä»¶
        yaml_file = self.output_dir / 'dataset.yaml'
        with open(yaml_file, 'w', encoding='utf-8') as f:
            f.write(yaml_content)
        
        print(f"âœ… åˆ›å»ºæ•°æ®é›†é…ç½®æ–‡ä»¶: {yaml_file}")
    
    def create_training_script(self):
        """åˆ›å»ºè®­ç»ƒè„šæœ¬"""
        script_content = f'''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¯å¢ƒæ£€æµ‹æ¨¡å‹è®­ç»ƒè„šæœ¬
"""

from ultralytics import YOLO
import os

def train_environment_detection_model():
    """è®­ç»ƒç¯å¢ƒæ£€æµ‹æ¨¡å‹"""
    
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    model = YOLO('yolov8n.pt')  # ä½¿ç”¨YOLOv8 nanoç‰ˆæœ¬
    
    # è®­ç»ƒå‚æ•°
    training_args = {{
        'data': '{self.output_dir.absolute()}/dataset.yaml',
        'epochs': 100,
        'imgsz': 640,
        'batch': 16,
        'device': 'cpu',  # å¦‚æœæœ‰GPUï¼Œæ”¹ä¸º 'cuda'
        'workers': 4,
        'project': 'environment_detection',
        'name': 'environment_model',
        'save': True,
        'save_period': 10,
        'cache': True,
        'patience': 20,
        'lr0': 0.01,
        'lrf': 0.1,
        'momentum': 0.937,
        'weight_decay': 0.0005,
        'warmup_epochs': 3,
        'warmup_momentum': 0.8,
        'warmup_bias_lr': 0.1,
        'box': 7.5,
        'cls': 0.5,
        'dfl': 1.5,
        'pose': 12.0,
        'kobj': 2.0,
        'label_smoothing': 0.0,
        'nbs': 64,
        'overlap_mask': True,
        'mask_ratio': 4,
        'dropout': 0.0,
        'val': True,
        'plots': True,
        'verbose': True
    }}
    
    print("ğŸš€ å¼€å§‹è®­ç»ƒç¯å¢ƒæ£€æµ‹æ¨¡å‹...")
    print(f"ğŸ“Š æ•°æ®é›†è·¯å¾„: {{training_args['data']}}")
    print(f"ğŸ¯ è®­ç»ƒè½®æ•°: {{training_args['epochs']}}")
    print(f"ğŸ“ å›¾åƒå°ºå¯¸: {{training_args['imgsz']}}")
    print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {{training_args['batch']}}")
    
    # å¼€å§‹è®­ç»ƒ
    results = model.train(**training_args)
    
    print("âœ… è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: {{results.save_dir}}")
    
    # éªŒè¯æ¨¡å‹
    print("ğŸ” éªŒè¯æ¨¡å‹æ€§èƒ½...")
    val_results = model.val()
    
    return results, val_results

if __name__ == "__main__":
    train_environment_detection_model()
'''
        
        script_file = self.output_dir / 'train_environment_model.py'
        with open(script_file, 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        # è®¾ç½®æ‰§è¡Œæƒé™
        os.chmod(script_file, 0o755)
        
        print(f"âœ… åˆ›å»ºè®­ç»ƒè„šæœ¬: {script_file}")
    
    def process_all_annotations(self):
        """å¤„ç†æ‰€æœ‰æ ‡æ³¨æ–‡ä»¶"""
        print(f"ğŸ” å¼€å§‹å¤„ç†æ ‡æ³¨æ–‡ä»¶...")
        print(f"ğŸ“ è¾“å…¥ç›®å½•: {self.input_dir}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        
        # æŸ¥æ‰¾æ‰€æœ‰æ ‡æ³¨æ–‡ä»¶
        annotation_files = list(self.input_dir.glob("*.json"))
        
        if not annotation_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ ‡æ³¨æ–‡ä»¶")
            return
        
        print(f"ğŸ“„ æ‰¾åˆ° {len(annotation_files)} ä¸ªæ ‡æ³¨æ–‡ä»¶")
        
        # å¤„ç†æ¯ä¸ªæ ‡æ³¨æ–‡ä»¶
        processed_count = 0
        for annotation_file in annotation_files:
            if self.process_annotation_file(annotation_file):
                processed_count += 1
                print(f"âœ… å¤„ç†å®Œæˆ: {annotation_file.name}")
            else:
                print(f"âŒ å¤„ç†å¤±è´¥: {annotation_file.name}")
        
        print(f"\nğŸ“Š å¤„ç†å®Œæˆ: {processed_count}/{len(annotation_files)} ä¸ªæ–‡ä»¶")
        
        # åˆ›å»ºé…ç½®æ–‡ä»¶
        self.create_dataset_yaml()
        self.create_training_script()
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        self.print_statistics()
    
    def print_statistics(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“Š æ•°æ®å‡†å¤‡ç»Ÿè®¡:")
        print(f"  æ€»å›¾åƒæ•°: {self.stats['total_images']}")
        print(f"  æ€»æ ‡æ³¨æ•°: {self.stats['total_annotations']}")
        print(f"  è½¬æ¢é”™è¯¯: {self.stats['conversion_errors']}")
        
        print("\nğŸ“ˆ ç±»åˆ«åˆ†å¸ƒ:")
        for class_name, count in sorted(self.stats['class_counts'].items(), key=lambda x: x[1], reverse=True):
            print(f"  {class_name}: {count}")
        
        print(f"\nğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"  ğŸ“· å›¾åƒç›®å½•: {self.output_dir}/images")
        print(f"  ğŸ·ï¸ æ ‡ç­¾ç›®å½•: {self.output_dir}/labels")
        print(f"  âš™ï¸ é…ç½®æ–‡ä»¶: {self.output_dir}/dataset.yaml")
        print(f"  ğŸš€ è®­ç»ƒè„šæœ¬: {self.output_dir}/train_environment_model.py")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç¯å¢ƒæ£€æµ‹è®­ç»ƒæ•°æ®å‡†å¤‡å·¥å…·')
    parser.add_argument('--input', '-i', required=True, help='è¾“å…¥ç›®å½•ï¼ˆåŒ…å«å›¾åƒå’Œæ ‡æ³¨æ–‡ä»¶ï¼‰')
    parser.add_argument('--output', '-o', required=True, help='è¾“å‡ºç›®å½•ï¼ˆYOLOæ ¼å¼æ•°æ®é›†ï¼‰')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {args.input}")
        return
    
    # åˆ›å»ºæ•°æ®å‡†å¤‡å™¨
    preparer = EnvironmentTrainingDataPreparer(args.input, args.output)
    
    # å¤„ç†æ‰€æœ‰æ ‡æ³¨
    preparer.process_all_annotations()
    
    print("\nğŸ‰ æ•°æ®å‡†å¤‡å®Œæˆï¼")
    print("ğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("  1. æ£€æŸ¥ç”Ÿæˆçš„æ•°æ®é›†")
    print("  2. è¿è¡Œè®­ç»ƒè„šæœ¬: python train_environment_model.py")
    print("  3. è¯„ä¼°æ¨¡å‹æ€§èƒ½")
    print("  4. é›†æˆåˆ°ç›²é“æ£€æµ‹ç³»ç»Ÿ")

if __name__ == "__main__":
    main()







