#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›²é“æ ‡æ³¨æ•°æ®åˆ†æå·¥å…·
åŠŸèƒ½ï¼š
1. ç»Ÿè®¡æ ‡æ³¨æ•°æ®
2. è½¬æ¢ä¸ºYOLOæ ¼å¼
3. å‡†å¤‡è®­ç»ƒæ•°æ®é›†
"""

import os
import json
import glob
import cv2
import numpy as np
from pathlib import Path

class BlindPathDataAnalyzer:
    def __init__(self):
        self.annotations_dir = "annotations"
        self.images_dir = "images"
        self.output_dir = "yolo_dataset"
        
    def analyze_annotations(self):
        """åˆ†ææ‰€æœ‰æ ‡æ³¨æ•°æ®"""
        print("=== ç›²é“æ ‡æ³¨æ•°æ®åˆ†æ ===")
        
        # è·å–æ‰€æœ‰æ ‡æ³¨æ–‡ä»¶
        annotation_files = glob.glob(os.path.join(self.annotations_dir, "*_annotations.json"))
        
        if not annotation_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ ‡æ³¨æ–‡ä»¶")
            return
            
        print(f"ğŸ“ æ‰¾åˆ° {len(annotation_files)} ä¸ªæ ‡æ³¨æ–‡ä»¶")
        
        total_lines = 0
        total_images = 0
        lines_per_image = []
        
        for ann_file in annotation_files:
            try:
                with open(ann_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                annotations = data.get('annotations', [])
                lines_count = len([ann for ann in annotations if ann['type'] == 'blind_path_line'])
                
                total_lines += lines_count
                total_images += 1
                lines_per_image.append(lines_count)
                
                print(f"  ğŸ“„ {os.path.basename(ann_file)}: {lines_count} æ¡çº¿æ®µ")
                
            except Exception as e:
                print(f"  âŒ è¯»å– {ann_file} å¤±è´¥: {e}")
        
        print(f"\nğŸ“Š ç»Ÿè®¡ç»“æœ:")
        print(f"  æ€»å›¾åƒæ•°: {total_images}")
        print(f"  æ€»çº¿æ®µæ•°: {total_lines}")
        print(f"  å¹³å‡æ¯å¼ å›¾åƒçº¿æ®µæ•°: {total_lines/total_images:.1f}")
        print(f"  æœ€å¤šçº¿æ®µæ•°: {max(lines_per_image)}")
        print(f"  æœ€å°‘çº¿æ®µæ•°: {min(lines_per_image)}")
        
        return total_images, total_lines, lines_per_image
        
    def convert_to_yolo_format(self):
        """è½¬æ¢ä¸ºYOLOæ ¼å¼"""
        print("\n=== è½¬æ¢ä¸ºYOLOæ ¼å¼ ===")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, "images"), exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, "labels"), exist_ok=True)
        
        # è·å–æ‰€æœ‰æ ‡æ³¨æ–‡ä»¶
        annotation_files = glob.glob(os.path.join(self.annotations_dir, "*_annotations.json"))
        
        converted_count = 0
        
        for ann_file in annotation_files:
            try:
                with open(ann_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                image_path = data.get('image_path', '')
                if not image_path or not os.path.exists(image_path):
                    print(f"  âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                    continue
                
                # è¯»å–å›¾åƒè·å–å°ºå¯¸
                image = cv2.imread(image_path)
                if image is None:
                    print(f"  âŒ æ— æ³•è¯»å–å›¾åƒ: {image_path}")
                    continue
                
                height, width = image.shape[:2]
                
                # ç”ŸæˆYOLOæ ‡ç­¾æ–‡ä»¶
                image_name = os.path.basename(image_path)
                label_name = image_name.replace('.jpg', '.txt').replace('.png', '.txt')
                label_path = os.path.join(self.output_dir, "labels", label_name)
                
                yolo_lines = []
                annotations = data.get('annotations', [])
                
                for ann in annotations:
                    if ann['type'] == 'blind_path_line':
                        start = ann['start']
                        end = ann['end']
                        
                        # è®¡ç®—çº¿æ®µä¸­ç‚¹ä½œä¸ºç›®æ ‡ç‚¹
                        center_x = (start[0] + end[0]) / 2
                        center_y = (start[1] + end[1]) / 2
                        
                        # è®¡ç®—çº¿æ®µé•¿åº¦ä½œä¸ºç›®æ ‡å¤§å°
                        length = np.sqrt((end[0] - start[0])**2 + (end[1] - start[1])**2)
                        
                        # è½¬æ¢ä¸ºYOLOæ ¼å¼ (x_center, y_center, width, height) å½’ä¸€åŒ–
                        x_center = center_x / width
                        y_center = center_y / height
                        w = min(length / width, 1.0)  # å®½åº¦å½’ä¸€åŒ–
                        h = min(length / height, 1.0)  # é«˜åº¦å½’ä¸€åŒ–
                        
                        # ç±»åˆ«ID: 0 = ç›²é“çº¿æ®µ
                        yolo_lines.append(f"0 {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}")
                
                # ä¿å­˜YOLOæ ‡ç­¾æ–‡ä»¶
                with open(label_path, 'w') as f:
                    f.write('\n'.join(yolo_lines))
                
                # å¤åˆ¶å›¾åƒæ–‡ä»¶
                output_image_path = os.path.join(self.output_dir, "images", image_name)
                cv2.imwrite(output_image_path, image)
                
                converted_count += 1
                print(f"  âœ… {image_name}: {len(yolo_lines)} ä¸ªç›®æ ‡")
                
            except Exception as e:
                print(f"  âŒ è½¬æ¢ {ann_file} å¤±è´¥: {e}")
        
        print(f"\nâœ… è½¬æ¢å®Œæˆ: {converted_count} ä¸ªæ–‡ä»¶")
        return converted_count
        
    def create_dataset_config(self):
        """åˆ›å»ºæ•°æ®é›†é…ç½®æ–‡ä»¶"""
        print("\n=== åˆ›å»ºæ•°æ®é›†é…ç½® ===")
        
        # åˆ›å»ºYOLOæ•°æ®é›†é…ç½®æ–‡ä»¶
        config_content = """# YOLOç›²é“æ£€æµ‹æ•°æ®é›†é…ç½®
path: ./yolo_dataset  # æ•°æ®é›†æ ¹ç›®å½•
train: images  # è®­ç»ƒå›¾åƒç›®å½•
val: images    # éªŒè¯å›¾åƒç›®å½•

# ç±»åˆ«æ•°é‡å’Œåç§°
nc: 1  # ç±»åˆ«æ•°é‡
names: ['blind_path']  # ç±»åˆ«åç§°

# æ•°æ®é›†ä¿¡æ¯
# ç›²é“æ£€æµ‹æ•°æ®é›†
# åŒ…å«ç›²é“çº¿æ®µæ ‡æ³¨
"""
        
        config_path = os.path.join(self.output_dir, "dataset.yaml")
        with open(config_path, 'w', encoding='utf-8') as f:
            f.write(config_content)
        
        print(f"âœ… é…ç½®æ–‡ä»¶å·²åˆ›å»º: {config_path}")
        
    def create_training_script(self):
        """åˆ›å»ºè®­ç»ƒè„šæœ¬"""
        print("\n=== åˆ›å»ºè®­ç»ƒè„šæœ¬ ===")
        
        script_content = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›²é“æ£€æµ‹YOLOv8è®­ç»ƒè„šæœ¬
"""

from ultralytics import YOLO
import os

def train_blind_path_detector():
    """è®­ç»ƒç›²é“æ£€æµ‹æ¨¡å‹"""
    
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    model = YOLO('yolov8n.pt')  # ä½¿ç”¨YOLOv8 nanoæ¨¡å‹
    
    # è®­ç»ƒå‚æ•°
    results = model.train(
        data='yolo_dataset/dataset.yaml',  # æ•°æ®é›†é…ç½®æ–‡ä»¶
        epochs=100,                        # è®­ç»ƒè½®æ•°
        imgsz=640,                         # å›¾åƒå°ºå¯¸
        batch=16,                          # æ‰¹æ¬¡å¤§å°
        name='blind_path_detector',        # å®éªŒåç§°
        patience=20,                       # æ—©åœè€å¿ƒå€¼
        save=True,                         # ä¿å­˜æ¨¡å‹
        device='auto'                      # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
    )
    
    print("è®­ç»ƒå®Œæˆï¼")
    return results

if __name__ == "__main__":
    train_blind_path_detector()
'''
        
        script_path = "train_blind_path.py"
        with open(script_path, 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        print(f"âœ… è®­ç»ƒè„šæœ¬å·²åˆ›å»º: {script_path}")
        
    def run_full_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸš€ å¼€å§‹ç›²é“æ ‡æ³¨æ•°æ®åˆ†æ...")
        
        # 1. åˆ†ææ ‡æ³¨æ•°æ®
        total_images, total_lines, lines_per_image = self.analyze_annotations()
        
        # 2. è½¬æ¢ä¸ºYOLOæ ¼å¼
        converted_count = self.convert_to_yolo_format()
        
        # 3. åˆ›å»ºæ•°æ®é›†é…ç½®
        self.create_dataset_config()
        
        # 4. åˆ›å»ºè®­ç»ƒè„šæœ¬
        self.create_training_script()
        
        print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")
        print(f"ğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
        print(f"  - å›¾åƒæ•°é‡: {total_images}")
        print(f"  - æ ‡æ³¨çº¿æ®µ: {total_lines}")
        print(f"  - è½¬æ¢æˆåŠŸ: {converted_count}")
        print(f"\nğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"ğŸ“„ è®­ç»ƒè„šæœ¬: train_blind_path.py")
        print(f"\nğŸš€ ä¸‹ä¸€æ­¥: è¿è¡Œ python train_blind_path.py å¼€å§‹è®­ç»ƒ")

def main():
    analyzer = BlindPathDataAnalyzer()
    analyzer.run_full_analysis()

if __name__ == "__main__":
    main() 