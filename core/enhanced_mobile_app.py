# -*- coding: utf-8 -*-
"""
ç›²é“éšœç¢æ£€æµ‹ç§»åŠ¨ç«¯åº”ç”¨ - å¢å¼ºç‰ˆ
é›†æˆYOLOv8æ£€æµ‹ + è½¨è¿¹é¢„æµ‹ + æ™ºèƒ½è¯­éŸ³é¢„è­¦
æ”¯æŒç›²é“è¯†åˆ«ã€åŠ¨æ€éšœç¢ç‰©è·Ÿè¸ªå’Œè½¨è¿¹é¢„æµ‹
"""

import sys
import os
import cv2
import numpy as np
import json
import threading
import time
from PyQt5.QtWidgets import *
from PyQt5.QtCore import *
from PyQt5.QtGui import *
from PyQt5.QtMultimedia import QMediaPlayer, QMediaContent
from PyQt5.QtCore import QUrl
import requests
import base64
import tempfile
import uuid
from collections import deque
import math

# å¯¼å…¥è½¨è¿¹é¢„æµ‹æ¨¡å—
try:
    from trajectory_predictor import TrajectoryPredictor
    TRAJECTORY_PREDICTOR_AVAILABLE = True
    print("âœ… è½¨è¿¹é¢„æµ‹æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError:
    TRAJECTORY_PREDICTOR_AVAILABLE = False
    print("âš ï¸ è½¨è¿¹é¢„æµ‹æ¨¡å—å¯¼å…¥å¤±è´¥")

# å¯¼å…¥è¯­éŸ³åº“
try:
    from voice_library import VoiceLibrary
    VOICE_LIBRARY_AVAILABLE = True
    print("âœ… è¯­éŸ³åº“å¯¼å…¥æˆåŠŸ")
except ImportError:
    VOICE_LIBRARY_AVAILABLE = False
    print("âš ï¸ è¯­éŸ³åº“å¯¼å…¥å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤è¯­éŸ³æç¤º")

# å¯¼å…¥YOLO
try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
    print("âœ… YOLOå¯¼å…¥æˆåŠŸ")
except ImportError:
    YOLO_AVAILABLE = False
    print("âŒ YOLOå¯¼å…¥å¤±è´¥")

class BaiduTTS:
    """ç™¾åº¦è¯­éŸ³åˆæˆ"""
    
    def __init__(self, app_id, api_key, secret_key):
        self.app_id = app_id
        self.api_key = api_key
        self.secret_key = secret_key
        self.access_token = None
        self.token_expire_time = 0
        
    def get_access_token(self):
        """è·å–è®¿é—®ä»¤ç‰Œ"""
        if self.access_token and time.time() < self.token_expire_time:
            return self.access_token
            
        url = "https://aip.baidubce.com/oauth/2.0/token"
        params = {
            "grant_type": "client_credentials",
            "client_id": self.api_key,
            "client_secret": self.secret_key
        }
        
        try:
            response = requests.post(url, params=params)
            result = response.json()
            
            if "access_token" in result:
                self.access_token = result["access_token"]
                self.token_expire_time = time.time() + result["expires_in"] - 60
                print("âœ… ç™¾åº¦è¯­éŸ³ä»¤ç‰Œè·å–æˆåŠŸ")
                return self.access_token
            else:
                print(f"âŒ è·å–ç™¾åº¦è¯­éŸ³ä»¤ç‰Œå¤±è´¥: {result}")
                return None
        except Exception as e:
            print(f"âŒ è·å–ç™¾åº¦è¯­éŸ³ä»¤ç‰Œå¼‚å¸¸: {e}")
            return None
    
    def text_to_speech(self, text, output_file=None):
        """æ–‡æœ¬è½¬è¯­éŸ³"""
        token = self.get_access_token()
        if not token:
            return False
            
        url = "https://tsn.baidu.com/text2audio"
        
        data = {
            "tex": text,
            "tok": token,
            "cuid": "blind_road_detector",
            "ctp": "1",
            "lan": "zh",
            "spd": "5",
            "pit": "5",
            "vol": "5",
            "per": "0"
        }
        
        try:
            response = requests.post(url, data=data)
            
            if response.status_code == 200 and response.headers.get('Content-Type', '').startswith('audio'):
                if output_file:
                    with open(output_file, 'wb') as f:
                        f.write(response.content)
                    print(f"âœ… è¯­éŸ³æ–‡ä»¶ä¿å­˜: {output_file}")
                return True
            else:
                print(f"âŒ è¯­éŸ³åˆæˆå¤±è´¥: {response.text}")
                return False
        except Exception as e:
            print(f"âŒ è¯­éŸ³åˆæˆå¼‚å¸¸: {e}")
            return False

class SimpleVoiceSystem:
    """ç®€åŒ–è¯­éŸ³ç³»ç»Ÿ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œæ”¯æŒè¿ç»­å®Œæ•´æ’­æŠ¥"""
    
    def __init__(self):
        self.media_player = None
        self.baidu_tts = None
        self.voice_enabled = True
        self.last_speech_time = 0
        self.speech_cooldown = 1.0  # å‡å°‘å†·å´æ—¶é—´
        
        # è¯­éŸ³é˜Ÿåˆ—ç®¡ç†
        self.voice_queue = []
        self.is_playing = False
        self.voice_lock = threading.Lock()
        
        self.init_media_player()
        self.init_baidu_tts()
        
        # å¯åŠ¨è¯­éŸ³å¤„ç†çº¿ç¨‹
        self.start_voice_processor()
    
    def init_media_player(self):
        """åˆå§‹åŒ–åª’ä½“æ’­æ”¾å™¨"""
        try:
            self.media_player = QMediaPlayer()
            print("âœ… åª’ä½“æ’­æ”¾å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ åª’ä½“æ’­æ”¾å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def init_baidu_tts(self):
        """åˆå§‹åŒ–ç™¾åº¦TTS"""
        try:
            # ä»é…ç½®æ–‡ä»¶è¯»å–ç™¾åº¦è¯­éŸ³é…ç½®
            if os.path.exists("voice_config.json"):
                with open("voice_config.json", 'r', encoding='utf-8') as f:
                    config = json.load(f)
                
                baidu_config = config.get('baidu_tts', {})
                app_id = baidu_config.get('app_id')
                api_key = baidu_config.get('api_key')
                secret_key = baidu_config.get('secret_key')
                
                if app_id and api_key and secret_key:
                    self.baidu_tts = BaiduTTS(app_id, api_key, secret_key)
                    print("âœ… ç™¾åº¦TTSåˆå§‹åŒ–æˆåŠŸ")
                else:
                    print("âš ï¸ ç™¾åº¦TTSé…ç½®ä¸å®Œæ•´")
            else:
                print("âš ï¸ è¯­éŸ³é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
        except Exception as e:
            print(f"âŒ ç™¾åº¦TTSåˆå§‹åŒ–å¤±è´¥: {e}")
    
    def start_voice_processor(self):
        """å¯åŠ¨è¯­éŸ³å¤„ç†çº¿ç¨‹"""
        def voice_processor():
            while True:
                try:
                    with self.voice_lock:
                        if self.voice_queue and not self.is_playing:
                            text = self.voice_queue.pop(0)
                            self.is_playing = True
                        else:
                            text = None
                    
                    if text:
                        self.execute_speech(text)
                        with self.voice_lock:
                            self.is_playing = False
                    else:
                        time.sleep(0.1)  # çŸ­æš‚ç­‰å¾…
                        
                except Exception as e:
                    print(f"âš ï¸ è¯­éŸ³å¤„ç†çº¿ç¨‹é”™è¯¯: {e}")
                    with self.voice_lock:
                        self.is_playing = False
        
        voice_thread = threading.Thread(target=voice_processor, daemon=True)
        voice_thread.start()
        print("âœ… è¯­éŸ³å¤„ç†çº¿ç¨‹å·²å¯åŠ¨")
    
    def speak(self, text, priority=1):
        """æ’­æ”¾è¯­éŸ³ - æ”¯æŒä¼˜å…ˆçº§å’Œé˜Ÿåˆ—ç®¡ç†"""
        if not self.voice_enabled:
            return
        
        # æ£€æŸ¥å†·å´æ—¶é—´ï¼ˆæ ¹æ®ä¼˜å…ˆçº§è°ƒæ•´ï¼‰
        current_time = time.time()
        cooldown = 0.5 if priority >= 3 else 1.0
        if current_time - self.last_speech_time < cooldown:
            return
        
        self.last_speech_time = current_time
        
        print(f"ğŸ”Š è¯­éŸ³æ’­æŠ¥ (ä¼˜å…ˆçº§{priority}): {text}")
        
        # æ·»åŠ åˆ°è¯­éŸ³é˜Ÿåˆ—
        with self.voice_lock:
            if priority >= 3:
                # é«˜ä¼˜å…ˆçº§ï¼Œæ’å…¥åˆ°é˜Ÿåˆ—å‰é¢
                self.voice_queue.insert(0, text)
            else:
                # æ™®é€šä¼˜å…ˆçº§ï¼Œæ·»åŠ åˆ°é˜Ÿåˆ—æœ«å°¾
                self.voice_queue.append(text)
    
    def execute_speech(self, text):
        """æ‰§è¡Œè¯­éŸ³æ’­æŠ¥"""
        try:
            if self.baidu_tts:
                # ä½¿ç”¨ç™¾åº¦TTS
                temp_file = tempfile.NamedTemporaryFile(suffix='.mp3', delete=False)
                temp_file.close()
                
                if self.baidu_tts.text_to_speech(text, temp_file.name):
                    self.play_audio(temp_file.name)
                    # å»¶è¿Ÿåˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    threading.Timer(5.0, lambda: os.unlink(temp_file.name) if os.path.exists(temp_file.name) else None).start()
                else:
                    print(f"âš ï¸ ä½¿ç”¨é»˜è®¤è¯­éŸ³æç¤º: {text}")
            else:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨pyttsx3
                try:
                    import pyttsx3
                    tts = pyttsx3.init()
                    tts.setProperty('rate', 150)
                    tts.say(text)
                    tts.runAndWait()
                    tts.stop()
                    print(f"âœ… å¤‡ç”¨è¯­éŸ³æ’­æŠ¥æˆåŠŸ: {text}")
                except Exception as e:
                    print(f"âš ï¸ å¤‡ç”¨è¯­éŸ³æ’­æŠ¥å¤±è´¥: {e}")
        except Exception as e:
            print(f"âŒ è¯­éŸ³æ’­æ”¾å¤±è´¥: {e}")
    
    def play_audio(self, audio_file):
        """æ’­æ”¾éŸ³é¢‘æ–‡ä»¶"""
        try:
            if self.media_player:
                url = QUrl.fromLocalFile(audio_file)
                content = QMediaContent(url)
                self.media_player.setMedia(content)
                self.media_player.play()
                print(f"âœ… éŸ³é¢‘æ’­æ”¾æˆåŠŸ: {audio_file}")
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ’­æ”¾å¤±è´¥: {e}")

class EnhancedMobileDetectWindow(QMainWindow):
    """å¢å¼ºç‰ˆç§»åŠ¨ç«¯æ£€æµ‹çª—å£"""
    
    def __init__(self):
        super().__init__()
        self.camera = None
        self.timer = QTimer()
        self.voice_system = SimpleVoiceSystem()
        self.trajectory_predictor = None
        self.yolo_model = None
        self.detection_history = deque(maxlen=100)
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.init_models()
        self.init_ui()
        
        # è¿æ¥ä¿¡å·
        self.timer.timeout.connect(self.update_frame)
    
    def init_models(self):
        """åˆå§‹åŒ–æ£€æµ‹å’Œè·Ÿè¸ªæ¨¡å‹"""
        print("ğŸ”§ åˆå§‹åŒ–æ¨¡å‹...")
        
        # åˆå§‹åŒ–YOLOæ£€æµ‹æ¨¡å‹
        if YOLO_AVAILABLE:
            try:
                # ä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹
                if os.path.exists("runs/detect/train5/weights/best.pt"):
                    self.yolo_model = YOLO("runs/detect/train5/weights/best.pt")
                    print("âœ… åŠ è½½è‡ªå®šä¹‰YOLOæ¨¡å‹")
                elif os.path.exists("yolov8n.pt"):
                    self.yolo_model = YOLO("yolov8n.pt")
                    print("âœ… åŠ è½½é»˜è®¤YOLOæ¨¡å‹")
                else:
                    print("âŒ æœªæ‰¾åˆ°YOLOæ¨¡å‹æ–‡ä»¶")
                    self.yolo_model = None
            except Exception as e:
                print(f"âŒ YOLOæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                self.yolo_model = None
        else:
            self.yolo_model = None
        
        # åˆå§‹åŒ–è½¨è¿¹é¢„æµ‹å™¨
        if TRAJECTORY_PREDICTOR_AVAILABLE:
            self.trajectory_predictor = TrajectoryPredictor()
            print("âœ… è½¨è¿¹é¢„æµ‹å™¨åˆå§‹åŒ–æˆåŠŸ")
        else:
            self.trajectory_predictor = None
            print("âš ï¸ è½¨è¿¹é¢„æµ‹å™¨ä¸å¯ç”¨")
    
    def init_ui(self):
        """åˆå§‹åŒ–ç”¨æˆ·ç•Œé¢"""
        self.setWindowTitle("ç›²é“éšœç¢æ£€æµ‹ - å¢å¼ºç‰ˆ (è½¨è¿¹é¢„æµ‹)")
        self.setGeometry(100, 100, 1000, 700)
        
        # åˆ›å»ºä¸­å¤®éƒ¨ä»¶
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        # åˆ›å»ºä¸»å¸ƒå±€
        main_layout = QHBoxLayout(central_widget)
        
        # å·¦ä¾§è§†é¢‘å’Œæ§åˆ¶åŒºåŸŸ
        left_panel = QVBoxLayout()
        
        # è§†é¢‘æ˜¾ç¤ºåŒºåŸŸ
        self.video_label = QLabel()
        self.video_label.setMinimumSize(640, 480)
        self.video_label.setStyleSheet("border: 2px solid gray; background-color: black;")
        self.video_label.setAlignment(Qt.AlignCenter)
        self.video_label.setText("ç‚¹å‡»å¼€å§‹æ£€æµ‹")
        left_panel.addWidget(self.video_label)
        
        # æ§åˆ¶æŒ‰é’®åŒºåŸŸ
        button_layout = QHBoxLayout()
        
        self.start_button = QPushButton("å¼€å§‹æ£€æµ‹")
        self.start_button.clicked.connect(self.toggle_camera)
        button_layout.addWidget(self.start_button)
        
        self.voice_button = QPushButton("è¯­éŸ³å¼€å…³")
        self.voice_button.setCheckable(True)
        self.voice_button.setChecked(True)
        self.voice_button.clicked.connect(self.toggle_voice)
        button_layout.addWidget(self.voice_button)
        
        self.test_voice_button = QPushButton("æµ‹è¯•è¯­éŸ³")
        self.test_voice_button.clicked.connect(self.test_voice)
        button_layout.addWidget(self.test_voice_button)
        
        left_panel.addLayout(button_layout)
        
        # çŠ¶æ€æ˜¾ç¤ºåŒºåŸŸ
        self.status_label = QLabel("çŠ¶æ€: å°±ç»ª")
        self.status_label.setStyleSheet("color: green; font-weight: bold;")
        left_panel.addWidget(self.status_label)
        
        main_layout.addLayout(left_panel)
        
        # å³ä¾§ä¿¡æ¯æ˜¾ç¤ºåŒºåŸŸ
        right_panel = QVBoxLayout()
        
        # è·Ÿè¸ªä¿¡æ¯æ˜¾ç¤º
        self.tracking_label = QLabel("è·Ÿè¸ªç›®æ ‡: 0")
        self.tracking_label.setStyleSheet("color: blue; font-weight: bold;")
        right_panel.addWidget(self.tracking_label)
        
        # ç›²é“ä¿¡æ¯æ˜¾ç¤º
        self.blind_path_label = QLabel("ç›²é“çŠ¶æ€: æœªæ£€æµ‹")
        self.blind_path_label.setStyleSheet("color: orange; font-weight: bold;")
        right_panel.addWidget(self.blind_path_label)
        
        # ç¢°æ’é£é™©æ˜¾ç¤º
        self.risk_label = QLabel("ç¢°æ’é£é™©: ä½")
        self.risk_label.setStyleSheet("color: green; font-weight: bold;")
        right_panel.addWidget(self.risk_label)
        
        # è­¦å‘Šä¿¡æ¯æ˜¾ç¤ºåŒºåŸŸ
        self.warning_text = QTextEdit()
        self.warning_text.setMaximumHeight(150)
        self.warning_text.setStyleSheet("background-color: #f0f0f0; border: 1px solid #ccc;")
        self.warning_text.setReadOnly(True)
        right_panel.addWidget(QLabel("è­¦å‘Šä¿¡æ¯:"))
        right_panel.addWidget(self.warning_text)
        
        # ç¯å¢ƒå®‰å…¨ä¿¡æ¯æ˜¾ç¤º
        self.environment_label = QLabel("ç¯å¢ƒå®‰å…¨: è‰¯å¥½")
        self.environment_label.setStyleSheet("color: green; font-weight: bold;")
        right_panel.addWidget(self.environment_label)
        
        # å®‰å…¨è¯„åˆ†æ˜¾ç¤º
        self.safety_score_label = QLabel("å®‰å…¨è¯„åˆ†: 100%")
        self.safety_score_label.setStyleSheet("color: green; font-weight: bold;")
        right_panel.addWidget(self.safety_score_label)
        
        # å¤©æ°”ä¿¡æ¯æ˜¾ç¤º
        self.weather_label = QLabel("å¤©æ°”æ¡ä»¶: æ™´æœ—")
        self.weather_label.setStyleSheet("color: blue; font-weight: bold;")
        right_panel.addWidget(self.weather_label)
        
        # å…‰ç…§ä¿¡æ¯æ˜¾ç¤º
        self.lighting_label = QLabel("å…‰ç…§æ¡ä»¶: æ­£å¸¸")
        self.lighting_label.setStyleSheet("color: blue; font-weight: bold;")
        right_panel.addWidget(self.lighting_label)
        
        # è·¯é¢ä¿¡æ¯æ˜¾ç¤º
        self.surface_label = QLabel("è·¯é¢æ¡ä»¶: å¹³æ•´")
        self.surface_label.setStyleSheet("color: blue; font-weight: bold;")
        right_panel.addWidget(self.surface_label)
        
        # å®‰å…¨æŒ‡å¯¼æ˜¾ç¤º
        self.guidance_label = QLabel("å®‰å…¨æŒ‡å¯¼: ç¯å¢ƒå®‰å…¨ï¼Œå¯ä»¥æ­£å¸¸å‰è¿›")
        self.guidance_label.setStyleSheet("color: green; font-weight: bold;")
        self.guidance_label.setWordWrap(True)
        right_panel.addWidget(self.guidance_label)
        
        main_layout.addLayout(right_panel)
    
    def toggle_camera(self):
        """åˆ‡æ¢æ‘„åƒå¤´çŠ¶æ€"""
        if self.camera is None or not self.camera.isOpened():
            self.start_camera()
        else:
            self.stop_camera()
    
    def toggle_voice(self):
        """åˆ‡æ¢è¯­éŸ³å¼€å…³"""
        self.voice_system.voice_enabled = self.voice_button.isChecked()
        status = "å¼€å¯" if self.voice_system.voice_enabled else "å…³é—­"
        self.status_label.setText(f"çŠ¶æ€: è¯­éŸ³{status}")
    
    def start_camera(self):
        """å¯åŠ¨æ‘„åƒå¤´"""
        try:
            self.camera = cv2.VideoCapture(0)
            if self.camera.isOpened():
                self.start_button.setText("åœæ­¢æ£€æµ‹")
                self.status_label.setText("çŠ¶æ€: æ£€æµ‹ä¸­")
                self.timer.start(30)  # 30msé—´éš”ï¼Œçº¦33FPS
                print("âœ… æ‘„åƒå¤´å¯åŠ¨æˆåŠŸ")
            else:
                print("âŒ æ‘„åƒå¤´å¯åŠ¨å¤±è´¥")
                self.status_label.setText("çŠ¶æ€: æ‘„åƒå¤´å¯åŠ¨å¤±è´¥")
        except Exception as e:
            print(f"âŒ æ‘„åƒå¤´å¯åŠ¨å¼‚å¸¸: {e}")
            self.status_label.setText("çŠ¶æ€: æ‘„åƒå¤´å¯åŠ¨å¼‚å¸¸")
    
    def stop_camera(self):
        """åœæ­¢æ‘„åƒå¤´"""
        self.timer.stop()
        if self.camera:
            self.camera.release()
            self.camera = None
        self.start_button.setText("å¼€å§‹æ£€æµ‹")
        self.status_label.setText("çŠ¶æ€: å·²åœæ­¢")
        self.video_label.setText("ç‚¹å‡»å¼€å§‹æ£€æµ‹")
        print("âœ… æ‘„åƒå¤´å·²åœæ­¢")
    
    def update_frame(self):
        """æ›´æ–°è§†é¢‘å¸§"""
        if not self.camera or not self.camera.isOpened():
            return
        
        ret, frame = self.camera.read()
        if not ret:
            return
        
        # è°ƒæ•´å¸§å¤§å°
        frame = cv2.resize(frame, (640, 480))
        
        # æ‰§è¡Œæ£€æµ‹å’Œè½¨è¿¹é¢„æµ‹
        processed_frame = self.process_frame(frame)
        
        # è½¬æ¢ä¸ºQtæ ¼å¼å¹¶æ˜¾ç¤º
        rgb_frame = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)
        h, w, ch = rgb_frame.shape
        bytes_per_line = ch * w
        qt_image = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(qt_image)
        self.video_label.setPixmap(pixmap.scaled(self.video_label.size(), Qt.KeepAspectRatio))
    
    def process_frame(self, frame):
        """å¤„ç†è§†é¢‘å¸§ï¼šæ£€æµ‹ + è½¨è¿¹é¢„æµ‹ + é¢„è­¦"""
        if not self.yolo_model or not self.trajectory_predictor:
            return frame
        
        try:
            # Step 1: YOLOv8æ£€æµ‹
            results = self.yolo_model(frame, stream=True)
            detections = []
            
            for result in results:
                if result.boxes is not None:
                    boxes = result.boxes.xyxy.cpu().numpy()
                    confs = result.boxes.conf.cpu().numpy()
                    clss = result.boxes.cls.cpu().numpy()
                    
                    for box, conf, cls in zip(boxes, confs, clss):
                        if conf > 0.5:  # ç½®ä¿¡åº¦é˜ˆå€¼
                            x1, y1, x2, y2 = box
                            detections.append([x1, y1, x2, y2, conf, int(cls)])
            
            # Step 2: è½¨è¿¹é¢„æµ‹å¤„ç†
            prediction_result = self.trajectory_predictor.process_frame(frame, detections)
            
            # Step 3: ç»˜åˆ¶æ£€æµ‹ç»“æœå’Œè½¨è¿¹
            frame = self.draw_detections_and_trajectories(frame, detections, prediction_result)
            
            # Step 4: æ›´æ–°UIä¿¡æ¯
            self.update_ui_info(prediction_result)
            
            # Step 5: å¤„ç†è­¦å‘Šå’Œè¯­éŸ³æç¤º
            self.handle_warnings(prediction_result)
            
        except Exception as e:
            print(f"âŒ å¸§å¤„ç†å¼‚å¸¸: {e}")
        
        return frame
    
    def draw_detections_and_trajectories(self, frame, detections, prediction_result):
        """ç»˜åˆ¶æ£€æµ‹ç»“æœå’Œè½¨è¿¹"""
        # ç»˜åˆ¶æ£€æµ‹æ¡†
        for detection in detections:
            x1, y1, x2, y2, conf, cls = detection
            color = self.get_class_color(cls)
            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
            
            # æ·»åŠ æ ‡ç­¾
            label = f"{self.get_class_name(cls)} {conf:.2f}"
            cv2.putText(frame, label, (int(x1), int(y1)-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # ç»˜åˆ¶ç›²é“ä¿¡æ¯
        if prediction_result.get('blind_path'):
            blind_path = prediction_result['blind_path']
            center = blind_path['center']
            width = blind_path['width']
            height = blind_path['height']
            confidence = blind_path['confidence']
            
            # ç»˜åˆ¶ç›²é“è½®å»“
            if 'contour' in blind_path:
                cv2.drawContours(frame, [blind_path['contour']], -1, (0, 255, 255), 2)
            
            # ç»˜åˆ¶ç›²é“ä¸­å¿ƒçº¿
            cv2.circle(frame, center, 5, (0, 255, 255), -1)
            cv2.putText(frame, f"ç›²é“ {confidence:.2f}", (center[0]-50, center[1]-20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
            
            # ç»˜åˆ¶é¢„æµ‹è½¨è¿¹
            if 'predicted_trajectory' in blind_path:
                predicted_points = blind_path['predicted_trajectory']
                for i, point in enumerate(predicted_points):
                    color = (255, 255, 0) if i == len(predicted_points) - 1 else (100, 100, 100)
                    cv2.circle(frame, point, 3, color, -1)
        
        # ç»˜åˆ¶è·Ÿè¸ªç›®æ ‡å’Œè½¨è¿¹
        tracked_objects = prediction_result.get('tracked_objects', [])
        for obj in tracked_objects:
            track_id = obj['id']
            centroid = obj['centroid']
            class_id = obj.get('class_id', 0)
            
            # ç»˜åˆ¶è·Ÿè¸ªæ¡†
            x1, y1 = centroid[0] - 25, centroid[1] - 25
            x2, y2 = centroid[0] + 25, centroid[1] + 25
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, f"ID:{track_id}", (x1, y1-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            
            # ç»˜åˆ¶å†å²è½¨è¿¹
            if 'trajectory' in obj and len(obj['trajectory']) > 1:
                trajectory = obj['trajectory']
                for i in range(1, len(trajectory)):
                    cv2.line(frame, trajectory[i-1], trajectory[i], (0, 255, 255), 2)
            
            # ç»˜åˆ¶é¢„æµ‹è½¨è¿¹
            if 'predicted_trajectory' in obj:
                predicted_points = obj['predicted_trajectory']
                for i, point in enumerate(predicted_points):
                    color = (255, 0, 0) if i == len(predicted_points) - 1 else (100, 100, 100)
                    cv2.circle(frame, point, 3, color, -1)
        
        # ç»˜åˆ¶ç”¨æˆ·ä½ç½®ï¼ˆå¸§ä¸­å¿ƒï¼‰
        user_pos = (320, 240)
        cv2.circle(frame, user_pos, 10, (255, 255, 255), -1)
        cv2.putText(frame, "ç”¨æˆ·", (user_pos[0]-20, user_pos[1]+25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        return frame
    
    def update_ui_info(self, prediction_result):
        """æ›´æ–°UIä¿¡æ¯"""
        # æ›´æ–°è·Ÿè¸ªç›®æ ‡æ•°é‡
        tracked_objects = prediction_result.get('tracked_objects', [])
        self.tracking_label.setText(f"è·Ÿè¸ªç›®æ ‡: {len(tracked_objects)}")
        
        # æ›´æ–°ç›²é“çŠ¶æ€
        blind_path = prediction_result.get('blind_path')
        if blind_path:
            confidence = blind_path.get('confidence', 0)
            self.blind_path_label.setText(f"ç›²é“çŠ¶æ€: å·²æ£€æµ‹ (ç½®ä¿¡åº¦: {confidence:.2f})")
            self.blind_path_label.setStyleSheet("color: green; font-weight: bold;")
        else:
            self.blind_path_label.setText("ç›²é“çŠ¶æ€: æœªæ£€æµ‹")
            self.blind_path_label.setStyleSheet("color: red; font-weight: bold;")
        
        # æ›´æ–°ç¢°æ’é£é™©
        collision_risks = prediction_result.get('collision_risks', {})
        if collision_risks:
            max_risk = max(collision_risks.values()) if collision_risks else 0
            if max_risk > 0.7:
                self.risk_label.setText(f"ç¢°æ’é£é™©: é«˜ ({max_risk:.2f})")
                self.risk_label.setStyleSheet("color: red; font-weight: bold;")
            elif max_risk > 0.3:
                self.risk_label.setText(f"ç¢°æ’é£é™©: ä¸­ ({max_risk:.2f})")
                self.risk_label.setStyleSheet("color: orange; font-weight: bold;")
            else:
                self.risk_label.setText(f"ç¢°æ’é£é™©: ä½ ({max_risk:.2f})")
                self.risk_label.setStyleSheet("color: green; font-weight: bold;")
        else:
            self.risk_label.setText("ç¢°æ’é£é™©: ä½")
            self.risk_label.setStyleSheet("color: green; font-weight: bold;")
        
        # æ›´æ–°ç¯å¢ƒå®‰å…¨ä¿¡æ¯
        self.update_environment_info(prediction_result)
        
        # æ›´æ–°å®‰å…¨æŒ‡å¯¼
        if self.trajectory_predictor:
            guidance = self.trajectory_predictor.get_safety_guidance()
            self.guidance_label.setText(f"å®‰å…¨æŒ‡å¯¼: {guidance}")
            
            # æ ¹æ®æŒ‡å¯¼å†…å®¹è®¾ç½®é¢œè‰²
            if "ç´§æ€¥" in guidance or "å±é™©" in guidance:
                self.guidance_label.setStyleSheet("color: red; font-weight: bold;")
            elif "æ³¨æ„" in guidance:
                self.guidance_label.setStyleSheet("color: orange; font-weight: bold;")
            else:
                self.guidance_label.setStyleSheet("color: green; font-weight: bold;")
    
    def update_environment_info(self, prediction_result):
        """æ›´æ–°ç¯å¢ƒå®‰å…¨ä¿¡æ¯æ˜¾ç¤º"""
        # æ›´æ–°ç¯å¢ƒå®‰å…¨ç­‰çº§
        safety_level = prediction_result.get('overall_safety_level', 'safe')
        safety_score = prediction_result.get('safety_score', 1.0)
        
        if safety_level == 'high_risk':
            self.environment_label.setText("ç¯å¢ƒå®‰å…¨: é«˜é£é™©")
            self.environment_label.setStyleSheet("color: red; font-weight: bold;")
        elif safety_level == 'medium_risk':
            self.environment_label.setText("ç¯å¢ƒå®‰å…¨: ä¸­ç­‰é£é™©")
            self.environment_label.setStyleSheet("color: orange; font-weight: bold;")
        else:
            self.environment_label.setText("ç¯å¢ƒå®‰å…¨: è‰¯å¥½")
            self.environment_label.setStyleSheet("color: green; font-weight: bold;")
        
        # æ›´æ–°å®‰å…¨è¯„åˆ†
        score_percentage = int(safety_score * 100)
        self.safety_score_label.setText(f"å®‰å…¨è¯„åˆ†: {score_percentage}%")
        
        if score_percentage < 30:
            self.safety_score_label.setStyleSheet("color: red; font-weight: bold;")
        elif score_percentage < 60:
            self.safety_score_label.setStyleSheet("color: orange; font-weight: bold;")
        else:
            self.safety_score_label.setStyleSheet("color: green; font-weight: bold;")
        
        # æ›´æ–°å¤©æ°”ä¿¡æ¯
        weather_info = prediction_result.get('weather_info')
        if weather_info:
            weather_type = weather_info.get('weather_type', 'clear')
            visibility = weather_info.get('visibility_level', 'good')
            self.weather_label.setText(f"å¤©æ°”æ¡ä»¶: {weather_type} ({visibility})")
            
            if weather_info.get('safety_impact') == 'very_high':
                self.weather_label.setStyleSheet("color: red; font-weight: bold;")
            elif weather_info.get('safety_impact') == 'high':
                self.weather_label.setStyleSheet("color: orange; font-weight: bold;")
            else:
                self.weather_label.setStyleSheet("color: blue; font-weight: bold;")
        else:
            self.weather_label.setText("å¤©æ°”æ¡ä»¶: æ™´æœ—")
            self.weather_label.setStyleSheet("color: blue; font-weight: bold;")
        
        # æ›´æ–°å…‰ç…§ä¿¡æ¯
        lighting_info = prediction_result.get('lighting_info')
        if lighting_info:
            lighting_level = lighting_info.get('lighting_level', 'normal')
            visibility_quality = lighting_info.get('visibility_quality', 'good')
            self.lighting_label.setText(f"å…‰ç…§æ¡ä»¶: {lighting_level} ({visibility_quality})")
            
            if lighting_info.get('safety_impact') == 'very_high':
                self.lighting_label.setStyleSheet("color: red; font-weight: bold;")
            elif lighting_info.get('safety_impact') == 'high':
                self.lighting_label.setStyleSheet("color: orange; font-weight: bold;")
            else:
                self.lighting_label.setStyleSheet("color: blue; font-weight: bold;")
        else:
            self.lighting_label.setText("å…‰ç…§æ¡ä»¶: æ­£å¸¸")
            self.lighting_label.setStyleSheet("color: blue; font-weight: bold;")
        
        # æ›´æ–°è·¯é¢ä¿¡æ¯
        surface_info = prediction_result.get('surface_info')
        if surface_info:
            surface_type = surface_info.get('surface_type', 'smooth')
            safety_level = surface_info.get('safety_level', 'safe')
            self.surface_label.setText(f"è·¯é¢æ¡ä»¶: {surface_type} ({safety_level})")
            
            if surface_info.get('safety_level') == 'caution':
                self.surface_label.setStyleSheet("color: orange; font-weight: bold;")
            elif surface_info.get('safety_level') == 'moderate':
                self.surface_label.setStyleSheet("color: blue; font-weight: bold;")
            else:
                self.surface_label.setStyleSheet("color: green; font-weight: bold;")
        else:
            self.surface_label.setText("è·¯é¢æ¡ä»¶: å¹³æ•´")
            self.surface_label.setStyleSheet("color: green; font-weight: bold;")
    
    def handle_warnings(self, prediction_result):
        """å¤„ç†è­¦å‘Šå’Œè¯­éŸ³æç¤º"""
        warnings = prediction_result.get('warnings', [])
        emergency_alerts = prediction_result.get('emergency_alerts', [])
        
        # æ›´æ–°è­¦å‘Šæ–‡æœ¬
        all_warnings = warnings + emergency_alerts
        if all_warnings:
            warning_text = "\n".join(all_warnings)
            self.warning_text.append(f"[{time.strftime('%H:%M:%S')}] {warning_text}")
            
            # è¯­éŸ³æ’­æŠ¥ç¬¬ä¸€ä¸ªè­¦å‘Šï¼ˆä¼˜å…ˆç´§æ€¥è­¦æŠ¥ï¼‰
            if all_warnings and self.voice_system.voice_enabled:
                priority_warning = emergency_alerts[0] if emergency_alerts else warnings[0]
                self.voice_system.speak(priority_warning, priority=3 if emergency_alerts else 1)
        
        # æ»šåŠ¨åˆ°åº•éƒ¨
        self.warning_text.verticalScrollBar().setValue(
            self.warning_text.verticalScrollBar().maximum()
        )
    
    def get_class_color(self, cls):
        """è·å–ç±»åˆ«é¢œè‰²"""
        colors = [
            (255, 0, 0),    # çº¢è‰² - äºº
            (0, 255, 0),    # ç»¿è‰² - è½¦
            (0, 0, 255),    # è“è‰² - å…¶ä»–
            (255, 255, 0),  # é»„è‰²
            (255, 0, 255),  # ç´«è‰²
        ]
        return colors[cls % len(colors)]
    
    def get_class_name(self, cls):
        """è·å–ç±»åˆ«åç§°"""
        names = ["äºº", "è½¦", "éšœç¢ç‰©", "å‘æ´¼", "å…¶ä»–"]
        return names[cls % len(names)]
    
    def test_voice(self):
        """æµ‹è¯•è¯­éŸ³"""
        self.voice_system.speak("è½¨è¿¹é¢„æµ‹ç³»ç»Ÿæµ‹è¯•æ­£å¸¸")
    
    def closeEvent(self, event):
        """å…³é—­äº‹ä»¶"""
        self.stop_camera()
        event.accept()

def main():
    """ä¸»å‡½æ•°"""
    app = QApplication(sys.argv)
    
    # è®¾ç½®åº”ç”¨æ ·å¼
    app.setStyle('Fusion')
    
    # åˆ›å»ºä¸»çª—å£
    window = EnhancedMobileDetectWindow()
    window.show()
    
    # è¿è¡Œåº”ç”¨
    sys.exit(app.exec_())

if __name__ == "__main__":
    main() 