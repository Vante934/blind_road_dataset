#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é›†æˆéšœç¢ç‰©æ£€æµ‹å’Œé¢„æµ‹ç³»ç»Ÿ
ç»“åˆYOLOæ£€æµ‹ã€è½¨è¿¹é¢„æµ‹å’Œé£é™©è¯„ä¼°
"""

import cv2
import numpy as np
import time
from typing import Dict, List, Tuple, Optional
from ultralytics import YOLO
from modules.dynamic_obstacle_predictor import DynamicObstaclePredictor, Prediction
from modules.trajectory_predictor import TrajectoryPredictor

class IntegratedObstacleSystem:
    """é›†æˆéšœç¢ç‰©æ£€æµ‹å’Œé¢„æµ‹ç³»ç»Ÿ"""
    
    def __init__(self, 
                 model_path: str = "models/yolo11n.pt",
                 confidence_threshold: float = 0.5,
                 nms_threshold: float = 0.4):
        
        # åˆå§‹åŒ–YOLOæ¨¡å‹
        self.model = YOLO(model_path)
        self.confidence_threshold = confidence_threshold
        self.nms_threshold = nms_threshold
        
        # åˆå§‹åŒ–åŠ¨æ€éšœç¢ç‰©é¢„æµ‹å™¨
        self.obstacle_predictor = DynamicObstaclePredictor(
            prediction_horizon=3.0,
            time_step=0.1,
            collision_threshold=100.0,
            velocity_threshold=5.0
        )
        
        # åˆå§‹åŒ–è½¨è¿¹é¢„æµ‹å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            self.trajectory_predictor = TrajectoryPredictor()
            self.trajectory_available = True
        except:
            self.trajectory_predictor = None
            self.trajectory_available = False
        
        # ç”¨æˆ·ä½ç½®è·Ÿè¸ª
        self.user_position = None
        self.user_trajectory = []
        
        # ç³»ç»ŸçŠ¶æ€
        self.is_running = False
        self.frame_count = 0
        
    def detect_obstacles(self, frame: np.ndarray) -> List[Dict]:
        """æ£€æµ‹éšœç¢ç‰©"""
        # ä½¿ç”¨YOLOè¿›è¡Œç›®æ ‡æ£€æµ‹
        results = self.model(frame, conf=self.confidence_threshold, iou=self.nms_threshold)
        
        detections = []
        for result in results:
            if result.boxes is not None:
                for box in result.boxes:
                    # è·å–è¾¹ç•Œæ¡†åæ ‡
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
                    
                    # è·å–ç½®ä¿¡åº¦å’Œç±»åˆ«
                    confidence = box.conf[0].cpu().numpy()
                    class_id = int(box.cls[0].cpu().numpy())
                    class_name = self.model.names[class_id]
                    
                    # è¿‡æ»¤æ‰ä¸éœ€è¦çš„ç±»åˆ«
                    if class_name in ['person', 'car', 'truck', 'bus', 'bicycle', 'motorcycle']:
                        detections.append({
                            'bbox': (x1, y1, x2, y2),
                            'class_name': class_name,
                            'confidence': float(confidence),
                            'class_id': class_id
                        })
        
        return detections
    
    def update_user_position(self, position: Tuple[float, float]):
        """æ›´æ–°ç”¨æˆ·ä½ç½®"""
        self.user_position = position
        self.user_trajectory.append((position, time.time()))
        
        # ä¿æŒè½¨è¿¹å†å²é•¿åº¦
        if len(self.user_trajectory) > 100:
            self.user_trajectory = self.user_trajectory[-100:]
    
    def process_frame(self, frame: np.ndarray) -> Dict:
        """å¤„ç†å•å¸§å›¾åƒ"""
        self.frame_count += 1
        start_time = time.time()
        
        # 1. æ£€æµ‹éšœç¢ç‰©
        detections = self.detect_obstacles(frame)
        
        # 2. æ›´æ–°éšœç¢ç‰©è·Ÿè¸ª
        obstacles = self.obstacle_predictor.update_obstacles(detections)
        
        # 3. é¢„æµ‹éšœç¢ç‰©è½¨è¿¹
        predictions = self.obstacle_predictor.predict_obstacle_trajectories(self.user_position)
        
        # 4. è®¡ç®—å¤„ç†æ—¶é—´
        processing_time = time.time() - start_time
        
        # 5. ç”Ÿæˆè­¦å‘Šä¿¡æ¯
        warnings = self._generate_warnings(predictions)
        
        # 6. è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = self.obstacle_predictor.get_obstacle_statistics()
        
        return {
            'detections': detections,
            'obstacles': obstacles,
            'predictions': predictions,
            'warnings': warnings,
            'statistics': stats,
            'processing_time': processing_time,
            'frame_count': self.frame_count
        }
    
    def _generate_warnings(self, predictions: List[Prediction]) -> List[str]:
        """ç”Ÿæˆè­¦å‘Šä¿¡æ¯"""
        warnings = []
        
        for prediction in predictions:
            if prediction.collision_risk > 0.8:
                warnings.append(f"ğŸš¨ ç´§æ€¥è­¦å‘Šï¼šéšœç¢ç‰©ID {prediction.obstacle_id} é«˜é£é™©ç¢°æ’ï¼")
            elif prediction.collision_risk > 0.5:
                warnings.append(f"âš ï¸ æ³¨æ„ï¼šéšœç¢ç‰©ID {prediction.obstacle_id} ä¸­ç­‰é£é™©")
            
            if prediction.time_to_collision and prediction.time_to_collision < 2.0:
                warnings.append(f"â° ç¢°æ’å€’è®¡æ—¶ï¼š{prediction.time_to_collision:.1f}ç§’")
        
        return warnings
    
    def visualize_results(self, frame: np.ndarray, results: Dict) -> np.ndarray:
        """å¯è§†åŒ–æ£€æµ‹å’Œé¢„æµ‹ç»“æœ"""
        vis_frame = frame.copy()
        
        # ç»˜åˆ¶æ£€æµ‹æ¡†
        for detection in results['detections']:
            x1, y1, x2, y2 = detection['bbox']
            class_name = detection['class_name']
            confidence = detection['confidence']
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            color = self._get_class_color(class_name)
            cv2.rectangle(vis_frame, (x1, y1), (x2, y2), color, 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{class_name}: {confidence:.2f}"
            cv2.putText(vis_frame, label, (x1, y1 - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        # ç»˜åˆ¶é¢„æµ‹è½¨è¿¹
        vis_frame = self.obstacle_predictor.visualize_predictions(vis_frame, results['predictions'])
        
        # ç»˜åˆ¶ç”¨æˆ·ä½ç½®
        if self.user_position:
            cv2.circle(vis_frame, (int(self.user_position[0]), int(self.user_position[1])), 
                      10, (255, 0, 0), -1)
            cv2.putText(vis_frame, "User", 
                       (int(self.user_position[0]) + 15, int(self.user_position[1])), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
        
        # ç»˜åˆ¶è­¦å‘Šä¿¡æ¯
        y_offset = 30
        for warning in results['warnings']:
            cv2.putText(vis_frame, warning, (10, y_offset), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            y_offset += 25
        
        # ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯
        stats_text = f"éšœç¢ç‰©: {results['statistics']['total_obstacles']} | " \
                    f"è¿åŠ¨: {results['statistics']['moving_obstacles']} | " \
                    f"å¤„ç†æ—¶é—´: {results['processing_time']*1000:.1f}ms"
        cv2.putText(vis_frame, stats_text, (10, vis_frame.shape[0] - 20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        return vis_frame
    
    def _get_class_color(self, class_name: str) -> Tuple[int, int, int]:
        """è·å–ç±»åˆ«å¯¹åº”çš„é¢œè‰²"""
        colors = {
            'person': (0, 255, 0),      # ç»¿è‰²
            'car': (255, 0, 0),        # è“è‰²
            'truck': (0, 0, 255),      # çº¢è‰²
            'bus': (0, 255, 255),      # é»„è‰²
            'bicycle': (255, 0, 255),  # ç´«è‰²
            'motorcycle': (255, 255, 0) # é’è‰²
        }
        return colors.get(class_name, (128, 128, 128))
    
    def get_system_status(self) -> Dict:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        return {
            'is_running': self.is_running,
            'frame_count': self.frame_count,
            'user_position': self.user_position,
            'trajectory_available': self.trajectory_available,
            'model_loaded': self.model is not None,
            'obstacle_predictor_ready': self.obstacle_predictor is not None
        }
    
    def start_system(self):
        """å¯åŠ¨ç³»ç»Ÿ"""
        self.is_running = True
        self.frame_count = 0
        print("ğŸš€ é›†æˆéšœç¢ç‰©æ£€æµ‹ç³»ç»Ÿå·²å¯åŠ¨")
    
    def stop_system(self):
        """åœæ­¢ç³»ç»Ÿ"""
        self.is_running = False
        print("â¹ï¸ é›†æˆéšœç¢ç‰©æ£€æµ‹ç³»ç»Ÿå·²åœæ­¢")
    
    def reset_system(self):
        """é‡ç½®ç³»ç»Ÿ"""
        self.obstacle_predictor = DynamicObstaclePredictor()
        self.user_position = None
        self.user_trajectory = []
        self.frame_count = 0
        print("ğŸ”„ ç³»ç»Ÿå·²é‡ç½®")


class ObstacleDetectionGUI:
    """éšœç¢ç‰©æ£€æµ‹GUIç•Œé¢"""
    
    def __init__(self):
        self.system = IntegratedObstacleSystem()
        self.cap = None
        self.is_running = False
        
    def start_camera(self, camera_id: int = 0):
        """å¯åŠ¨æ‘„åƒå¤´"""
        self.cap = cv2.VideoCapture(camera_id)
        if not self.cap.isOpened():
            raise Exception(f"æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {camera_id}")
        
        self.system.start_system()
        self.is_running = True
        
        print(f"ğŸ“¹ æ‘„åƒå¤´ {camera_id} å·²å¯åŠ¨")
    
    def process_camera_feed(self):
        """å¤„ç†æ‘„åƒå¤´æ•°æ®æµ"""
        if not self.cap or not self.cap.isOpened():
            return None
        
        ret, frame = self.cap.read()
        if not ret:
            return None
        
        # å¤„ç†å¸§
        results = self.system.process_frame(frame)
        
        # å¯è§†åŒ–ç»“æœ
        vis_frame = self.system.visualize_results(frame, results)
        
        return vis_frame, results
    
    def stop_camera(self):
        """åœæ­¢æ‘„åƒå¤´"""
        if self.cap:
            self.cap.release()
        self.system.stop_system()
        self.is_running = False
        print("ğŸ“¹ æ‘„åƒå¤´å·²åœæ­¢")
    
    def update_user_position(self, x: int, y: int):
        """æ›´æ–°ç”¨æˆ·ä½ç½®ï¼ˆé¼ æ ‡ç‚¹å‡»ï¼‰"""
        self.system.update_user_position((float(x), float(y)))
        print(f"ğŸ“ ç”¨æˆ·ä½ç½®æ›´æ–°: ({x}, {y})")


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    gui = ObstacleDetectionGUI()
    
    try:
        # å¯åŠ¨æ‘„åƒå¤´
        gui.start_camera(0)
        
        while True:
            # å¤„ç†æ‘„åƒå¤´æ•°æ®
            result = gui.process_camera_feed()
            if result is None:
                break
            
            vis_frame, results = result
            
            # æ˜¾ç¤ºç»“æœ
            cv2.imshow('Dynamic Obstacle Detection', vis_frame)
            
            # å¤„ç†é”®ç›˜è¾“å…¥
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('r'):
                gui.system.reset_system()
            elif key == ord('s'):
                # ä¿å­˜å½“å‰å¸§
                cv2.imwrite(f'frame_{gui.system.frame_count}.jpg', vis_frame)
                print(f"ğŸ’¾ ä¿å­˜å¸§: frame_{gui.system.frame_count}.jpg")
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
    finally:
        gui.stop_camera()
        cv2.destroyAllWindows()

