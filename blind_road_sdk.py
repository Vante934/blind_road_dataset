#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›²é“éšœç¢æ£€æµ‹SDK - æµ‹è¯•ç‰ˆ
é›†æˆæ‰€æœ‰åŠŸèƒ½ï¼šæ£€æµ‹ã€é¢„æµ‹ã€è¯­éŸ³ã€æ ‡æ³¨ã€è®­ç»ƒ
"""

import os
import sys
import cv2
import numpy as np
import json
import time
import threading
import tempfile
import uuid
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any, Callable
from collections import deque
import math

# ==================== ä¾èµ–æ£€æŸ¥ ====================
def check_dependencies():
    """æ£€æŸ¥æ‰€æœ‰ä¾èµ–"""
    dependencies = {
        'ultralytics': 'pip install ultralytics',
        'torch': 'pip install torch',
        'opencv-python': 'pip install opencv-python',
        'numpy': 'pip install numpy',
        'requests': 'pip install requests',
        'PyQt5': 'pip install PyQt5'
    }
    
    missing = []
    for dep, install_cmd in dependencies.items():
        try:
            __import__(dep)
            print(f"âœ… {dep} å·²å®‰è£…")
        except ImportError:
            print(f"âŒ {dep} æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: {install_cmd}")
            missing.append(dep)
    
    return len(missing) == 0

# ==================== æ ¸å¿ƒæ£€æµ‹æ¨¡å— ====================
class BlindRoadDetector:
    """ç›²é“æ£€æµ‹æ ¸å¿ƒæ¨¡å—"""
    
    def __init__(self, model_path: str = "models/yolov8n.pt"):
        self.model_path = model_path
        self.model = None
        self.is_initialized = False
        self.detection_history = deque(maxlen=100)
        
    def initialize(self) -> bool:
        """åˆå§‹åŒ–æ£€æµ‹æ¨¡å‹"""
        try:
            from ultralytics import YOLO
            
            if os.path.exists(self.model_path):
                self.model = YOLO(self.model_path)
            else:
                print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹")
                self.model = YOLO('yolov8n.pt')
            
            self.is_initialized = True
            print("âœ… ç›²é“æ£€æµ‹æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def detect(self, frame: np.ndarray, conf_threshold: float = 0.5) -> List[Dict]:
        """æ‰§è¡Œæ£€æµ‹"""
        if not self.is_initialized:
            if not self.initialize():
                return []
        
        try:
            results = self.model(frame, conf=conf_threshold, verbose=False)
            
            detections = []
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        conf = box.conf[0].cpu().numpy()
                        cls = int(box.cls[0].cpu().numpy())
                        
                        detections.append({
                            'bbox': [int(x1), int(y1), int(x2), int(y2)],
                            'confidence': float(conf),
                            'class_id': cls,
                            'class_name': self.get_class_name(cls)
                        })
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            self.detection_history.append({
                'timestamp': time.time(),
                'detections': detections
            })
            
            return detections
            
        except Exception as e:
            print(f"âŒ æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def get_class_name(self, class_id: int) -> str:
        """è·å–ç±»åˆ«åç§°"""
        class_names = {
            0: "person", 1: "bicycle", 2: "car", 3: "motorcycle",
            4: "airplane", 5: "bus", 6: "train", 7: "truck",
            8: "boat", 9: "traffic light", 10: "fire hydrant"
        }
        return class_names.get(class_id, f"unknown_{class_id}")

# ==================== è½¨è¿¹é¢„æµ‹æ¨¡å— ====================
class TrajectoryPredictor:
    """è½¨è¿¹é¢„æµ‹æ¨¡å—"""
    
    def __init__(self):
        self.tracked_objects = {}
        self.path_history = deque(maxlen=50)
        self.user_position = (320, 240)
        
    def update_user_position(self, position: Tuple[int, int]):
        """æ›´æ–°ç”¨æˆ·ä½ç½®"""
        self.user_position = position
    
    def track_objects(self, detections: List[Dict]) -> List[Dict]:
        """è·Ÿè¸ªæ£€æµ‹åˆ°çš„ç‰©ä½“"""
        current_time = time.time()
        tracked = []
        
        for detection in detections:
            bbox = detection['bbox']
            center = ((bbox[0] + bbox[2]) // 2, (bbox[1] + bbox[3]) // 2)
            
            object_id = detection.get('object_id', len(self.tracked_objects))
            
            if object_id not in self.tracked_objects:
                self.tracked_objects[object_id] = {
                    'history': deque(maxlen=10),
                    'class_id': detection['class_id'],
                    'class_name': detection['class_name']
                }
            
            self.tracked_objects[object_id]['history'].append({
                'position': center,
                'timestamp': current_time,
                'bbox': bbox
            })
            
            tracked.append({
                'object_id': object_id,
                'position': center,
                'bbox': bbox,
                'class_id': detection['class_id'],
                'class_name': detection['class_name'],
                'velocity': self.calculate_velocity(object_id)
            })
        
        return tracked
    
    def calculate_velocity(self, object_id: int) -> Tuple[float, float]:
        """è®¡ç®—ç‰©ä½“é€Ÿåº¦"""
        if object_id not in self.tracked_objects:
            return (0.0, 0.0)
        
        history = self.tracked_objects[object_id]['history']
        if len(history) < 2:
            return (0.0, 0.0)
        
        pos1 = history[-1]['position']
        pos2 = history[-2]['position']
        time_diff = history[-1]['timestamp'] - history[-2]['timestamp']
        
        if time_diff > 0:
            vx = (pos1[0] - pos2[0]) / time_diff
            vy = (pos1[1] - pos2[1]) / time_diff
            return (vx, vy)
        
        return (0.0, 0.0)
    
    def predict_collision_risk(self, tracked_objects: List[Dict]) -> Dict[int, float]:
        """é¢„æµ‹ç¢°æ’é£é™©"""
        risks = {}
        
        for obj in tracked_objects:
            object_id = obj['object_id']
            position = obj['position']
            velocity = obj['velocity']
            
            distance = math.sqrt((position[0] - self.user_position[0])**2 + 
                               (position[1] - self.user_position[1])**2)
            
            if distance < 100:
                risk = max(0.0, 1.0 - distance / 100.0)
                speed = math.sqrt(velocity[0]**2 + velocity[1]**2)
                if speed > 10:
                    risk *= 1.5
                risks[object_id] = min(1.0, risk)
            else:
                risks[object_id] = 0.0
        
        return risks
    
    def generate_warnings(self, tracked_objects: List[Dict], collision_risks: Dict[int, float]) -> List[str]:
        """ç”Ÿæˆè­¦å‘Šä¿¡æ¯"""
        warnings = []
        
        for obj in tracked_objects:
            object_id = obj['object_id']
            risk = collision_risks.get(object_id, 0.0)
            
            if risk > 0.7:
                warnings.append(f"å±é™©ï¼{obj['class_name']}æ¥è¿‘ï¼Œé£é™©ç­‰çº§ï¼š{risk:.2f}")
            elif risk > 0.3:
                warnings.append(f"æ³¨æ„ï¼{obj['class_name']}åœ¨é™„è¿‘ï¼Œé£é™©ç­‰çº§ï¼š{risk:.2f}")
        
        return warnings

# ==================== è¯­éŸ³ç³»ç»Ÿæ¨¡å— ====================
class VoiceSystem:
    """è¯­éŸ³ç³»ç»Ÿæ¨¡å—"""
    
    def __init__(self, config_file: str = "configs/voice_config.json"):
        self.config_file = config_file
        self.is_enabled = True
        self.volume = 0.8
        self.rate = 1.0
        self.voice_config = self.load_voice_config()
        self._init_voice_engine()
        
    def load_voice_config(self) -> Dict:
        """åŠ è½½è¯­éŸ³é…ç½®"""
        try:
            if os.path.exists(self.config_file):
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"âš ï¸ åŠ è½½è¯­éŸ³é…ç½®å¤±è´¥: {e}")
        
        return {
            'obstacle_types': {
                'person': {'name': 'è¡Œäºº', 'priority': 'high'},
                'car': {'name': 'è½¦è¾†', 'priority': 'high'},
                'bicycle': {'name': 'è‡ªè¡Œè½¦', 'priority': 'medium'},
                'pothole': {'name': 'å‘æ´', 'priority': 'high'},
                'construction': {'name': 'æ–½å·¥åŒºåŸŸ', 'priority': 'high'}
            },
            'warning_templates': {
                'high_risk': 'å±é™©ï¼{object_name}æ¥è¿‘ï¼Œè¯·ç«‹å³åœæ­¢ï¼',
                'medium_risk': 'æ³¨æ„ï¼{object_name}åœ¨é™„è¿‘ï¼Œè¯·å‡é€Ÿ',
                'low_risk': 'å‰æ–¹æœ‰{object_name}ï¼Œè¯·æ³¨æ„'
            }
        }
    
    def generate_message(self, class_name: str, risk_level: float) -> str:
        """ç”Ÿæˆè¯­éŸ³æ¶ˆæ¯"""
        obstacle_info = self.voice_config['obstacle_types'].get(class_name, {'name': class_name})
        object_name = obstacle_info['name']
        
        if risk_level > 0.7:
            template = self.voice_config['warning_templates']['high_risk']
        elif risk_level > 0.3:
            template = self.voice_config['warning_templates']['medium_risk']
        else:
            template = self.voice_config['warning_templates']['low_risk']
        
        return template.format(object_name=object_name)
    
    def _init_voice_engine(self):
        """åˆå§‹åŒ–è¯­éŸ³å¼•æ“"""
        try:
            import pyttsx3
            self.tts_engine = pyttsx3.init()
            
            # è®¾ç½®ä¸­æ–‡è¯­éŸ³
            voices = self.tts_engine.getProperty('voices')
            for voice in voices:
                if 'chinese' in voice.name.lower() or 'zh' in voice.id.lower():
                    self.tts_engine.setProperty('voice', voice.id)
                    break
            
            self.tts_engine.setProperty('rate', int(150 * self.rate))
            self.tts_engine.setProperty('volume', self.volume)
            print("âœ… è¯­éŸ³å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âš ï¸ è¯­éŸ³å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
            self.tts_engine = None
    
    def speak(self, message: str):
        """æ’­æ”¾è¯­éŸ³ï¼ˆç¨³å®šç‰ˆï¼‰"""
        if not self.is_enabled:
            return
        
        try:
            # ä¼˜å…ˆä½¿ç”¨pyttsx3ï¼ˆæœ€ç¨³å®šï¼‰
            if self.tts_engine:
                self.tts_engine.setProperty('rate', int(150 * self.rate))
                self.tts_engine.setProperty('volume', self.volume)
                self.tts_engine.say(message)
                self.tts_engine.runAndWait()
                return
            
            # é™çº§åˆ°æ§åˆ¶å°è¾“å‡º
            print(f"ğŸ”Š è¯­éŸ³æ’­æŠ¥: {message}")
            
        except Exception as e:
            print(f"âŒ è¯­éŸ³æ’­æ”¾å¤±è´¥: {e}")
            print(f"ğŸ”Š è¯­éŸ³æ’­æŠ¥: {message}")
    
    
    def enable(self):
        """å¯ç”¨è¯­éŸ³"""
        self.is_enabled = True
        print("âœ… è¯­éŸ³ç³»ç»Ÿå·²å¯ç”¨")
    
    def disable(self):
        """ç¦ç”¨è¯­éŸ³"""
        self.is_enabled = False
        print("ğŸ”‡ è¯­éŸ³ç³»ç»Ÿå·²ç¦ç”¨")
    
    def set_volume(self, volume: float):
        """è®¾ç½®éŸ³é‡"""
        self.volume = max(0.0, min(1.0, volume))
        print(f"ğŸ”Š éŸ³é‡è®¾ç½®ä¸º: {self.volume:.1f}")
    
    def set_rate(self, rate: float):
        """è®¾ç½®è¯­é€Ÿ"""
        self.rate = max(0.5, min(2.0, rate))
        print(f"âš¡ è¯­é€Ÿè®¾ç½®ä¸º: {self.rate:.1f}")

# ==================== æ ‡æ³¨å·¥å…·æ¨¡å— ====================
class AnnotationTool:
    """æ ‡æ³¨å·¥å…·æ¨¡å—"""
    
    def __init__(self):
        self.annotations = []
        self.current_image = None
        self.annotation_file = None
        
    def load_image(self, image_path: str) -> bool:
        """åŠ è½½å›¾åƒ"""
        try:
            self.current_image = cv2.imread(image_path)
            if self.current_image is None:
                return False
            
            image_name = os.path.splitext(os.path.basename(image_path))[0]
            self.annotation_file = f"data/annotations/{image_name}_annotations.json"
            
            self.load_annotations()
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½å›¾åƒå¤±è´¥: {e}")
            return False
    
    def load_annotations(self):
        """åŠ è½½ç°æœ‰æ ‡æ³¨"""
        if os.path.exists(self.annotation_file):
            try:
                with open(self.annotation_file, 'r', encoding='utf-8') as f:
                    self.annotations = json.load(f)
                print(f"âœ… åŠ è½½æ ‡æ³¨æ–‡ä»¶: {self.annotation_file}")
            except Exception as e:
                print(f"âš ï¸ åŠ è½½æ ‡æ³¨å¤±è´¥: {e}")
                self.annotations = []
        else:
            self.annotations = []
    
    def add_annotation(self, x1: int, y1: int, x2: int, y2: int, class_name: str = "obstacle"):
        """æ·»åŠ æ ‡æ³¨"""
        annotation = {
            'id': len(self.annotations),
            'bbox': [x1, y1, x2, y2],
            'class_name': class_name,
            'timestamp': time.time()
        }
        self.annotations.append(annotation)
        print(f"âœ… æ·»åŠ æ ‡æ³¨: {class_name} at ({x1}, {y1}, {x2}, {y2})")
    
    def save_annotations(self) -> bool:
        """ä¿å­˜æ ‡æ³¨"""
        if not self.annotation_file:
            return False
        
        try:
            os.makedirs(os.path.dirname(self.annotation_file), exist_ok=True)
            with open(self.annotation_file, 'w', encoding='utf-8') as f:
                json.dump(self.annotations, f, ensure_ascii=False, indent=2)
            print(f"âœ… ä¿å­˜æ ‡æ³¨åˆ°: {self.annotation_file}")
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜æ ‡æ³¨å¤±è´¥: {e}")
            return False

# ==================== è®­ç»ƒæ¨¡å— ====================
class ModelTrainer:
    """æ¨¡å‹è®­ç»ƒæ¨¡å—"""
    
    def __init__(self):
        self.training_config = {
            'model': 'yolov8n.pt',
            'data': 'data/yolo_dataset/dataset.yaml',
            'epochs': 100,
            'batch_size': 16,
            'imgsz': 640,
            'device': 'auto'
        }
        self.training_callback = None
        
    def set_training_callback(self, callback: Callable):
        """è®¾ç½®è®­ç»ƒå›è°ƒå‡½æ•°"""
        self.training_callback = callback
    
    def start_training(self, dataset_yaml: str = None, **kwargs) -> bool:
        """å¼€å§‹è®­ç»ƒ"""
        try:
            from ultralytics import YOLO
            
            config = self.training_config.copy()
            if dataset_yaml:
                config['data'] = dataset_yaml
            config.update(kwargs)
            
            print("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
            print(f"ğŸ“‹ è®­ç»ƒé…ç½®: {config}")
            
            model = YOLO(config['model'])
            
            results = model.train(
                data=config['data'],
                epochs=config['epochs'],
                batch=config['batch_size'],
                imgsz=config['imgsz'],
                device=config['device']
            )
            
            print("âœ… è®­ç»ƒå®Œæˆ")
            return True
            
        except Exception as e:
            print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
            return False
    
    def evaluate_model(self, model_path: str, test_data: str) -> Dict:
        """è¯„ä¼°æ¨¡å‹"""
        try:
            from ultralytics import YOLO
            
            model = YOLO(model_path)
            results = model.val(data=test_data)
            
            metrics = {
                'mAP50': results.box.map50,
                'mAP50-95': results.box.map,
                'precision': results.box.mp,
                'recall': results.box.mr
            }
            
            print(f"ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœ:")
            for metric, value in metrics.items():
                print(f"  - {metric}: {value:.4f}")
            
            return metrics
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
            return {}

# ==================== ä¸»SDKç±» ====================
class BlindRoadSDK:
    """ç›²é“éšœç¢æ£€æµ‹SDKä¸»ç±»"""
    
    def __init__(self):
        self.detector = BlindRoadDetector()
        self.trajectory_predictor = TrajectoryPredictor()
        self.voice_system = VoiceSystem()
        self.annotation_tool = AnnotationTool()
        self.model_trainer = ModelTrainer()
        
        self.is_initialized = False
        self.camera = None
        self.is_camera_active = False
        
    def initialize(self) -> bool:
        """åˆå§‹åŒ–SDK"""
        print("ğŸ”§ åˆå§‹åŒ–ç›²é“éšœç¢æ£€æµ‹SDK...")
        
        if not check_dependencies():
            print("âŒ ä¾èµ–æ£€æŸ¥å¤±è´¥")
            return False
        
        if not self.detector.initialize():
            print("âŒ æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥")
            return False
        
        self.is_initialized = True
        print("âœ… SDKåˆå§‹åŒ–æˆåŠŸ")
        return True
    
    def start_camera(self, camera_id: int = 0) -> bool:
        """å¯åŠ¨æ‘„åƒå¤´"""
        if not self.is_initialized:
            print("âŒ SDKæœªåˆå§‹åŒ–")
            return False
        
        try:
            self.camera = cv2.VideoCapture(camera_id)
            if not self.camera.isOpened():
                print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
                return False
            
            self.is_camera_active = True
            print("âœ… æ‘„åƒå¤´å¯åŠ¨æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ å¯åŠ¨æ‘„åƒå¤´å¤±è´¥: {e}")
            return False
    
    def stop_camera(self):
        """åœæ­¢æ‘„åƒå¤´"""
        if self.camera:
            self.camera.release()
        self.is_camera_active = False
        print("ğŸ›‘ æ‘„åƒå¤´å·²åœæ­¢")
    
    def process_frame(self, frame: np.ndarray) -> Dict:
        """å¤„ç†å•å¸§å›¾åƒ"""
        if not self.is_initialized:
            return {}
        
        detections = self.detector.detect(frame)
        tracked_objects = self.trajectory_predictor.track_objects(detections)
        collision_risks = self.trajectory_predictor.predict_collision_risk(tracked_objects)
        warnings = self.trajectory_predictor.generate_warnings(tracked_objects, collision_risks)
        
        for warning in warnings:
            self.voice_system.speak(warning)
        
        return {
            'detections': detections,
            'tracked_objects': tracked_objects,
            'collision_risks': collision_risks,
            'warnings': warnings
        }
    
    def get_camera_frame(self) -> Optional[np.ndarray]:
        """è·å–æ‘„åƒå¤´å¸§"""
        if not self.is_camera_active or not self.camera:
            return None
        
        ret, frame = self.camera.read()
        if ret:
            return frame
        return None
    
    def run_detection_loop(self, callback: Callable = None):
        """è¿è¡Œæ£€æµ‹å¾ªç¯"""
        if not self.is_camera_active:
            print("âŒ æ‘„åƒå¤´æœªå¯åŠ¨")
            return
        
        print("ğŸ”„ å¼€å§‹æ£€æµ‹å¾ªç¯...")
        
        try:
            while self.is_camera_active:
                frame = self.get_camera_frame()
                if frame is None:
                    continue
                
                result = self.process_frame(frame)
                
                if callback:
                    callback(frame, result)
                
                cv2.imshow('Blind Road Detection', frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
                    
        except KeyboardInterrupt:
            print("ğŸ›‘ æ£€æµ‹å¾ªç¯è¢«ä¸­æ–­")
        finally:
            cv2.destroyAllWindows()
            self.stop_camera()
    
    def train_model(self, dataset_path: str, **kwargs) -> bool:
        """è®­ç»ƒæ¨¡å‹"""
        print("ğŸ¯ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")
        return self.model_trainer.start_training(dataset_path, **kwargs)
    
    def evaluate_model(self, model_path: str, test_data: str) -> Dict:
        """è¯„ä¼°æ¨¡å‹"""
        return self.model_trainer.evaluate_model(model_path, test_data)
    
    def annotate_image(self, image_path: str) -> bool:
        """æ ‡æ³¨å›¾åƒ"""
        return self.annotation_tool.load_image(image_path)
    
    def add_annotation(self, x1: int, y1: int, x2: int, y2: int, class_name: str = "obstacle"):
        """æ·»åŠ æ ‡æ³¨"""
        self.annotation_tool.add_annotation(x1, y1, x2, y2, class_name)
    
    def save_annotations(self) -> bool:
        """ä¿å­˜æ ‡æ³¨"""
        return self.annotation_tool.save_annotations()
    
    def set_voice_enabled(self, enabled: bool):
        """è®¾ç½®è¯­éŸ³å¼€å…³"""
        if enabled:
            self.voice_system.enable()
        else:
            self.voice_system.disable()
    
    def set_voice_volume(self, volume: float):
        """è®¾ç½®è¯­éŸ³éŸ³é‡"""
        self.voice_system.set_volume(volume)
    
    def get_status(self) -> Dict:
        """è·å–SDKçŠ¶æ€"""
        return {
            'initialized': self.is_initialized,
            'camera_active': self.is_camera_active,
            'voice_enabled': self.voice_system.is_enabled,
            'voice_volume': self.voice_system.volume,
            'detection_count': len(self.detector.detection_history)
        }
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.stop_camera()
        print("ğŸ§¹ SDKèµ„æºå·²æ¸…ç†")

# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================
def example_usage():
    """ä½¿ç”¨ç¤ºä¾‹"""
    print("ğŸš€ ç›²é“éšœç¢æ£€æµ‹SDKä½¿ç”¨ç¤ºä¾‹")
    
    sdk = BlindRoadSDK()
    
    if not sdk.initialize():
        print("âŒ SDKåˆå§‹åŒ–å¤±è´¥")
        return
    
    sdk.set_voice_enabled(True)
    sdk.set_voice_volume(0.8)
    
    if sdk.start_camera():
        def detection_callback(frame, result):
            print(f"æ£€æµ‹åˆ° {len(result['detections'])} ä¸ªç‰©ä½“")
            if result['warnings']:
                print(f"è­¦å‘Š: {result['warnings']}")
        
        sdk.run_detection_loop(detection_callback)
    
    sdk.cleanup()

if __name__ == "__main__":
    example_usage() 