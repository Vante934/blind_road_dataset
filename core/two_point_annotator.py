#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸¤ç‚¹æ¨¡å¼å’Œæ‹–æ‹½æ¨¡å¼æ ‡æ³¨å·¥å…·
åŠŸèƒ½ï¼š
1. ä¸¤ç‚¹æ¨¡å¼ï¼šç‚¹å‡»ä¸¤ä¸ªç‚¹ï¼Œè‡ªåŠ¨ç”Ÿæˆç›´çº¿
2. æ‹–æ‹½æ¨¡å¼ï¼šç‚¹å‡»èµ·ç‚¹ï¼Œæ‹–æ‹½åˆ°ç»ˆç‚¹ï¼Œå½¢æˆç›´çº¿
3. æ‘„åƒå¤´å®æ—¶æ£€æµ‹å’Œè¯­éŸ³æ’­æŠ¥
4. è½¨è¿¹é¢„æµ‹ï¼šç›²é“è¯†åˆ« + åŠ¨æ€éšœç¢ç‰©è½¨è¿¹é¢„æµ‹ + ç¢°æ’é£é™©è¯„ä¼°
"""

import sys
import os
import cv2
import json
import time
import glob
import requests
import base64
import subprocess
import threading
import numpy as np
import math
from pathlib import Path
from collections import deque
from typing import Dict, List, Tuple, Optional

from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, 
                             QHBoxLayout, QPushButton, QLabel, QFileDialog, 
                             QMessageBox, QListWidget, QGroupBox, QSpinBox,
                             QFrame, QSplitter, QTextEdit, QListWidgetItem,
                             QShortcut, QDialog, QGridLayout, QProgressBar,
                             QComboBox, QSlider, QStatusBar, QCheckBox)
from PyQt5.QtCore import Qt, pyqtSignal, QPoint, QRect, QTimer, QThread
from PyQt5.QtGui import QPixmap, QImage, QMouseEvent, QPainter, QPen, QColor, QFont, QKeySequence

# å®‰å…¨å¯¼å…¥ï¼Œé˜²æ­¢ä¾èµ–ç¼ºå¤±å¯¼è‡´ç¨‹åºå´©æºƒ
print("æ­£åœ¨æ£€æŸ¥ä¾èµ–...")

try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
    print("âœ… ultralytics å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    YOLO_AVAILABLE = False
    print(f"âŒ ultralytics å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·è¿è¡Œ: pip install ultralytics")

try:
    from modules.trajectory_predictor import TrajectoryPredictor
    TRAJECTORY_PREDICTOR_AVAILABLE = True
    print("âœ… è½¨è¿¹é¢„æµ‹æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    TRAJECTORY_PREDICTOR_AVAILABLE = False
    print(f"âš ï¸ è½¨è¿¹é¢„æµ‹æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

try:
    import sys
    import os
    # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    parent_dir = os.path.dirname(current_dir)
    if parent_dir not in sys.path:
        sys.path.append(parent_dir)
    
    from modules.environment_detector import EnvironmentDetector
    ENVIRONMENT_DETECTOR_AVAILABLE = True
    print("âœ… ç¯å¢ƒæ£€æµ‹æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    ENVIRONMENT_DETECTOR_AVAILABLE = False
    print(f"âš ï¸ ç¯å¢ƒæ£€æµ‹æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

try:
    from modules.voice_library import VoiceLibrary
    VOICE_LIBRARY_AVAILABLE = True
    print("âœ… è¯­éŸ³åº“æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    VOICE_LIBRARY_AVAILABLE = False
    print(f"âš ï¸ è¯­éŸ³åº“æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

# ==================== è½¨è¿¹é¢„æµ‹æ¨¡å— ====================
class BlindPathDetector:
    """ç›²é“æ£€æµ‹å™¨"""
    
    def __init__(self):
        self.path_history = deque(maxlen=50)
        self.path_center = None
        self.path_width = 0
        self.confidence = 0.0
        
    def detect_blind_path(self, frame: np.ndarray) -> Dict:
        """æ£€æµ‹ç›²é“"""
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # åº”ç”¨é«˜æ–¯æ¨¡ç³Š
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # è¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(blurred, 50, 150)
        
        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # ç­›é€‰å¯èƒ½çš„ç›²é“è½®å»“
        blind_path_contours = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > 1000:  # é¢ç§¯é˜ˆå€¼
                # è®¡ç®—è½®å»“çš„è¾¹ç•ŒçŸ©å½¢
                x, y, w, h = cv2.boundingRect(contour)
                aspect_ratio = w / h if h > 0 else 0
                
                # ç›²é“é€šå¸¸æ˜¯é•¿æ¡å½¢çš„
                if aspect_ratio > 2.0 and w > 50:
                    blind_path_contours.append(contour)
        
        if blind_path_contours:
            # é€‰æ‹©æœ€å¤§çš„ç›²é“è½®å»“
            largest_contour = max(blind_path_contours, key=cv2.contourArea)
            x, y, w, h = cv2.boundingRect(largest_contour)
            
            # è®¡ç®—ç›²é“ä¸­å¿ƒ
            center_x = x + w // 2
            center_y = y + h // 2
            
            self.path_center = (center_x, center_y)
            self.path_width = w
            self.confidence = min(1.0, cv2.contourArea(largest_contour) / 10000)
            
            return {
                'center': (center_x, center_y),
                'width': w,
                'confidence': self.confidence,
                'detected': True
            }
        
        return {'detected': False, 'confidence': 0.0}
    
    def predict_path_trajectory(self, steps: int = 10) -> List[Tuple[int, int]]:
        """é¢„æµ‹ç›²é“è½¨è¿¹"""
        if len(self.path_history) < 3:
            return []
        
        # è·å–æœ€è¿‘çš„ä½ç½®ç‚¹
        recent_points = list(self.path_history)[-3:]
        
        # è®¡ç®—å¹³å‡é€Ÿåº¦
        if len(recent_points) >= 2:
            dx = recent_points[-1][0] - recent_points[0][0]
            dy = recent_points[-1][1] - recent_points[0][1]
            dt = recent_points[-1][2] - recent_points[0][2]
            
            if dt > 0:
                vx = dx / dt
                vy = dy / dt
                
                # é¢„æµ‹æœªæ¥ä½ç½®
                predicted_points = []
                current_point = (recent_points[-1][0], recent_points[-1][1])
                
                for i in range(1, steps + 1):
                    next_x = int(current_point[0] + vx * i * 0.1)  # 0.1ç§’é—´éš”
                    next_y = int(current_point[1] + vy * i * 0.1)
                    predicted_points.append((next_x, next_y))
                
                return predicted_points
        
        return []

class MotionPredictor:
    """è¿åŠ¨é¢„æµ‹å™¨"""
    
    def __init__(self, prediction_steps: int = 5):
        self.trajectories = {}  # object_id -> deque of (x, y, timestamp)
        self.prediction_steps = prediction_steps
        
    def update_trajectory(self, object_id: int, position: Tuple[int, int], timestamp: float):
        """æ›´æ–°ç‰©ä½“è½¨è¿¹"""
        if object_id not in self.trajectories:
            self.trajectories[object_id] = deque(maxlen=20)
        
        self.trajectories[object_id].append((position[0], position[1], timestamp))
    
    def predict_trajectory(self, object_id: int) -> List[Tuple[int, int]]:
        """é¢„æµ‹ç‰©ä½“è½¨è¿¹"""
        if object_id not in self.trajectories or len(self.trajectories[object_id]) < 3:
            return []
        
        trajectory = list(self.trajectories[object_id])
        
        # è®¡ç®—é€Ÿåº¦
        if len(trajectory) >= 2:
            dx = trajectory[-1][0] - trajectory[0][0]
            dy = trajectory[-1][1] - trajectory[0][1]
            dt = trajectory[-1][2] - trajectory[0][2]
            
            if dt > 0:
                vx = dx / dt
                vy = dy / dt
                
                # é¢„æµ‹æœªæ¥ä½ç½®
                predicted_points = []
                current_point = (trajectory[-1][0], trajectory[-1][1])
                
                for i in range(1, self.prediction_steps + 1):
                    next_x = int(current_point[0] + vx * i * 0.1)
                    next_y = int(current_point[1] + vy * i * 0.1)
                    predicted_points.append((next_x, next_y))
                
                return predicted_points
        
        return []
    
    def calculate_collision_risk(self, object_id: int, user_position: Tuple[int, int], 
                               prediction_steps: int = 5) -> float:
        """è®¡ç®—ç¢°æ’é£é™©"""
        predicted_trajectory = self.predict_trajectory(object_id)
        if not predicted_trajectory:
            return 0.0
        
        # è®¡ç®—é¢„æµ‹è½¨è¿¹ä¸ç”¨æˆ·ä½ç½®çš„æœ€å°è·ç¦»
        min_distance = float('inf')
        for point in predicted_trajectory:
            distance = math.sqrt((point[0] - user_position[0])**2 + (point[1] - user_position[1])**2)
            min_distance = min(min_distance, distance)
        
        # è·ç¦»è¶Šè¿‘ï¼Œé£é™©è¶Šé«˜
        if min_distance < 50:  # 50åƒç´ å†…ä¸ºé«˜é£é™©
            return 1.0
        elif min_distance < 100:  # 100åƒç´ å†…ä¸ºä¸­é£é™©
            return 0.5
        else:
            return 0.1

class EnhancedTracker:
    """å¢å¼ºè·Ÿè¸ªå™¨"""
    
    def __init__(self, max_disappeared: int = 30, max_distance: int = 50):
        self.next_object_id = 0
        self.objects = {}  # object_id -> (centroid, class_id, disappeared_count)
        self.max_disappeared = max_disappeared
        self.max_distance = max_distance
        
    def register(self, centroid: Tuple[int, int], class_id: int = 0):
        """æ³¨å†Œæ–°ç‰©ä½“"""
        self.objects[self.next_object_id] = (centroid, class_id, 0)
        self.next_object_id += 1
    
    def deregister(self, object_id: int):
        """æ³¨é”€ç‰©ä½“"""
        if object_id in self.objects:
            del self.objects[object_id]
    
    def update(self, detections: List[List]) -> List[Dict]:
        """æ›´æ–°è·Ÿè¸ªçŠ¶æ€"""
        if len(detections) == 0:
            # æ²¡æœ‰æ£€æµ‹åˆ°ç‰©ä½“ï¼Œå¢åŠ æ¶ˆå¤±è®¡æ•°
            for object_id in list(self.objects.keys()):
                centroid, class_id, disappeared = self.objects[object_id]
                disappeared += 1
                if disappeared > self.max_disappeared:
                    self.deregister(object_id)
                else:
                    self.objects[object_id] = (centroid, class_id, disappeared)
            return []
        
        # åˆå§‹åŒ–ç‰©ä½“ä¸­å¿ƒç‚¹æ•°ç»„
        input_centroids = []
        for detection in detections:
            centroid = self.get_centroid(detection)
            input_centroids.append(centroid)
        
        # å¦‚æœæ²¡æœ‰è·Ÿè¸ªçš„ç‰©ä½“ï¼Œæ³¨å†Œæ‰€æœ‰æ£€æµ‹åˆ°çš„ç‰©ä½“
        if len(self.objects) == 0:
            for i in range(len(input_centroids)):
                self.register(input_centroids[i], detections[i][5] if len(detections[i]) > 5 else 0)
        else:
            # è·å–å½“å‰è·Ÿè¸ªçš„ç‰©ä½“IDå’Œä¸­å¿ƒç‚¹
            object_ids = list(self.objects.keys())
            object_centroids = [self.objects[object_id][0] for object_id in object_ids]
            
            # è®¡ç®—è·ç¦»çŸ©é˜µ
            distances = np.zeros((len(object_ids), len(input_centroids)))
            for i in range(len(object_ids)):
                for j in range(len(input_centroids)):
                    distances[i, j] = self.calculate_distance(object_centroids[i], input_centroids[j])
            
            # ä½¿ç”¨åŒˆç‰™åˆ©ç®—æ³•è¿›è¡ŒåŒ¹é…
            from scipy.optimize import linear_sum_assignment
            try:
                row_indices, col_indices = linear_sum_assignment(distances)
                
                # å¤„ç†åŒ¹é…ç»“æœ
                for row, col in zip(row_indices, col_indices):
                    if distances[row, col] < self.max_distance:
                        # æ›´æ–°ç°æœ‰ç‰©ä½“
                        object_id = object_ids[row]
                        self.objects[object_id] = (input_centroids[col], detections[col][5] if len(detections[col]) > 5 else 0, 0)
                    else:
                        # è·ç¦»å¤ªè¿œï¼Œæ³¨å†Œä¸ºæ–°ç‰©ä½“
                        self.register(input_centroids[col], detections[col][5] if len(detections[col]) > 5 else 0)
                
                # å¤„ç†æœªåŒ¹é…çš„æ£€æµ‹ç»“æœ
                unmatched_cols = set(range(len(input_centroids))) - set(col_indices)
                for col in unmatched_cols:
                    self.register(input_centroids[col], detections[col][5] if len(detections[col]) > 5 else 0)
                
                # å¤„ç†æœªåŒ¹é…çš„è·Ÿè¸ªç‰©ä½“
                unmatched_rows = set(range(len(object_ids))) - set(row_indices)
                for row in unmatched_rows:
                    object_id = object_ids[row]
                    centroid, class_id, disappeared = self.objects[object_id]
                    disappeared += 1
                    if disappeared > self.max_disappeared:
                        self.deregister(object_id)
                    else:
                        self.objects[object_id] = (centroid, class_id, disappeared)
                        
            except ImportError:
                # å¦‚æœæ²¡æœ‰scipyï¼Œä½¿ç”¨ç®€å•çš„æœ€è¿‘é‚»åŒ¹é…
                for i, input_centroid in enumerate(input_centroids):
                    min_distance = float('inf')
                    min_index = -1
                    
                    for j, object_centroid in enumerate(object_centroids):
                        distance = self.calculate_distance(object_centroid, input_centroid)
                        if distance < min_distance and distance < self.max_distance:
                            min_distance = distance
                            min_index = j
                    
                    if min_index != -1:
                        # æ›´æ–°ç°æœ‰ç‰©ä½“
                        object_id = object_ids[min_index]
                        self.objects[object_id] = (input_centroid, detections[i][5] if len(detections[i]) > 5 else 0, 0)
                    else:
                        # æ³¨å†Œä¸ºæ–°ç‰©ä½“
                        self.register(input_centroid, detections[i][5] if len(detections[i]) > 5 else 0)
        
        # è¿”å›è·Ÿè¸ªç»“æœ
        tracked_objects = []
        for object_id, (centroid, class_id, disappeared) in self.objects.items():
            if disappeared == 0:  # åªè¿”å›å½“å‰å¸§æ£€æµ‹åˆ°çš„ç‰©ä½“
                tracked_objects.append({
                    'id': object_id,
                    'centroid': centroid,
                    'class_id': class_id,
                    'bbox': self.find_bbox_for_centroid(centroid, detections)
                })
        
        return tracked_objects
    
    def find_bbox_for_centroid(self, centroid: Tuple[int, int], detections: List[List]) -> List:
        """æ ¹æ®ä¸­å¿ƒç‚¹æ‰¾åˆ°å¯¹åº”çš„è¾¹ç•Œæ¡†"""
        for detection in detections:
            if len(detection) >= 4:
                x1, y1, x2, y2 = detection[:4]
                center_x = (x1 + x2) / 2
                center_y = (y1 + y2) / 2
                if abs(center_x - centroid[0]) < 10 and abs(center_y - centroid[1]) < 10:
                    return detection[:4]
        return [0, 0, 0, 0]
    
    def get_centroid(self, detection: List) -> Tuple[int, int]:
        """è®¡ç®—æ£€æµ‹æ¡†çš„ä¸­å¿ƒç‚¹"""
        if len(detection) >= 4:
            x1, y1, x2, y2 = detection[:4]
            return (int((x1 + x2) / 2), int((y1 + y2) / 2))
        return (0, 0)
    
    def calculate_distance(self, point1: Tuple[int, int], point2: Tuple[int, int]) -> float:
        """è®¡ç®—ä¸¤ç‚¹é—´è·ç¦»"""
        return math.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)
    
    def get_collision_risks(self, user_position: Tuple[int, int]) -> Dict[int, float]:
        """è·å–æ‰€æœ‰ç‰©ä½“çš„ç¢°æ’é£é™©"""
        risks = {}
        for object_id, (centroid, class_id, disappeared) in self.objects.items():
            if disappeared == 0:
                distance = self.calculate_distance(centroid, user_position)
                if distance < 100:
                    risk = max(0, 1 - distance / 100)
                    risks[object_id] = risk
        return risks

class TrajectoryPredictor:
    """è½¨è¿¹é¢„æµ‹å™¨ä¸»ç±»"""
    
    def __init__(self):
        self.blind_path_detector = BlindPathDetector()
        self.motion_predictor = MotionPredictor()
        self.tracker = EnhancedTracker()
        self.user_position = (320, 240)  # é»˜è®¤ç”¨æˆ·ä½ç½®ï¼ˆå±å¹•ä¸­å¿ƒï¼‰
        
    def process_frame(self, frame: np.ndarray, detections: List[List]) -> Dict:
        """å¤„ç†å•å¸§å›¾åƒ"""
        # æ£€æµ‹ç›²é“
        blind_path_info = self.blind_path_detector.detect_blind_path(frame)
        
        # è·Ÿè¸ªç‰©ä½“
        tracked_objects = self.tracker.update(detections)
        
        # æ›´æ–°è¿åŠ¨é¢„æµ‹å™¨
        current_time = time.time()
        for obj in tracked_objects:
            self.motion_predictor.update_trajectory(obj['id'], obj['centroid'], current_time)
        
        # è®¡ç®—ç¢°æ’é£é™©
        collision_risks = self.tracker.get_collision_risks(self.user_position)
        
        # ç”Ÿæˆè­¦å‘Šä¿¡æ¯
        warnings = self.generate_warnings(tracked_objects, collision_risks, blind_path_info)
        
        return {
            'blind_path': blind_path_info,
            'tracked_objects': tracked_objects,
            'collision_risks': collision_risks,
            'warnings': warnings,
            'safety_guidance': self.get_safety_guidance()
        }
    
    def generate_warnings(self, tracked_objects: List[Dict], collision_risks: Dict[int, float], 
                         blind_path_info: Optional[Dict]) -> List[str]:
        """ç”Ÿæˆè­¦å‘Šä¿¡æ¯"""
        warnings = []
        
        # æ£€æŸ¥é«˜ç¢°æ’é£é™©çš„ç‰©ä½“
        for object_id, risk in collision_risks.items():
            if risk > 0.7:
                obj = next((obj for obj in tracked_objects if obj['id'] == object_id), None)
                if obj:
                    class_name = self.get_class_name(obj['class_id'])
                    direction = self.get_direction(self.user_position[0], obj['centroid'][0])
                    warnings.append(f"âš ï¸ é«˜é£é™©ï¼š{direction}æœ‰{class_name}ï¼Œç¢°æ’é£é™©{risk:.1%}")
        
        # æ£€æŸ¥ç›²é“çŠ¶æ€
        if blind_path_info:
            if blind_path_info['confidence'] < 0.5:
                warnings.append("âš ï¸ ç›²é“è¯†åˆ«ç½®ä¿¡åº¦è¾ƒä½ï¼Œè¯·å°å¿ƒ")
        else:
            warnings.append("âš ï¸ æœªæ£€æµ‹åˆ°ç›²é“ï¼Œè¯·è°¨æ…å‰è¡Œ")
        
        return warnings
    
    def get_class_name(self, class_id: int) -> str:
        """è·å–ç±»åˆ«åç§°"""
        return CLASS_INFO.get(class_id, {}).get('name', f'ç‰©ä½“{class_id}')
    
    def get_direction(self, x1: int, x2: int) -> str:
        """è·å–æ–¹å‘æè¿°"""
        diff = x2 - x1
        if abs(diff) < 50:
            return "æ­£å‰æ–¹"
        elif diff > 0:
            return "å³å‰æ–¹"
        else:
            return "å·¦å‰æ–¹"
    
    def calculate_distance(self, point1: Tuple[int, int], point2: Tuple[int, int]) -> float:
        """è®¡ç®—è·ç¦»"""
        return math.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)
    
    def update_user_position(self, position: Tuple[int, int]):
        """æ›´æ–°ç”¨æˆ·ä½ç½®"""
        self.user_position = position
    
    def get_safety_guidance(self, frame_center: Tuple[int, int] = (320, 240)) -> str:
        """è·å–å®‰å…¨æŒ‡å¯¼"""
        return "è¯·æ²¿ç›²é“å‰è¡Œï¼Œæ³¨æ„å‘¨å›´éšœç¢ç‰©"

# ==================== è¯­éŸ³ç®¡ç†æ¨¡å— ====================
class VoiceLibrary:
    """è¯­éŸ³åº“ç®¡ç†"""
    
    def __init__(self, config_file: str = "configs/voice_config.json"):
        self.config_file = config_file
        self.obstacle_types = {}
        self.class_mapping = {}
        self.special_scenarios = {}
        self.load_config()
    
    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                self.obstacle_types = config.get('obstacle_types', {})
                self.class_mapping = config.get('class_mapping', {})
                self.special_scenarios = config.get('special_scenarios', {})
        except Exception as e:
            print(f"âš ï¸ åŠ è½½è¯­éŸ³é…ç½®å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤é…ç½®
            self.obstacle_types = {}
            self.class_mapping = {}
            self.special_scenarios = {}
    
    def get_obstacle_info(self, class_id: int) -> Dict:
        """è·å–éšœç¢ç‰©ä¿¡æ¯"""
        class_id_str = str(class_id)
        if class_id_str in self.class_mapping:
            path = self.class_mapping[class_id_str]
            current = self.obstacle_types
            for key in path:
                if key in current:
                    current = current[key]
                else:
                    return {}
            return current
        return {}
    
    def generate_message(self, class_id: int, distance: float, direction: str, risk_level: str = "near") -> str:
        """ç”Ÿæˆè¯­éŸ³æ¶ˆæ¯"""
        obstacle_info = self.get_obstacle_info(class_id)
        if obstacle_info and 'templates' in obstacle_info:
            templates = obstacle_info['templates']
            if risk_level in templates:
                template = templates[risk_level]
                return template.format(distance=f"{distance:.1f}", direction=direction)
        
        # ä½¿ç”¨é»˜è®¤æ¨¡æ¿
        return f"å‰æ–¹{distance:.1f}ç±³{direction}æœ‰éšœç¢ç‰©"
    
    def get_special_message(self, scenario: str) -> str:
        """è·å–ç‰¹æ®Šåœºæ™¯æ¶ˆæ¯"""
        return self.special_scenarios.get(scenario, "")

# ç™¾åº¦è¯­éŸ³APIé…ç½®
BAIDU_APP_ID = '119634292'
BAIDU_API_KEY = 'w978fA2S7PJmUy4IEvlGqxfx'
BAIDU_SECRET_KEY = 'ZeTBNN1UYQRL1kaDEEImHm07Y09jgaRc'

# COCOæ•°æ®é›†ç±»åˆ«æ˜ å°„ï¼ˆYOLOé»˜è®¤æ£€æµ‹ç±»åˆ«ï¼‰
COCO_CLASSES = {
    0: "person", 1: "bicycle", 2: "car", 3: "motorcycle", 4: "airplane", 5: "bus",
    6: "train", 7: "truck", 8: "boat", 9: "traffic light", 10: "fire hydrant",
    11: "stop sign", 12: "parking meter", 13: "bench", 14: "bird", 15: "cat",
    16: "dog", 17: "horse", 18: "sheep", 19: "cow", 20: "elephant",
    21: "bear", 22: "zebra", 23: "giraffe", 24: "backpack", 25: "umbrella",
    26: "handbag", 27: "tie", 28: "suitcase", 29: "frisbee", 30: "skis",
    31: "snowboard", 32: "sports ball", 33: "kite", 34: "baseball bat", 35: "baseball glove",
    36: "skateboard", 37: "surfboard", 38: "tennis racket", 39: "bottle", 40: "wine glass",
    41: "cup", 42: "fork", 43: "knife", 44: "spoon", 45: "bowl",
    46: "banana", 47: "apple", 48: "sandwich", 49: "orange", 50: "broccoli",
    51: "carrot", 52: "hot dog", 53: "pizza", 54: "donut", 55: "cake",
    56: "chair", 57: "couch", 58: "potted plant", 59: "bed", 60: "dining table",
    61: "toilet", 62: "tv", 63: "laptop", 64: "mouse", 65: "remote",
    66: "keyboard", 67: "cell phone", 68: "microwave", 69: "oven", 70: "toaster",
    71: "sink", 72: "refrigerator", 73: "book", 74: "clock", 75: "vase",
    76: "scissors", 77: "teddy bear", 78: "hair drier", 79: "toothbrush"
}

# ç›²é“å¯¼èˆªéšœç¢ç‰©ç±»å‹æ ‡ç­¾åº“ï¼ˆå®Œæ•´ç‰ˆï¼‰
# ä¾æ®ISO 23599å›½é™…æ— éšœç¢æ ‡å‡†ä¸GB50763å›½å†…è§„èŒƒåˆ¶å®š
BLIND_ROAD_CLASSES = {
    # é™æ€éšœç¢ç‰© - åœ°é¢éšœç¢
    0: {"name": "äº•ç›–å‡¸èµ·", "color": (0, 255, 0), "category": "static_ground_protrusion", "risk_level": 3},
    1: {"name": "è·¯é¢ä¿®è¡¥å‡¸åŒ…", "color": (0, 255, 128), "category": "static_ground_protrusion", "risk_level": 2},
    2: {"name": "å‡é€Ÿå¸¦", "color": (0, 255, 255), "category": "static_ground_protrusion", "risk_level": 2},
    3: {"name": "è½¨é“å‡¸èµ·", "color": (0, 0, 255), "category": "static_ground_protrusion", "risk_level": 3},
    4: {"name": "æ’æ°´æ²Ÿ", "color": (255, 0, 0), "category": "static_ground_depression", "risk_level": 3},
    5: {"name": "å‘æ´", "color": (255, 0, 128), "category": "static_ground_depression", "risk_level": 4},
    6: {"name": "ç¼ºå¤±åœ°ç –", "color": (255, 0, 255), "category": "static_ground_depression", "risk_level": 2},
    7: {"name": "æ–½å·¥å‡¹æ§½", "color": (255, 128, 0), "category": "static_ground_depression", "risk_level": 4},
    8: {"name": "ç§¯æ°´æ»©", "color": (255, 128, 128), "category": "static_ground_surface", "risk_level": 2},
    9: {"name": "æ²¹æ±¡åŒº", "color": (255, 128, 255), "category": "static_ground_surface", "risk_level": 3},
    10: {"name": "å…‰æ»‘å¤§ç†çŸ³åœ°é¢", "color": (128, 0, 255), "category": "static_ground_surface", "risk_level": 2},
    11: {"name": "è½å¶å †ç§¯", "color": (128, 128, 255), "category": "static_ground_surface", "risk_level": 1},
    
    # é™æ€éšœç¢ç‰© - å›ºå®šè®¾æ–½
    12: {"name": "è·¯ç¯æ†", "color": (0, 128, 255), "category": "static_facility_street", "risk_level": 3},
    13: {"name": "å…¬äº¤ç«™ç‰Œ", "color": (128, 255, 0), "category": "static_facility_street", "risk_level": 2},
    14: {"name": "åƒåœ¾æ¡¶", "color": (128, 255, 128), "category": "static_facility_street", "risk_level": 2},
    15: {"name": "è‡ªè¡Œè½¦æ¶", "color": (128, 255, 255), "category": "static_facility_street", "risk_level": 2},
    16: {"name": "æŠ¥åˆŠäº­", "color": (255, 128, 255), "category": "static_facility_commercial", "risk_level": 2},
    17: {"name": "å†°æ·‡æ·‹è½¦", "color": (255, 255, 128), "category": "static_facility_commercial", "risk_level": 2},
    18: {"name": "ä¸´æ—¶å±•å°", "color": (255, 255, 255), "category": "static_facility_commercial", "risk_level": 2},
    19: {"name": "è‡ªåŠ¨å”®è´§æœº", "color": (64, 64, 64), "category": "static_facility_commercial", "risk_level": 2},
    20: {"name": "æ¶ˆé˜²æ “", "color": (128, 64, 64), "category": "static_facility_public", "risk_level": 3},
    21: {"name": "ç”µç®±", "color": (64, 128, 64), "category": "static_facility_public", "risk_level": 3},
    22: {"name": "é‚®ç­’", "color": (64, 64, 128), "category": "static_facility_public", "risk_level": 2},
    23: {"name": "AEDè®¾å¤‡ç®±", "color": (128, 128, 64), "category": "static_facility_public", "risk_level": 2},
    
    # åŠ¨æ€éšœç¢ç‰© - è¡Œäººç›¸å…³
    24: {"name": "ç«™ç«‹è¡Œäºº", "color": (64, 128, 128), "category": "dynamic_pedestrian_individual", "risk_level": 2},
    25: {"name": "å¥”è·‘å„¿ç«¥", "color": (192, 64, 64), "category": "dynamic_pedestrian_individual", "risk_level": 4},
    26: {"name": "æ»‘æ¿å°‘å¹´", "color": (64, 192, 64), "category": "dynamic_pedestrian_individual", "risk_level": 3},
    27: {"name": "ä½å¤´æ—", "color": (64, 64, 192), "category": "dynamic_pedestrian_individual", "risk_level": 2},
    28: {"name": "æ’é˜Ÿäººç¾¤", "color": (192, 192, 64), "category": "dynamic_pedestrian_group", "risk_level": 2},
    29: {"name": "æ—…æ¸¸å›¢", "color": (64, 192, 192), "category": "dynamic_pedestrian_group", "risk_level": 2},
    30: {"name": "å¹¿åœºèˆç¾¤ä½“", "color": (192, 64, 192), "category": "dynamic_pedestrian_group", "risk_level": 2},
    31: {"name": "æŠ—è®®é›†ä¼š", "color": (192, 192, 192), "category": "dynamic_pedestrian_group", "risk_level": 3},
    32: {"name": "è½®æ¤…ä½¿ç”¨è€…", "color": (32, 32, 32), "category": "dynamic_pedestrian_special", "risk_level": 3},
    33: {"name": "å¯¼ç›²çŠ¬", "color": (96, 32, 32), "category": "dynamic_pedestrian_special", "risk_level": 3},
    34: {"name": "æ‹„æ‹è¡Œäºº", "color": (32, 96, 32), "category": "dynamic_pedestrian_special", "risk_level": 3},
    35: {"name": "å©´å„¿è½¦", "color": (32, 32, 96), "category": "dynamic_pedestrian_special", "risk_level": 3},
    
    # åŠ¨æ€éšœç¢ç‰© - äº¤é€šå·¥å…·
    36: {"name": "å…±äº«å•è½¦", "color": (96, 96, 32), "category": "dynamic_vehicle_non_motorized", "risk_level": 2},
    37: {"name": "ç”µåŠ¨è‡ªè¡Œè½¦", "color": (32, 96, 96), "category": "dynamic_vehicle_non_motorized", "risk_level": 3},
    38: {"name": "ä¸‰è½®è½¦", "color": (96, 32, 96), "category": "dynamic_vehicle_non_motorized", "risk_level": 2},
    39: {"name": "å¹³è¡¡è½¦", "color": (96, 96, 96), "category": "dynamic_vehicle_non_motorized", "risk_level": 3},
    40: {"name": "è¿åœæ±½è½¦", "color": (160, 48, 48), "category": "dynamic_vehicle_motorized", "risk_level": 3},
    41: {"name": "é€è´§å¡è½¦", "color": (48, 160, 48), "category": "dynamic_vehicle_motorized", "risk_level": 3},
    42: {"name": "ç´§æ€¥è½¦è¾†", "color": (48, 48, 160), "category": "dynamic_vehicle_motorized", "risk_level": 4},
    43: {"name": "ç§»åŠ¨é¤è½¦", "color": (160, 160, 48), "category": "dynamic_vehicle_motorized", "risk_level": 2},
    44: {"name": "æ‰‹æ¨è½¦", "color": (48, 160, 160), "category": "dynamic_vehicle_micro", "risk_level": 2},
    45: {"name": "è¡Œæè½¦", "color": (160, 48, 160), "category": "dynamic_vehicle_micro", "risk_level": 2},
    46: {"name": "è¶…å¸‚è´­ç‰©è½¦", "color": (160, 160, 160), "category": "dynamic_vehicle_micro", "risk_level": 2},
    47: {"name": "å¹³æ¿æ‹–è½¦", "color": (80, 24, 24), "category": "dynamic_vehicle_micro", "risk_level": 2},
    
    # åŠ¨æ€éšœç¢ç‰© - åŠ¨ç‰©ç±»
    48: {"name": "æœªæ “ç»³çŠ¬åª", "color": (24, 80, 24), "category": "dynamic_animal_pet", "risk_level": 4},
    49: {"name": "çŒ«", "color": (24, 24, 80), "category": "dynamic_animal_pet", "risk_level": 2},
    50: {"name": "é¸½å­ç¾¤", "color": (80, 80, 24), "category": "dynamic_animal_pet", "risk_level": 1},
    51: {"name": "æµæµªåŠ¨ç‰©", "color": (24, 80, 80), "category": "dynamic_animal_pet", "risk_level": 2},
    52: {"name": "å¯¼ç›²çŠ¬å·¥ä½œ", "color": (80, 24, 80), "category": "dynamic_animal_working", "risk_level": 3},
    53: {"name": "è­¦çŠ¬", "color": (80, 80, 80), "category": "dynamic_animal_working", "risk_level": 3},
    54: {"name": "é©¬æœ¯ç”¨é©¬", "color": (40, 12, 12), "category": "dynamic_animal_working", "risk_level": 3},
    
    # æ—¥å¸¸é«˜é¢‘éšœç¢ - å•†ä¸šæ´»åŠ¨
    55: {"name": "æ—©é¤æ‘Š", "color": (12, 40, 12), "category": "daily_commercial_stall", "risk_level": 2},
    56: {"name": "å¤œå¸‚æ‘Šä½", "color": (12, 12, 40), "category": "daily_commercial_stall", "risk_level": 2},
    57: {"name": "ä¿ƒé”€å±•å°", "color": (40, 40, 12), "category": "daily_commercial_stall", "risk_level": 2},
    58: {"name": "æµåŠ¨èŠ±è½¦", "color": (12, 40, 40), "category": "daily_commercial_stall", "risk_level": 2},
    59: {"name": "å¿«é€’å †æ”¾", "color": (40, 12, 40), "category": "daily_commercial_goods", "risk_level": 2},
    60: {"name": "è´§å“è£…å¸", "color": (40, 40, 40), "category": "daily_commercial_goods", "risk_level": 2},
    61: {"name": "å•¤é…’ç®±", "color": (20, 6, 6), "category": "daily_commercial_goods", "risk_level": 2},
    62: {"name": "è”¬èœç­", "color": (6, 20, 6), "category": "daily_commercial_goods", "risk_level": 2},
    
    # æ—¥å¸¸é«˜é¢‘éšœç¢ - ä¸´æ—¶æ€§éšœç¢
    63: {"name": "å©šç¤¼æ‹±é—¨", "color": (6, 6, 20), "category": "daily_temporary_activity", "risk_level": 2},
    64: {"name": "æ‹æ‘„å™¨æ", "color": (20, 20, 6), "category": "daily_temporary_activity", "risk_level": 2},
    65: {"name": "ä¸´æ—¶èˆå°", "color": (6, 20, 20), "category": "daily_temporary_activity", "risk_level": 2},
    66: {"name": "å……æ°”åŸå ¡", "color": (20, 6, 20), "category": "daily_temporary_activity", "risk_level": 2},
    67: {"name": "æŠ˜æ–­æ ‘æ", "color": (20, 20, 20), "category": "daily_temporary_natural", "risk_level": 2},
    68: {"name": "å†°é¢", "color": (10, 3, 3), "category": "daily_temporary_natural", "risk_level": 3},
    69: {"name": "ç§¯é›ªå †", "color": (3, 10, 3), "category": "daily_temporary_natural", "risk_level": 2},
    70: {"name": "æ²™å°˜å †ç§¯", "color": (3, 3, 10), "category": "daily_temporary_natural", "risk_level": 1},
    
    # æ—¥å¸¸é«˜é¢‘éšœç¢ - ç‰¹æ®Šåœºæ™¯
    71: {"name": "åœ°é“é—¸æœº", "color": (10, 10, 3), "category": "daily_special_transport", "risk_level": 2},
    72: {"name": "å®‰æ£€è®¾å¤‡", "color": (3, 10, 10), "category": "daily_special_transport", "risk_level": 2},
    73: {"name": "å…¬äº¤å¡æœº", "color": (10, 3, 10), "category": "daily_special_transport", "risk_level": 2},
    74: {"name": "å…±äº«å•è½¦åœæ”¾åŒº", "color": (10, 10, 10), "category": "daily_special_transport", "risk_level": 2},
    75: {"name": "ATMæœº", "color": (5, 1, 1), "category": "daily_special_service", "risk_level": 2},
    76: {"name": "å……ç”µæ¡©", "color": (1, 5, 1), "category": "daily_special_service", "risk_level": 2},
    77: {"name": "å¿«é€’æŸœ", "color": (1, 1, 5), "category": "daily_special_service", "risk_level": 2},
    78: {"name": "ä½“é‡ç§¤", "color": (5, 5, 1), "category": "daily_special_service", "risk_level": 1},
    
    # å»ºç­‘éšœç¢ - è®¾è®¡ç¼ºé™·
    79: {"name": "è¿‡çª„ç›²é“", "color": (1, 5, 5), "category": "architectural_design_defect", "risk_level": 3},
    80: {"name": "ç›´è§’è½¬å¼¯", "color": (5, 1, 5), "category": "architectural_design_defect", "risk_level": 2},
    81: {"name": "çªç„¶æ–­å¤´", "color": (5, 5, 5), "category": "architectural_design_defect", "risk_level": 4},
    82: {"name": "ç»¿åŒ–å¸¦ä¾µå ", "color": (2, 0, 0), "category": "architectural_design_defect", "risk_level": 2},
    83: {"name": "è¿‡çŸ®æ‰¶æ‰‹", "color": (0, 2, 0), "category": "architectural_design_defect", "risk_level": 2},
    84: {"name": "åå…‰ç»ç’ƒå¹•å¢™", "color": (0, 0, 2), "category": "architectural_design_defect", "risk_level": 2},
    85: {"name": "æ—‹è½¬é—¨æ— è¾…åŠ©æŠŠæ‰‹", "color": (2, 2, 0), "category": "architectural_design_defect", "risk_level": 3},
    
    # å»ºç­‘éšœç¢ - æ–½å·¥ç›¸å…³
    86: {"name": "æ°´æ³¥æ…æ‹Œè½¦", "color": (0, 2, 2), "category": "architectural_construction", "risk_level": 3},
    87: {"name": "è„šæ‰‹æ¶", "color": (2, 0, 2), "category": "architectural_construction", "risk_level": 3},
    88: {"name": "å»ºæå †æ”¾", "color": (2, 2, 2), "category": "architectural_construction", "risk_level": 2},
    89: {"name": "é’»å­”æœº", "color": (1, 0, 0), "category": "architectural_construction", "risk_level": 3},
    90: {"name": "ä¸´æ—¶ç”µçº¿", "color": (0, 1, 0), "category": "architectural_construction", "risk_level": 3},
    91: {"name": "æµ‹é‡æ ‡æ¡©", "color": (0, 0, 1), "category": "architectural_construction", "risk_level": 2},
    92: {"name": "æ¢å‘", "color": (1, 1, 0), "category": "architectural_construction", "risk_level": 3},
    93: {"name": "å›´æŒ¡å»¶ä¼¸", "color": (0, 1, 1), "category": "architectural_construction", "risk_level": 2},
    
    # å»ºç­‘éšœç¢ - ç‰¹æ®Šå»ºç­‘ç»“æ„
    94: {"name": "æ‚¬æŒ‚ç¯ç¬¼", "color": (1, 0, 1), "category": "architectural_special", "risk_level": 2},
    95: {"name": "ç›‘æ§æ†", "color": (1, 1, 1), "category": "architectural_special", "risk_level": 2},
    96: {"name": "åŠè£…è£…é¥°", "color": (0, 0, 0), "category": "architectural_special", "risk_level": 2},
    97: {"name": "æ¨ªå¹…ç»³ç´¢", "color": (255, 255, 255), "category": "architectural_special", "risk_level": 2},
    98: {"name": "é€šé£äº•", "color": (128, 128, 128), "category": "architectural_special", "risk_level": 3},
    99: {"name": "åœ°é“å‡ºå£", "color": (64, 64, 64), "category": "architectural_special", "risk_level": 2},
    100: {"name": "åœ°ä¸‹è½¦åº“å¡é“", "color": (32, 32, 32), "category": "architectural_special", "risk_level": 3}
}

DEFAULT_COLOR = (128, 128, 128)

class SimpleVoiceSystem:
    """ç®€åŒ–çš„è¯­éŸ³ç³»ç»Ÿ - æ”¯æŒGUIå†…åµŒæ’­æ”¾"""
    def __init__(self):
        self.access_token = None
        self.get_access_token()
        self.is_enabled = True
        self.last_speak_time = 0
        self.last_speak_text = ""  # è®°å½•ä¸Šæ¬¡æ’­æŠ¥çš„æ–‡æœ¬
        self.speak_lock = threading.Lock()
        self.media_player = None
        self.init_media_player()
    
    def init_media_player(self):
        """åˆå§‹åŒ–åª’ä½“æ’­æ”¾å™¨"""
        try:
            from PyQt5.QtMultimedia import QMediaPlayer, QMediaContent
            from PyQt5.QtCore import QUrl
            self.media_player = QMediaPlayer()
            self.media_player.setVolume(80)
            print("âœ… GUIåª’ä½“æ’­æ”¾å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ GUIåª’ä½“æ’­æ”¾å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.media_player = None
    
    def get_access_token(self):
        """è·å–ç™¾åº¦APIè®¿é—®ä»¤ç‰Œ"""
        try:
            url = f"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={BAIDU_API_KEY}&client_secret={BAIDU_SECRET_KEY}"
            response = requests.get(url)
            if response.status_code == 200:
                result = response.json()
                self.access_token = result.get('access_token')
                print(f"âœ… ç™¾åº¦APIè®¿é—®ä»¤ç‰Œè·å–æˆåŠŸ")
                return True
            else:
                print(f"âŒ è·å–è®¿é—®ä»¤ç‰Œå¤±è´¥: {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ è·å–è®¿é—®ä»¤ç‰Œå‡ºé”™: {e}")
            return False
    
    def speak(self, text):
        """è¯­éŸ³æ’­æŠ¥ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        if not self.is_enabled or not self.access_token:
            return
        
        # é˜²é‡å¤æœºåˆ¶ï¼šç›¸åŒæ–‡æœ¬ä¸é‡å¤æ’­æŠ¥
        if text == self.last_speak_text:
            return
        
        # ç®€å•çš„å†·å´æœºåˆ¶ï¼ˆå¢åŠ å†·å´æ—¶é—´ï¼Œé¿å…è¯­éŸ³é‡å ï¼‰
        current_time = time.time()
        if current_time - self.last_speak_time < 2.0:  # 2ç§’å†·å´ï¼Œé¿å…è¯­éŸ³é‡å 
            return
        
        self.last_speak_time = current_time
        self.last_speak_text = text  # è®°å½•æœ¬æ¬¡æ’­æŠ¥çš„æ–‡æœ¬
        
        def speak_thread():
            try:
                with self.speak_lock:
                    # ç”Ÿæˆè¯­éŸ³æ–‡ä»¶
                    temp_file = self.generate_speech(text)
                    if temp_file and os.path.exists(temp_file):
                        # æ’­æ”¾éŸ³é¢‘
                        self.play_audio(temp_file)
                        # å»¶è¿Ÿåˆ é™¤æ–‡ä»¶
                        threading.Timer(3.0, lambda: self.cleanup_file(temp_file)).start()
            except Exception as e:
                print(f"âŒ è¯­éŸ³æ’­æŠ¥é”™è¯¯: {e}")
        
        threading.Thread(target=speak_thread, daemon=True).start()
    
    def generate_speech(self, text):
        """ç”Ÿæˆè¯­éŸ³æ–‡ä»¶"""
        try:
            import tempfile
            import uuid
            
            # ä½¿ç”¨UUIDç”Ÿæˆå”¯ä¸€æ–‡ä»¶åï¼Œé¿å…å†²çª
            unique_id = str(uuid.uuid4())[:8]
            temp_dir = tempfile.gettempdir()
            temp_file = os.path.join(temp_dir, f'blind_road_{unique_id}.mp3')
            
            # ç¡®ä¿æ–‡ä»¶ä¸å­˜åœ¨
            if os.path.exists(temp_file):
                os.remove(temp_file)
            
            url = "https://tsn.baidu.com/text2audio"
            params = {
                'tok': self.access_token,
                'tex': text,
                'per': 0,  # å¥³å£°
                'spd': 5,  # è¯­é€Ÿ
                'pit': 5,  # éŸ³è°ƒ
                'vol': 5,  # éŸ³é‡
                'cuid': 'blind_road_detector',
                'ctp': 1,
                'lan': 'zh'
            }
            
            response = requests.post(url, data=params)
            if response.status_code == 200:
                with open(temp_file, 'wb') as f:
                    f.write(response.content)
                print(f"âœ… è¯­éŸ³æ–‡ä»¶ç”Ÿæˆ: {temp_file}")
                return temp_file
            else:
                print(f"âŒ è¯­éŸ³åˆæˆå¤±è´¥: {response.status_code}")
                return None
        except Exception as e:
            print(f"âŒ ç”Ÿæˆè¯­éŸ³æ–‡ä»¶é”™è¯¯: {e}")
            return None
    
    def play_audio(self, audio_file):
        """æ’­æ”¾éŸ³é¢‘æ–‡ä»¶ - GUIå†…åµŒæ’­æ”¾"""
        try:
            if self.media_player and os.path.exists(audio_file):
                # ä½¿ç”¨GUIå†…åµŒåª’ä½“æ’­æ”¾å™¨æ’­æ”¾
                from PyQt5.QtCore import QUrl
                from PyQt5.QtMultimedia import QMediaContent
                
                file_path = os.path.abspath(audio_file)
                url = QUrl.fromLocalFile(file_path)
                content = QMediaContent(url)
                self.media_player.setMedia(content)
                self.media_player.play()
                print(f"ğŸµ GUIå†…åµŒæ’­æ”¾éŸ³é¢‘: {audio_file}")
            else:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ç³»ç»Ÿé»˜è®¤æ’­æ”¾å™¨
                import platform
                if platform.system() == "Windows":
                    subprocess.Popen(['start', audio_file], shell=True)
                elif platform.system() == "Darwin":  # macOS
                    subprocess.Popen(['open', audio_file])
                else:  # Linux
                    subprocess.Popen(['xdg-open', audio_file])
                print(f"ğŸµ ç³»ç»Ÿæ’­æ”¾å™¨æ’­æ”¾éŸ³é¢‘: {audio_file}")
        except Exception as e:
            print(f"âŒ æ’­æ”¾éŸ³é¢‘é”™è¯¯: {e}")
            # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ
            try:
                import platform
                if platform.system() == "Windows":
                    subprocess.Popen(['start', audio_file], shell=True)
                print(f"ğŸµ å¤‡ç”¨æ’­æ”¾å™¨æ’­æ”¾éŸ³é¢‘: {audio_file}")
            except:
                print(f"âŒ æ‰€æœ‰æ’­æ”¾æ–¹å¼éƒ½å¤±è´¥")
    
    def cleanup_file(self, file_path):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
                print(f"ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {file_path}")
        except:
            pass
    
    def enable(self):
        """å¯ç”¨è¯­éŸ³"""
        self.is_enabled = True
        print("ğŸ”Š è¯­éŸ³ç³»ç»Ÿå·²å¯ç”¨")
    
    def disable(self):
        """ç¦ç”¨è¯­éŸ³"""
        self.is_enabled = False
        print("ğŸ”‡ è¯­éŸ³ç³»ç»Ÿå·²ç¦ç”¨")

# ä½¿ç”¨COCOç±»åˆ«ä½œä¸ºé»˜è®¤æ£€æµ‹ç±»åˆ«
CLASS_INFO = COCO_CLASSES
DEFAULT_COLOR = (128, 128, 128)  # æœªçŸ¥ç±»åˆ«ç”¨ç°è‰²

class TwoPointAnnotator(QMainWindow):
    def __init__(self):
        super().__init__()
        self.initUI()
        self.annotations = []
        self.current_image_path = None
        self.image_files = []
        self.current_image_index = -1
        
        # ç»˜åˆ¶çŠ¶æ€
        self.drawing_mode = "two_point"  # "two_point" æˆ– "drag"
        self.drawing = False
        self.start_point = None
        self.end_point = None
        self.temp_points = []  # ä¸´æ—¶å­˜å‚¨ä¸¤ç‚¹æ¨¡å¼çš„ç‚¹
        self.drag_start = None  # æ‹–æ‹½æ¨¡å¼çš„èµ·ç‚¹
        
        # ç•Œé¢è®¾ç½®
        self.font_size = 12
        self.line_width = 3
        self.point_size = 8
        
        # å›¾åƒç¼©æ”¾ä¿¡æ¯
        self.original_size = None  # åŸå§‹å›¾åƒå°ºå¯¸
        self.display_size = None   # æ˜¾ç¤ºå°ºå¯¸
        self.scale_factor = 1.0    # ç¼©æ”¾å› å­
        
        # è½¨è¿¹é¢„æµ‹ç³»ç»Ÿ
        if TRAJECTORY_PREDICTOR_AVAILABLE:
            self.trajectory_predictor = TrajectoryPredictor()
            print("âœ… è½¨è¿¹é¢„æµ‹ç³»ç»Ÿå·²é›†æˆ")
        else:
            self.trajectory_predictor = None
            print("âš ï¸ è½¨è¿¹é¢„æµ‹ç³»ç»Ÿä¸å¯ç”¨")
        
        # ç¯å¢ƒæ£€æµ‹ç³»ç»Ÿ
        if ENVIRONMENT_DETECTOR_AVAILABLE:
            try:
                self.env_detector = EnvironmentDetector()
                print("âœ… ç¯å¢ƒæ£€æµ‹ç³»ç»Ÿå·²é›†æˆ")
            except Exception as e:
                print(f"âš ï¸ ç¯å¢ƒæ£€æµ‹ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
                self.env_detector = None
        else:
            self.env_detector = None
            print("âš ï¸ ç¯å¢ƒæ£€æµ‹ç³»ç»Ÿä¸å¯ç”¨")
        
        # è¯­éŸ³æ’­æŠ¥ç³»ç»Ÿ
        self.voice_enabled = True
        self.voice_mode = "ç®€æ´æ¨¡å¼"  # ç®€æ´æ¨¡å¼/è¯¦ç»†æ¨¡å¼/é™é»˜æ¨¡å¼
        self.volume = 80
        self.last_voice_time = 0
        self.voice_cooldown = 2.0  # è¯­éŸ³æ’­æŠ¥å†·å´æ—¶é—´
        import queue
        self.voice_queue = queue.Queue()  # è¯­éŸ³æ’­æŠ¥é˜Ÿåˆ—
        self.current_voice_priority = 0  # å½“å‰æ’­æŠ¥ä¼˜å…ˆçº§
        
        # æ£€æµ‹ç²¾åº¦è®¾ç½®
        self.detection_accuracy = "é«˜ç²¾åº¦"
        self.detection_confidence_threshold = 0.3
        self.detection_nms_threshold = 0.4
        
        # éšœç¢ç‰©å˜åŒ–æ£€æµ‹
        self.previous_detections = []  # ä¸Šä¸€å¸§çš„æ£€æµ‹ç»“æœ
        self.detection_change_threshold = 0.3  # å˜åŒ–é˜ˆå€¼
        self.last_announcement_time = 0  # ä¸Šæ¬¡æ’­æŠ¥æ—¶é—´
        self.announcement_cooldown = 3.0  # æ’­æŠ¥å†·å´æ—¶é—´
        
        # åˆå§‹åŒ–è¯­éŸ³åˆæˆ
        self.init_voice_synthesis()
        
        # åˆå§‹åŒ–è¯­éŸ³æ’­æŠ¥ç³»ç»Ÿ
        self.init_voice_system()
        
        # åˆå§‹åŒ–YOLOæ¨¡å‹
        self.init_yolo_model()
        
        # åˆå§‹åŒ–è¯­éŸ³çŠ¶æ€æ˜¾ç¤º
        QTimer.singleShot(1000, self.update_voice_status)
    
    def init_voice_synthesis(self):
        """åˆå§‹åŒ–è¯­éŸ³åˆæˆ"""
        try:
            import pyttsx3
            
            # æµ‹è¯•è¯­éŸ³åˆæˆæ˜¯å¦å¯ç”¨
            test_tts = pyttsx3.init()
            test_tts.stop()
            
            print("âœ… è¯­éŸ³åˆæˆå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            self.voice_synthesis_available = True
            
        except ImportError:
            print("âš ï¸ pyttsx3æœªå®‰è£…ï¼Œä½¿ç”¨æ§åˆ¶å°è¾“å‡ºä»£æ›¿è¯­éŸ³æ’­æŠ¥")
            self.voice_synthesis_available = False
        except Exception as e:
            print(f"âš ï¸ è¯­éŸ³åˆæˆåˆå§‹åŒ–å¤±è´¥: {e}")
            self.voice_synthesis_available = False
    
    def init_voice_system(self):
        """åˆå§‹åŒ–è¯­éŸ³æ’­æŠ¥ç³»ç»Ÿ"""
        try:
            import threading
            import queue
            import time
            
            # åˆå§‹åŒ–è¯­éŸ³é˜Ÿåˆ—å’ŒçŠ¶æ€ç®¡ç†
            self.voice_queue = queue.PriorityQueue()
            self.voice_thread = None
            self.is_voice_playing = False
            self.voice_lock = threading.Lock()
            self.global_tts_engine = None
            
            # å¯åŠ¨è¯­éŸ³å·¥ä½œçº¿ç¨‹
            self.start_voice_worker()
            
            print("âœ… è¯­éŸ³æ’­æŠ¥ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âš ï¸ è¯­éŸ³æ’­æŠ¥ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            self.voice_synthesis_available = False
    
    def init_yolo_model(self):
        """åˆå§‹åŒ–YOLOæ¨¡å‹"""
        try:
            if YOLO_AVAILABLE:
                from ultralytics import YOLO
                # å°è¯•åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
                self.yolo_model = YOLO('yolov8n.pt')  # ä½¿ç”¨nanoç‰ˆæœ¬ï¼Œé€Ÿåº¦æ›´å¿«
                print("âœ… YOLOæ¨¡å‹åŠ è½½æˆåŠŸ")
                self.yolo_available = True
            else:
                print("âš ï¸ YOLOä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ£€æµ‹")
                self.yolo_model = None
                self.yolo_available = False
        except Exception as e:
            print(f"âš ï¸ YOLOæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.yolo_model = None
            self.yolo_available = False
        
    def initUI(self):
        self.setWindowTitle('ç›²é“éšœç¢æ£€æµ‹ç³»ç»Ÿ - å¢å¼ºç‰ˆ v2.0')
        self.setGeometry(100, 100, 1920, 1080)
        
        # è®¾ç½®å¤§å­—ä½“
        self.setStyleSheet("""
            QMainWindow { font-size: 14px; }
            QPushButton { font-size: 14px; padding: 8px 12px; min-height: 28px; }
            QLabel { font-size: 14px; }
            QGroupBox { font-size: 13px; font-weight: bold; }
            QListWidget { font-size: 13px; }
            QSplitter::handle { background-color: #ddd; }
        """)
        
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        # ä¸»å¸ƒå±€ - å‚ç›´åˆ†å‰²
        main_layout = QVBoxLayout(central_widget)
        
        # åˆ›å»ºä¸»åˆ†å‰²å™¨ï¼ˆæ°´å¹³ï¼‰
        main_splitter = QSplitter(Qt.Horizontal)
        main_layout.addWidget(main_splitter)
        
        # å·¦ä¾§æ§åˆ¶é¢æ¿
        control_panel = self.create_control_panel()
        control_panel.setMinimumWidth(300)
        control_panel.setMaximumWidth(500)
        main_splitter.addWidget(control_panel)
        
        # ä¸­é—´æ‘„åƒå¤´æ£€æµ‹åŒºåŸŸï¼ˆä¸»è¦åŒºåŸŸï¼‰
        camera_panel = self.create_camera_panel()
        camera_panel.setMinimumWidth(800)
        main_splitter.addWidget(camera_panel)
        
        # æ‘„åƒå¤´æ£€æµ‹ç›¸å…³å˜é‡
        self.camera_active = False
        self.cap = None
        self.camera_timer = QTimer()
        self.camera_timer.timeout.connect(self.update_camera_frame)
        
        # å³ä¾§è½¨è¿¹é¢„æµ‹é¢æ¿
        analysis_panel = self.create_analysis_panel()
        analysis_panel.setMinimumWidth(300)
        analysis_panel.setMaximumWidth(500)
        main_splitter.addWidget(analysis_panel)
        
        # è®¾ç½®åˆ†å‰²å™¨æ¯”ä¾‹ï¼šæ§åˆ¶é¢æ¿:æ‘„åƒå¤´:åˆ†æé¢æ¿ = 1:4:1
        main_splitter.setSizes([300, 1600, 300])
        
        # åº•éƒ¨çŠ¶æ€æ 
        self.create_status_bar()
        
        # å¿«æ·é”®æ’¤å›
        undo_shortcut = QShortcut(QKeySequence("Ctrl+Z"), self)
        undo_shortcut.activated.connect(self.undo_last_annotation)
        
    def create_control_panel(self):
        """åˆ›å»ºæ§åˆ¶é¢æ¿"""
        panel = QWidget()
        layout = QVBoxLayout(panel)
        
        # æ ‡é¢˜
        title_label = QLabel("ç›²é“éšœç¢æ£€æµ‹ç³»ç»Ÿ")
        title_label.setAlignment(Qt.AlignCenter)
        title_label.setStyleSheet("font-size: 18px; font-weight: bold; margin: 8px; color: #333; background-color: #e3f2fd; padding: 10px; border-radius: 8px;")
        layout.addWidget(title_label)
        
        # æ‘„åƒå¤´æ§åˆ¶ç»„
        camera_control_group = QGroupBox("æ‘„åƒå¤´æ§åˆ¶")
        camera_control_layout = QVBoxLayout(camera_control_group)
        
        # æ‘„åƒå¤´å¼€å…³
        self.camera_start_btn = QPushButton("ğŸ“¹ å¼€å¯æ‘„åƒå¤´æ£€æµ‹")
        self.camera_start_btn.clicked.connect(self.toggle_camera_detection)
        self.camera_start_btn.setStyleSheet("QPushButton { background-color: #4caf50; color: white; font-weight: bold; padding: 12px; font-size: 16px; }")
        camera_control_layout.addWidget(self.camera_start_btn)
        
        # æ˜¾ç¤ºæ§åˆ¶
        display_control_layout = QHBoxLayout()
        
        self.show_detection_btn = QPushButton("æ£€æµ‹æ¡†")
        self.show_detection_btn.setCheckable(True)
        self.show_detection_btn.setChecked(True)
        self.show_detection_btn.clicked.connect(self.toggle_show_detection)
        self.show_detection_btn.setStyleSheet("QPushButton { background-color: #4caf50; color: white; font-weight: bold; padding: 8px; }")
        display_control_layout.addWidget(self.show_detection_btn)
        
        self.show_trajectory_btn = QPushButton("è½¨è¿¹")
        self.show_trajectory_btn.setCheckable(True)
        self.show_trajectory_btn.setChecked(True)
        self.show_trajectory_btn.clicked.connect(self.toggle_show_trajectory)
        self.show_trajectory_btn.setStyleSheet("QPushButton { background-color: #4caf50; color: white; font-weight: bold; padding: 8px; }")
        display_control_layout.addWidget(self.show_trajectory_btn)
        
        camera_control_layout.addLayout(display_control_layout)
        layout.addWidget(camera_control_group)
        
        # è¯­éŸ³æ’­æŠ¥æ§åˆ¶ç»„
        voice_group = QGroupBox("è¯­éŸ³æ’­æŠ¥æ§åˆ¶")
        voice_layout = QVBoxLayout(voice_group)
        
        # è¯­éŸ³æ¨¡å¼é€‰æ‹©
        self.voice_mode_combo = QComboBox()
        self.voice_mode_combo.addItems(["ç®€æ´æ¨¡å¼", "è¯¦ç»†æ¨¡å¼", "é™é»˜æ¨¡å¼"])
        self.voice_mode_combo.setCurrentText("ç®€æ´æ¨¡å¼")
        self.voice_mode_combo.currentTextChanged.connect(self.change_voice_mode)
        voice_layout.addWidget(QLabel("æ’­æŠ¥æ¨¡å¼:"))
        voice_layout.addWidget(self.voice_mode_combo)
        
        # è¯­éŸ³æ’­æŠ¥å¼€å…³
        self.voice_enabled_btn = QPushButton("ğŸ”Š è¯­éŸ³æ’­æŠ¥: å¼€å¯")
        self.voice_enabled_btn.setCheckable(True)
        self.voice_enabled_btn.setChecked(True)
        self.voice_enabled_btn.clicked.connect(self.toggle_voice)
        self.voice_enabled_btn.setStyleSheet("QPushButton { background-color: #4caf50; color: white; font-weight: bold; }")
        voice_layout.addWidget(self.voice_enabled_btn)
        
        # éŸ³é‡æ§åˆ¶
        volume_layout = QHBoxLayout()
        volume_layout.addWidget(QLabel("éŸ³é‡:"))
        self.volume_slider = QSlider(Qt.Horizontal)
        self.volume_slider.setRange(0, 100)
        self.volume_slider.setValue(80)
        self.volume_slider.valueChanged.connect(self.change_volume)
        volume_layout.addWidget(self.volume_slider)
        self.volume_label = QLabel("80%")
        volume_layout.addWidget(self.volume_label)
        voice_layout.addLayout(volume_layout)
        
        layout.addWidget(voice_group)
        
        # ç¯å¢ƒæ£€æµ‹æ§åˆ¶ç»„
        env_group = QGroupBox("ç¯å¢ƒæ£€æµ‹æ§åˆ¶")
        env_layout = QVBoxLayout(env_group)
        
        # ç¯å¢ƒæ£€æµ‹å¼€å…³
        self.env_detection_btn = QPushButton("ğŸŒ ç¯å¢ƒæ£€æµ‹: å¼€å¯")
        self.env_detection_btn.setCheckable(True)
        self.env_detection_btn.setChecked(True)
        self.env_detection_btn.clicked.connect(self.toggle_environment_detection)
        self.env_detection_btn.setStyleSheet("QPushButton { background-color: #ff9800; color: white; font-weight: bold; padding: 10px; font-size: 14px; }")
        env_layout.addWidget(self.env_detection_btn)
        
        # ç¯å¢ƒæ£€æµ‹çŠ¶æ€æ ‡å¿—
        self.env_detection_enabled = True
        
        # ç¯å¢ƒæ£€æµ‹æ¨¡å¼é€‰æ‹©
        self.env_mode_combo = QComboBox()
        self.env_mode_combo.addItems(["æ ‡å‡†æ¨¡å¼", "é«˜ç²¾åº¦æ¨¡å¼", "å¿«é€Ÿæ¨¡å¼"])
        self.env_mode_combo.setCurrentText("æ ‡å‡†æ¨¡å¼")
        self.env_mode_combo.currentTextChanged.connect(self.change_env_mode)
        env_layout.addWidget(QLabel("æ£€æµ‹æ¨¡å¼:"))
        env_layout.addWidget(self.env_mode_combo)
        
        # ç¯å¢ƒæ£€æµ‹æµ‹è¯•æŒ‰é’®
        self.env_test_btn = QPushButton("ğŸ§ª ç¯å¢ƒæ£€æµ‹æµ‹è¯•")
        self.env_test_btn.clicked.connect(self.test_environment_detection)
        self.env_test_btn.setStyleSheet("QPushButton { background-color: #9c27b0; color: white; font-weight: bold; padding: 8px; }")
        env_layout.addWidget(self.env_test_btn)
        
        # è¯­éŸ³æ’­æŠ¥ç¯å¢ƒæŒ‰é’®
        self.voice_env_btn = QPushButton("ğŸ”Š è¯­éŸ³æ’­æŠ¥ç¯å¢ƒ")
        self.voice_env_btn.clicked.connect(self.voice_announce_environment)
        self.voice_env_btn.setStyleSheet("QPushButton { background-color: #e91e63; color: white; font-weight: bold; padding: 8px; }")
        env_layout.addWidget(self.voice_env_btn)
        
        layout.addWidget(env_group)
        
        # ç¯å¢ƒæ£€æµ‹ç»“æœæ˜¾ç¤ºç»„
        env_result_group = QGroupBox("ç¯å¢ƒæ£€æµ‹ç»“æœ")
        env_result_layout = QVBoxLayout(env_result_group)
        
        # ç¯å¢ƒå®‰å…¨çŠ¶æ€
        self.env_safety_label = QLabel("ç¯å¢ƒå®‰å…¨: æœªæ£€æµ‹")
        self.env_safety_label.setStyleSheet("font-weight: bold; color: #666; padding: 8px; background-color: #f5f5f5; border-radius: 5px;")
        env_result_layout.addWidget(self.env_safety_label)
        
        # å®‰å…¨è¯„åˆ†
        self.env_score_label = QLabel("å®‰å…¨è¯„åˆ†: --")
        self.env_score_label.setStyleSheet("font-weight: bold; color: #666; padding: 8px; background-color: #f5f5f5; border-radius: 5px;")
        env_result_layout.addWidget(self.env_score_label)
        
        # ç¯å¢ƒè¯¦æƒ…
        self.env_details_text = QTextEdit()
        self.env_details_text.setMaximumHeight(120)
        self.env_details_text.setReadOnly(True)
        self.env_details_text.setPlaceholderText("ç¯å¢ƒæ£€æµ‹è¯¦æƒ…å°†æ˜¾ç¤ºåœ¨è¿™é‡Œ...")
        self.env_details_text.setStyleSheet("background-color: #f9f9f9; border: 1px solid #ddd; padding: 5px; font-size: 12px;")
        env_result_layout.addWidget(QLabel("ç¯å¢ƒè¯¦æƒ…:"))
        env_result_layout.addWidget(self.env_details_text)
        
        # è­¦å‘Šä¿¡æ¯
        self.env_warnings_text = QTextEdit()
        self.env_warnings_text.setMaximumHeight(80)
        self.env_warnings_text.setReadOnly(True)
        self.env_warnings_text.setPlaceholderText("è­¦å‘Šä¿¡æ¯å°†æ˜¾ç¤ºåœ¨è¿™é‡Œ...")
        self.env_warnings_text.setStyleSheet("background-color: #fff3cd; border: 1px solid #ffeaa7; padding: 5px; font-size: 12px;")
        env_result_layout.addWidget(QLabel("è­¦å‘Šä¿¡æ¯:"))
        env_result_layout.addWidget(self.env_warnings_text)
        
        layout.addWidget(env_result_group)
        
        # æ‰‹æœºæµ‹è¯•æŒ‰é’®
        self.mobile_test_btn = QPushButton("ğŸ“± å¯åŠ¨æ‰‹æœºæµ‹è¯•")
        self.mobile_test_btn.clicked.connect(self.start_mobile_test)
        self.mobile_test_btn.setStyleSheet("QPushButton { background-color: #2196f3; color: white; font-weight: bold; font-size: 16px; padding: 12px; }")
        layout.addWidget(self.mobile_test_btn)
        
        # è¯­éŸ³æ’­æŠ¥çŠ¶æ€æ˜¾ç¤º
        self.voice_status_display = QLabel("è¯­éŸ³æ’­æŠ¥: å·²å¯ç”¨")
        self.voice_status_display.setStyleSheet("color: #4caf50; font-weight: bold; font-size: 14px; padding: 8px;")
        layout.addWidget(self.voice_status_display)
        
        layout.addStretch()
        return panel
    
    def create_camera_panel(self):
        """åˆ›å»ºæ‘„åƒå¤´æ£€æµ‹é¢æ¿"""
        panel = QWidget()
        layout = QVBoxLayout(panel)
        
        # æ‘„åƒå¤´æ§åˆ¶æŒ‰é’®
        control_layout = QHBoxLayout()
        
        self.camera_start_btn = QPushButton("ğŸ“¹ å¼€å¯æ‘„åƒå¤´æ£€æµ‹")
        self.camera_start_btn.clicked.connect(self.toggle_camera_detection)
        self.camera_start_btn.setStyleSheet("QPushButton { background-color: #4caf50; color: white; font-weight: bold; padding: 12px; font-size: 16px; }")
        control_layout.addWidget(self.camera_start_btn)
        
        self.show_detection_btn = QPushButton("æ˜¾ç¤ºæ£€æµ‹æ¡†")
        self.show_detection_btn.setCheckable(True)
        self.show_detection_btn.setChecked(True)
        self.show_detection_btn.clicked.connect(self.toggle_show_detection)
        self.show_detection_btn.setStyleSheet("QPushButton { background-color: #4caf50; color: white; font-weight: bold; padding: 8px; }")
        control_layout.addWidget(self.show_detection_btn)
        
        self.show_trajectory_btn = QPushButton("æ˜¾ç¤ºè½¨è¿¹")
        self.show_trajectory_btn.setCheckable(True)
        self.show_trajectory_btn.setChecked(True)
        self.show_trajectory_btn.clicked.connect(self.toggle_show_trajectory)
        self.show_trajectory_btn.setStyleSheet("QPushButton { background-color: #4caf50; color: white; font-weight: bold; padding: 8px; }")
        control_layout.addWidget(self.show_trajectory_btn)
        
        control_layout.addStretch()
        
        # æ£€æµ‹çŠ¶æ€æ˜¾ç¤º
        self.camera_status_label = QLabel("æ‘„åƒå¤´çŠ¶æ€: æœªå¯åŠ¨")
        self.camera_status_label.setStyleSheet("color: #666; padding: 8px; background-color: #f0f0f0; border-radius: 5px; font-size: 14px;")
        control_layout.addWidget(self.camera_status_label)
        
        layout.addLayout(control_layout)
        
        # æ‘„åƒå¤´æ˜¾ç¤ºåŒºåŸŸ
        self.camera_display = QLabel("ç‚¹å‡»'å¼€å¯æ‘„åƒå¤´æ£€æµ‹'å¼€å§‹å®æ—¶æ£€æµ‹")
        self.camera_display.setMinimumSize(800, 600)
        self.camera_display.setStyleSheet("""
            QLabel {
                border: 2px solid #ddd;
                border-radius: 10px;
                background-color: #f9f9f9;
                color: #666;
                font-size: 16px;
                padding: 20px;
            }
        """)
        self.camera_display.setAlignment(Qt.AlignCenter)
        layout.addWidget(self.camera_display)
        
        # æ£€æµ‹çŠ¶æ€ä¿¡æ¯
        status_layout = QHBoxLayout()
        
        self.detection_status_label = QLabel("æ£€æµ‹çŠ¶æ€: æœªå¯åŠ¨")
        self.detection_status_label.setStyleSheet("color: #666; padding: 5px; background-color: #f0f0f0; border-radius: 3px;")
        status_layout.addWidget(self.detection_status_label)
        
        self.fps_label = QLabel("FPS: 0")
        self.fps_label.setStyleSheet("color: #4caf50; padding: 5px; background-color: #e8f5e8; border-radius: 3px;")
        status_layout.addWidget(self.fps_label)
        
        self.detection_count_label = QLabel("æ£€æµ‹æ•°é‡: 0")
        self.detection_count_label.setStyleSheet("color: #2196f3; padding: 5px; background-color: #e3f2fd; border-radius: 3px;")
        status_layout.addWidget(self.detection_count_label)
        
        layout.addLayout(status_layout)
        
        return panel
    
    def create_analysis_panel(self):
        """åˆ›å»ºè½¨è¿¹é¢„æµ‹åˆ†æé¢æ¿"""
        panel = QWidget()
        layout = QVBoxLayout(panel)
        
        # è½¨è¿¹é¢„æµ‹ç»„
        trajectory_group = QGroupBox("è½¨è¿¹é¢„æµ‹")
        trajectory_layout = QVBoxLayout(trajectory_group)
        
        # åŠ¨æ€éšœç¢ç‰©è½¨è¿¹
        self.dynamic_objects_label = QLabel("åŠ¨æ€éšœç¢ç‰©è½¨è¿¹:")
        self.dynamic_objects_label.setStyleSheet("font-weight: bold; color: #333;")
        trajectory_layout.addWidget(self.dynamic_objects_label)
        
        self.dynamic_objects_list = QTextEdit()
        self.dynamic_objects_list.setMaximumHeight(100)
        self.dynamic_objects_list.setReadOnly(True)
        self.dynamic_objects_list.setStyleSheet("background-color: #f5f5f5; border: 1px solid #ddd; padding: 5px;")
        trajectory_layout.addWidget(self.dynamic_objects_list)
        
        # ç”¨æˆ·è½¨è¿¹å»ºè®®
        self.user_trajectory_label = QLabel("ç”¨æˆ·è½¨è¿¹å»ºè®®:")
        self.user_trajectory_label.setStyleSheet("font-weight: bold; color: #333;")
        trajectory_layout.addWidget(self.user_trajectory_label)
        
        self.user_trajectory_list = QTextEdit()
        self.user_trajectory_list.setMaximumHeight(100)
        self.user_trajectory_list.setReadOnly(True)
        self.user_trajectory_list.setStyleSheet("background-color: #f5f5f5; border: 1px solid #ddd; padding: 5px;")
        trajectory_layout.addWidget(self.user_trajectory_list)
        
        # è½¨è¿¹æ’­æŠ¥æ–‡æœ¬
        self.trajectory_voice_text = QTextEdit()
        self.trajectory_voice_text.setMaximumHeight(60)
        self.trajectory_voice_text.setReadOnly(True)
        self.trajectory_voice_text.setPlaceholderText("è½¨è¿¹é¢„æµ‹è¯­éŸ³æ’­æŠ¥å†…å®¹å°†æ˜¾ç¤ºåœ¨è¿™é‡Œ...")
        self.trajectory_voice_text.setStyleSheet("background-color: #d1ecf1; border: 1px solid #bee5eb; padding: 5px;")
        trajectory_layout.addWidget(QLabel("è½¨è¿¹æ’­æŠ¥:"))
        trajectory_layout.addWidget(self.trajectory_voice_text)
        
        layout.addWidget(trajectory_group)
        
        # è¯­éŸ³æ’­æŠ¥ç»„
        voice_group = QGroupBox("è¯­éŸ³æ’­æŠ¥çŠ¶æ€")
        voice_layout = QVBoxLayout(voice_group)
        
        self.voice_status_label = QLabel("æ’­æŠ¥çŠ¶æ€: å¾…æœº")
        self.voice_status_label.setStyleSheet("font-weight: bold; color: #666;")
        voice_layout.addWidget(self.voice_status_label)
        
        self.last_voice_label = QLabel("æœ€åæ’­æŠ¥: æ— ")
        self.last_voice_label.setStyleSheet("color: #666;")
        voice_layout.addWidget(self.last_voice_label)
        
        layout.addWidget(voice_group)
        
        layout.addStretch()
        return panel
    
    def create_status_bar(self):
        """åˆ›å»ºçŠ¶æ€æ """
        self.status_bar = QStatusBar()
        self.setStatusBar(self.status_bar)
        
        # ç³»ç»ŸçŠ¶æ€
        self.system_status_label = QLabel("ç³»ç»Ÿå°±ç»ª")
        self.status_bar.addWidget(self.system_status_label)
        
        # æ£€æµ‹çŠ¶æ€
        self.detection_status_bar_label = QLabel("æ£€æµ‹: æœªå¯åŠ¨")
        self.status_bar.addWidget(self.detection_status_bar_label)
        
        # è¯­éŸ³æ’­æŠ¥çŠ¶æ€
        self.voice_status_bar_label = QLabel("è¯­éŸ³: é™é»˜")
        self.status_bar.addWidget(self.voice_status_bar_label)
        
        # ç¯å¢ƒé£é™©è¯„ä¼°
        self.env_risk_bar_label = QLabel("ç¯å¢ƒ: å®‰å…¨")
        self.status_bar.addWidget(self.env_risk_bar_label)
        
        # è½¨è¿¹é¢„æµ‹çŠ¶æ€
        self.trajectory_status_bar_label = QLabel("è½¨è¿¹: æœªé¢„æµ‹")
        self.status_bar.addPermanentWidget(self.trajectory_status_bar_label)
        
        # æ—¶é—´æ˜¾ç¤º
        self.time_label = QLabel("")
        self.status_bar.addPermanentWidget(self.time_label)
        
        # æ›´æ–°æ—¶é—´æ˜¾ç¤º
        self.update_time_timer = QTimer()
        self.update_time_timer.timeout.connect(self.update_time_display)
        self.update_time_timer.start(1000)  # æ¯ç§’æ›´æ–°ä¸€æ¬¡
        
    def create_display_panel(self):
        """åˆ›å»ºæ˜¾ç¤ºé¢æ¿"""
        panel = QWidget()
        layout = QVBoxLayout(panel)
        
        # çŠ¶æ€æ 
        status_layout = QHBoxLayout()
        self.status_label = QLabel("è¯·é€‰æ‹©å›¾åƒè¿›è¡Œæ ‡æ³¨")
        self.status_label.setStyleSheet("font-size: 14px; color: #666; padding: 5px; background-color: #f0f0f0; border-radius: 3px;")
        status_layout.addWidget(self.status_label)
        
        self.mode_label = QLabel("å½“å‰æ¨¡å¼: ä¸¤ç‚¹æ¨¡å¼")
        self.mode_label.setStyleSheet("font-size: 14px; color: #2196f3; padding: 5px; background-color: #e3f2fd; border-radius: 3px;")
        status_layout.addWidget(self.mode_label)
        
        layout.addLayout(status_layout)
        
        # å›¾åƒæ˜¾ç¤ºåŒºåŸŸ
        self.image_display = TwoPointImageLabel("è¯·é€‰æ‹©å›¾åƒè¿›è¡Œæ ‡æ³¨")
        self.image_display.setMinimumSize(900, 700)
        self.image_display.mouse_pressed.connect(self.on_mouse_pressed)
        self.image_display.mouse_moved.connect(self.on_mouse_moved)
        self.image_display.mouse_released.connect(self.on_mouse_released)
        layout.addWidget(self.image_display)
        
        return panel
        
    def set_drawing_mode(self, mode):
        """è®¾ç½®ç»˜åˆ¶æ¨¡å¼"""
        self.drawing_mode = mode
        
        if mode == "two_point":
            self.two_point_mode_btn.setChecked(True)
            self.drag_mode_btn.setChecked(False)
            self.box_mode_btn.setChecked(False)
            self.mode_label.setText("å½“å‰æ¨¡å¼: ä¸¤ç‚¹æ¨¡å¼")
            self.mode_label.setStyleSheet("font-size: 14px; color: #2196f3; padding: 5px; background-color: #e3f2fd; border-radius: 3px;")
            self.clear_temp_points()
        elif mode == "drag":
            self.two_point_mode_btn.setChecked(False)
            self.drag_mode_btn.setChecked(True)
            self.box_mode_btn.setChecked(False)
            self.mode_label.setText("å½“å‰æ¨¡å¼: æ‹–æ‹½æ¨¡å¼")
            self.mode_label.setStyleSheet("font-size: 14px; color: #ff9800; padding: 5px; background-color: #fff3e0; border-radius: 3px;")
            self.clear_temp_points()
        elif mode == "box":
            self.two_point_mode_btn.setChecked(False)
            self.drag_mode_btn.setChecked(False)
            self.box_mode_btn.setChecked(True)
            self.mode_label.setText("å½“å‰æ¨¡å¼: æ¡†é€‰éšœç¢ç‰©")
            self.mode_label.setStyleSheet("font-size: 14px; color: #ff9800; padding: 5px; background-color: #fff3e0; border-radius: 3px;")
            self.clear_temp_points()
            
    def clear_temp_points(self):
        """æ¸…é™¤ä¸´æ—¶ç‚¹"""
        self.temp_points = []
        self.drag_start = None
        self.end_point = None
        self.box_start = None
        self.box_end = None
        self.update_display()
        
    def convert_display_to_image_coords(self, display_x, display_y):
        """å°†æ˜¾ç¤ºåæ ‡è½¬æ¢ä¸ºå›¾åƒåæ ‡"""
        # ä¼˜åŒ–åæ ‡æ˜ å°„ï¼Œå‡å°‘æ¼‚ç§»
        if not self.display_size or not self.original_size:
            return display_x, display_y
        disp_w, disp_h = self.display_size
        orig_w, orig_h = self.original_size
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹å’Œåç§»
        scale = min(disp_w / orig_w, disp_h / orig_h)
        pad_x = (disp_w - orig_w * scale) / 2
        pad_y = (disp_h - orig_h * scale) / 2
        x = int((display_x - pad_x) / scale)
        y = int((display_y - pad_y) / scale)
        x = max(0, min(orig_w - 1, x))
        y = max(0, min(orig_h - 1, y))
        return x, y
        
    def select_multiple_images(self):
        """é€‰æ‹©å¤šä¸ªå›¾åƒæ–‡ä»¶"""
        file_paths, _ = QFileDialog.getOpenFileNames(
            self, "é€‰æ‹©å¤šä¸ªå›¾åƒæ–‡ä»¶", "", "å›¾åƒæ–‡ä»¶ (*.jpg *.jpeg *.png *.bmp *.tiff)"
        )
        
        if file_paths:
            self.image_files = sorted(file_paths)
            self.current_image_index = 0
            self.load_image_by_index(0)
            self.update_file_info()
            self.enable_navigation()
            
    def select_single_image(self):
        """é€‰æ‹©å•å¼ å›¾åƒ"""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©å•å¼ å›¾åƒ", "", "å›¾åƒæ–‡ä»¶ (*.jpg *.jpeg *.png *.bmp *.tiff)"
        )
        
        if file_path:
            self.image_files = [file_path]
            self.current_image_index = 0
            self.load_image_by_index(0)
            self.update_file_info()
            self.enable_navigation()
            
    def load_from_images_folder(self):
        """ä»imagesæ–‡ä»¶å¤¹åŠ è½½"""
        images_dir = "images"
        if not os.path.exists(images_dir):
            QMessageBox.warning(self, "è­¦å‘Š", "imagesæ–‡ä»¶å¤¹ä¸å­˜åœ¨")
            return
            
        # æŸ¥æ‰¾æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
        self.image_files = []
        
        for ext in image_extensions:
            self.image_files.extend(glob.glob(os.path.join(images_dir, ext)))
            self.image_files.extend(glob.glob(os.path.join(images_dir, ext.upper())))
        
        self.image_files.sort()
        
        if self.image_files:
            self.current_image_index = 0
            self.load_image_by_index(0)
            self.update_file_info()
            self.enable_navigation()
            QMessageBox.information(self, "æˆåŠŸ", f"ä»imagesæ–‡ä»¶å¤¹åŠ è½½äº† {len(self.image_files)} å¼ å›¾åƒ")
        else:
            QMessageBox.warning(self, "è­¦å‘Š", "imagesæ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            
    def update_file_info(self):
        """æ›´æ–°æ–‡ä»¶ä¿¡æ¯"""
        if self.image_files:
            self.file_info_label.setText(f"å·²åŠ è½½ {len(self.image_files)} å¼ å›¾åƒ")
            self.file_info_label.setStyleSheet("color: #4caf50; padding: 5px; background-color: #e8f5e8; border-radius: 3px;")
        else:
            self.file_info_label.setText("æœªé€‰æ‹©æ–‡ä»¶")
            self.file_info_label.setStyleSheet("color: #666; padding: 5px; background-color: #f5f5f5; border-radius: 3px;")
            
    def enable_navigation(self):
        """å¯ç”¨å¯¼èˆªæŒ‰é’®"""
        self.prev_btn.setEnabled(len(self.image_files) > 1)
        self.next_btn.setEnabled(len(self.image_files) > 1)
        
    def load_image_by_index(self, index):
        """æ ¹æ®ç´¢å¼•åŠ è½½å›¾åƒ"""
        if 0 <= index < len(self.image_files):
            self.current_image_index = index
            image_path = self.image_files[index]
            self.load_image_from_path(image_path)
            self.update_image_info()
            
    def load_image_from_path(self, image_path):
        """ä»è·¯å¾„åŠ è½½å›¾åƒ"""
        if os.path.exists(image_path):
            self.current_image_path = image_path
            self.original_image = cv2.imread(image_path)
            
            # è®°å½•åŸå§‹å›¾åƒå°ºå¯¸
            self.original_size = (self.original_image.shape[1], self.original_image.shape[0])
            
            self.display_image = self.original_image.copy()
            self.annotations = []
            self.clear_temp_points()
            self.update_display()
            self.annotation_list.clear()
            
            # æ›´æ–°çª—å£æ ‡é¢˜
            self.setWindowTitle(f'ä¸¤ç‚¹æ¨¡å¼å’Œæ‹–æ‹½æ¨¡å¼æ ‡æ³¨å·¥å…· - {os.path.basename(image_path)}')
            self.status_label.setText(f"å½“å‰å›¾åƒ: {os.path.basename(image_path)}")
            
            # å°è¯•åŠ è½½å·²æœ‰æ ‡æ³¨
            self.load_existing_annotations()
            
            # è‡ªåŠ¨è¿›è¡Œç¯å¢ƒæ£€æµ‹å’Œè½¨è¿¹é¢„æµ‹
            self.auto_analyze_image()
            
    def load_previous_image(self):
        """åŠ è½½ä¸Šä¸€å¼ å›¾åƒ"""
        if self.current_image_index > 0:
            self.load_image_by_index(self.current_image_index - 1)
            
    def load_next_image(self):
        """åŠ è½½ä¸‹ä¸€å¼ å›¾åƒ"""
        if self.current_image_index < len(self.image_files) - 1:
            self.load_image_by_index(self.current_image_index + 1)
    
    def auto_analyze_image(self):
        """è‡ªåŠ¨åˆ†æå›¾åƒ"""
        if self.original_image is None:
            return
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œåˆ†æï¼Œé¿å…ç•Œé¢å¡é¡¿
        import threading
        
        def analyze():
            try:
                # ç¯å¢ƒæ£€æµ‹
                env_result = self.analyze_environment(self.original_image)
                
                # è½¨è¿¹é¢„æµ‹
                trajectory_result = self.predict_trajectory(self.original_image)
                
                print("âœ… å›¾åƒåˆ†æå®Œæˆ")
            except Exception as e:
                print(f"âŒ å›¾åƒåˆ†æå¤±è´¥: {e}")
        
        # å¯åŠ¨åå°åˆ†æçº¿ç¨‹
        analysis_thread = threading.Thread(target=analyze)
        analysis_thread.daemon = True
        analysis_thread.start()
    
    def change_voice_mode(self, mode):
        """æ”¹å˜è¯­éŸ³æ’­æŠ¥æ¨¡å¼"""
        self.voice_mode = mode
        print(f"è¯­éŸ³æ’­æŠ¥æ¨¡å¼å·²åˆ‡æ¢ä¸º: {mode}")
        
        if mode == "é™é»˜æ¨¡å¼":
            self.voice_enabled_btn.setText("ğŸ”‡ è¯­éŸ³æ’­æŠ¥: å…³é—­")
            self.voice_enabled_btn.setStyleSheet("QPushButton { background-color: #f44336; color: white; font-weight: bold; }")
        else:
            self.voice_enabled_btn.setText("ğŸ”Š è¯­éŸ³æ’­æŠ¥: å¼€å¯")
            self.voice_enabled_btn.setStyleSheet("QPushButton { background-color: #4caf50; color: white; font-weight: bold; }")
        
        # æ›´æ–°è¯­éŸ³çŠ¶æ€æ˜¾ç¤º
        self.update_voice_status()
    
    def toggle_voice(self):
        """åˆ‡æ¢è¯­éŸ³æ’­æŠ¥å¼€å…³"""
        self.voice_enabled = not self.voice_enabled
        if self.voice_enabled:
            self.voice_enabled_btn.setText("ğŸ”Š è¯­éŸ³æ’­æŠ¥: å¼€å¯")
            self.voice_enabled_btn.setStyleSheet("QPushButton { background-color: #4caf50; color: white; font-weight: bold; }")
        else:
            self.voice_enabled_btn.setText("ğŸ”‡ è¯­éŸ³æ’­æŠ¥: å…³é—­")
            self.voice_enabled_btn.setStyleSheet("QPushButton { background-color: #f44336; color: white; font-weight: bold; }")
        
        # æ›´æ–°è¯­éŸ³çŠ¶æ€æ˜¾ç¤º
        self.update_voice_status()
    
    def change_volume(self, value):
        """æ”¹å˜éŸ³é‡"""
        self.volume = value
        self.volume_label.setText(f"{value}%")
    
    def update_time_display(self):
        """æ›´æ–°æ—¶é—´æ˜¾ç¤º"""
        from datetime import datetime
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.time_label.setText(current_time)
    
    def voice_announce(self, message, priority=1, category="info"):
        """è¯­éŸ³æ’­æŠ¥ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œæ”¯æŒè¿ç»­å®Œæ•´æ’­æŠ¥"""
        if not self.voice_enabled or self.voice_mode == "é™é»˜æ¨¡å¼":
            return
        
        current_time = time.time()
        
        # æ£€æŸ¥å†·å´æ—¶é—´ï¼ˆæ ¹æ®ä¼˜å…ˆçº§è°ƒæ•´ï¼‰
        cooldown_time = 0.5 if priority >= 4 else 1.0 if priority >= 2 else 2.0
        if current_time - self.last_voice_time < cooldown_time:
            return
        
        # æ£€æŸ¥ä¼˜å…ˆçº§
        if priority < self.current_voice_priority:
            return
        
        # æ ¹æ®æ¨¡å¼è¿‡æ»¤æ¶ˆæ¯
        if self.voice_mode == "ç®€æ´æ¨¡å¼" and priority < 3:
            return
        
        # æ’­æŠ¥æ¶ˆæ¯
        print(f"ğŸ”Š è¯­éŸ³æ’­æŠ¥ [{category}]: {message}")
        
        # æ›´æ–°æ’­æŠ¥æ—¶é—´
        self.last_voice_time = current_time
        
        # å®é™…è¯­éŸ³åˆæˆ
        if self.voice_synthesis_available:
            try:
                # åˆ›å»ºè¯­éŸ³æ’­æŠ¥ä»»åŠ¡
                self.schedule_voice_task(message, priority)
                
            except Exception as e:
                print(f"âš ï¸ è¯­éŸ³æ’­æŠ¥è°ƒåº¦å¤±è´¥: {e}")
        
        # æ›´æ–°ç•Œé¢
        self.last_voice_label.setText(f"æœ€åæ’­æŠ¥: {message}")
        self.voice_status_label.setText(f"æ’­æŠ¥çŠ¶æ€: {category}")
        
        # æ›´æ–°çŠ¶æ€æ 
        self.voice_status_bar_label.setText(f"è¯­éŸ³: {category}")
        if category == "ç´§æ€¥":
            self.voice_status_bar_label.setStyleSheet("color: #d32f2f; font-weight: bold;")
        elif category == "è­¦å‘Š":
            self.voice_status_bar_label.setStyleSheet("color: #f57c00; font-weight: bold;")
        elif category == "æ£€æµ‹":
            self.voice_status_bar_label.setStyleSheet("color: #2196f3; font-weight: bold;")
        else:
            self.voice_status_bar_label.setStyleSheet("color: #4caf50;")
    
    def schedule_voice_task(self, message, priority=1):
        """è°ƒåº¦è¯­éŸ³æ’­æŠ¥ä»»åŠ¡ - æ”¯æŒé˜Ÿåˆ—ç®¡ç†å’Œè¿ç»­æ’­æŠ¥"""
        try:
            import time
            
            # æ£€æŸ¥è¯­éŸ³ç³»ç»Ÿæ˜¯å¦å·²åˆå§‹åŒ–
            if not hasattr(self, 'voice_queue'):
                print("âš ï¸ è¯­éŸ³ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œè·³è¿‡æ’­æŠ¥")
                return
            
            # å°†è¯­éŸ³ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—ï¼ˆä¼˜å…ˆçº§è¶Šé«˜ï¼Œæ•°å­—è¶Šå°ï¼‰
            self.voice_queue.put((priority, time.time(), message))
            
        except Exception as e:
            print(f"âš ï¸ è¯­éŸ³ä»»åŠ¡è°ƒåº¦å¤±è´¥: {e}")
    
    def start_voice_worker(self):
        """å¯åŠ¨è¯­éŸ³å·¥ä½œçº¿ç¨‹"""
        def voice_worker():
            import queue
            while True:
                try:
                    # ä»é˜Ÿåˆ—è·å–è¯­éŸ³ä»»åŠ¡
                    priority, timestamp, message = self.voice_queue.get(timeout=1)
                    
                    with self.voice_lock:
                        if self.is_voice_playing:
                            # å¦‚æœæ­£åœ¨æ’­æ”¾ï¼Œç­‰å¾…å½“å‰æ’­æ”¾å®Œæˆ
                            continue
                        
                        self.is_voice_playing = True
                    
                    # æ‰§è¡Œè¯­éŸ³æ’­æŠ¥
                    self.execute_voice_playback(message)
                    
                    with self.voice_lock:
                        self.is_voice_playing = False
                    
                    # æ ‡è®°ä»»åŠ¡å®Œæˆ
                    self.voice_queue.task_done()
                    
                except queue.Empty:
                    continue
                except Exception as e:
                    print(f"âš ï¸ è¯­éŸ³å·¥ä½œçº¿ç¨‹é”™è¯¯: {e}")
                    with self.voice_lock:
                        self.is_voice_playing = False
        
        # å¯åŠ¨è¯­éŸ³å·¥ä½œçº¿ç¨‹
        self.voice_thread = threading.Thread(target=voice_worker, daemon=True)
        self.voice_thread.start()
        print("âœ… è¯­éŸ³å·¥ä½œçº¿ç¨‹å·²å¯åŠ¨")
    
    def execute_voice_playback(self, message):
        """æ‰§è¡Œè¯­éŸ³æ’­æŠ¥"""
        try:
            import pyttsx3
            
            # åˆ›å»ºæˆ–é‡ç”¨è¯­éŸ³å¼•æ“
            if self.global_tts_engine is None:
                self.global_tts_engine = pyttsx3.init()
                
                # è®¾ç½®è¯­éŸ³å‚æ•°
                self.global_tts_engine.setProperty('rate', 150)
                self.global_tts_engine.setProperty('volume', self.volume / 100.0)
                
                # å°è¯•è®¾ç½®ä¸­æ–‡è¯­éŸ³
                voices = self.global_tts_engine.getProperty('voices')
                if voices:
                    for voice in voices:
                        voice_name = voice.name.lower()
                        voice_id = voice.id.lower()
                        if any(keyword in voice_name for keyword in ['chinese', 'zh', 'mandarin', 'ä¸­æ–‡']):
                            self.global_tts_engine.setProperty('voice', voice.id)
                            print(f"âœ… ä½¿ç”¨ä¸­æ–‡è¯­éŸ³: {voice.name}")
                            break
                
                # è®¾ç½®è¯­éŸ³å®Œæˆå›è°ƒ
                def on_finish(utterance_id):
                    print(f"âœ… è¯­éŸ³æ’­æŠ¥å®Œæˆ: {utterance_id}")
                
                def on_error(utterance_id):
                    print(f"âŒ è¯­éŸ³æ’­æŠ¥é”™è¯¯: {utterance_id}")
                
                self.global_tts_engine.connect('finished-utterance', on_finish)
                self.global_tts_engine.connect('error', on_error)
            
            # æ’­æŠ¥æ¶ˆæ¯
            utterance_id = f"voice_{int(time.time() * 1000)}"
            self.global_tts_engine.say(message, utterance_id)
            self.global_tts_engine.runAndWait()
            
        except Exception as e:
            print(f"âš ï¸ è¯­éŸ³æ’­æŠ¥æ‰§è¡Œå¤±è´¥: {e}")
            # å¦‚æœå…¨å±€å¼•æ“æœ‰é—®é¢˜ï¼Œå°è¯•é‡æ–°åˆ›å»º
            try:
                if self.global_tts_engine:
                    self.global_tts_engine.stop()
                self.global_tts_engine = None
            except:
                pass
    
    def reset_voice_priority(self):
        """é‡ç½®è¯­éŸ³ä¼˜å…ˆçº§"""
        self.current_voice_priority = 0
    
    def open_annotation_tool(self):
        """æ‰“å¼€ç›²é“æ ‡æ³¨å·¥å…·çª—å£"""
        try:
            from core.annotation_window import AnnotationWindow
            self.annotation_window = AnnotationWindow(self)
            self.annotation_window.show()
        except ImportError:
            QMessageBox.information(self, "æç¤º", "ç›²é“æ ‡æ³¨å·¥å…·åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...")
    
    def open_training_interface(self):
        """æ‰“å¼€æ¨¡å‹è®­ç»ƒç•Œé¢"""
        try:
            from model_training_interface import ModelTrainingInterface
            self.training_window = ModelTrainingInterface()
            self.training_window.show()
        except ImportError:
            QMessageBox.information(self, "æç¤º", "æ¨¡å‹è®­ç»ƒç•Œé¢åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...")
            
    def update_image_info(self):
        """æ›´æ–°å›¾åƒä¿¡æ¯"""
        if self.image_files:
            self.image_info_label.setText(f"{self.current_image_index + 1}/{len(self.image_files)}")
            
    def load_existing_annotations(self):
        """åŠ è½½å·²æœ‰æ ‡æ³¨"""
        if not self.current_image_path:
            return
            
        image_name = os.path.basename(self.current_image_path)
        annotation_file = f"annotations/{image_name.replace('.', '_')}_annotations.json"
        
        if os.path.exists(annotation_file):
            try:
                with open(annotation_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                self.annotations = data.get('annotations', [])
                self.update_display()
                self.update_annotation_list()
                
                self.status_label.setText(f"å·²åŠ è½½ {len(self.annotations)} ä¸ªæ ‡æ³¨")
            except Exception as e:
                print(f"åŠ è½½æ ‡æ³¨å¤±è´¥: {e}")
                
    def on_mouse_pressed(self, event):
        """é¼ æ ‡æŒ‰ä¸‹äº‹ä»¶"""
        if event.button() == Qt.LeftButton and self.current_image_path:
            if self.drawing_mode == "two_point":
                image_x, image_y = self.convert_display_to_image_coords(event.pos().x(), event.pos().y())
                self.temp_points.append((image_x, image_y))
                if len(self.temp_points) == 2:
                    annotation = {
                        'start': self.temp_points[0],
                        'end': self.temp_points[1],
                        'type': 'blind_path_line'
                    }
                    self.annotations.append(annotation)
                    self.temp_points = []
                    self.update_annotation_list()
                self.update_display()
            elif self.drawing_mode == "drag":
                image_x, image_y = self.convert_display_to_image_coords(event.pos().x(), event.pos().y())
                self.drawing = True
                self.drag_start = (image_x, image_y)
                self.end_point = event.pos()
            elif self.drawing_mode == "box":
                image_x, image_y = self.convert_display_to_image_coords(event.pos().x(), event.pos().y())
                self.drawing = True
                self.box_start = (image_x, image_y)
                self.box_end = (image_x, image_y)
        self.update_display()
                
    def on_mouse_moved(self, event):
        """é¼ æ ‡ç§»åŠ¨äº‹ä»¶"""
        if self.drawing and self.current_image_path:
            if self.drawing_mode == "drag":
                self.end_point = event.pos()
            elif self.drawing_mode == "box":
                image_x, image_y = self.convert_display_to_image_coords(event.pos().x(), event.pos().y())
                self.box_end = (image_x, image_y)
            self.update_display()
            
    def on_mouse_released(self, event):
        """é¼ æ ‡é‡Šæ”¾äº‹ä»¶"""
        if self.drawing and self.current_image_path and event.button() == Qt.LeftButton:
            if self.drawing_mode == "drag":
                image_x, image_y = self.convert_display_to_image_coords(event.pos().x(), event.pos().y())
                self.drawing = False
                if self.drag_start:
                    annotation = {
                        'start': self.drag_start,
                        'end': (image_x, image_y),
                        'type': 'blind_path_line'
                    }
                    self.annotations.append(annotation)
                    self.update_annotation_list()
                    self.drag_start = None
                    self.end_point = None
                self.update_display()
            elif self.drawing_mode == "box":
                image_x, image_y = self.convert_display_to_image_coords(event.pos().x(), event.pos().y())
                self.drawing = False
                if self.box_start:
                    x_min, y_min = self.box_start
                    x_max, y_max = image_x, image_y
                    x_min, x_max = min(x_min, x_max), max(x_min, x_max)
                    y_min, y_max = min(y_min, y_max), max(y_min, y_max)
                    annotation = {
                        'type': 'obstacle_box',
                        'box': (x_min, y_min, x_max, y_max)
                    }
                    self.annotations.append(annotation)
                    self.update_annotation_list()
                    self.box_start = None
                    self.box_end = None
                self.update_display()
            
    def update_display(self):
        """æ›´æ–°æ˜¾ç¤º"""
        if not hasattr(self, 'original_image'):
            return
            
        # å¤åˆ¶åŸå›¾
        self.display_image = self.original_image.copy()
        
        # ç»˜åˆ¶ä¸´æ—¶ç‚¹ï¼ˆä¸¤ç‚¹æ¨¡å¼ï¼‰
        for i, point in enumerate(self.temp_points):
            x, y = point
            cv2.circle(self.display_image, (x, y), self.point_size, (255, 0, 0), -1)
            cv2.putText(self.display_image, f"P{i+1}", (x+5, y-5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
            
            # å¦‚æœæœ‰ä¸¤ä¸ªç‚¹ï¼Œæ˜¾ç¤ºè¿æ¥çº¿
            if len(self.temp_points) == 2 and i == 0:
                next_point = self.temp_points[1]
                cv2.line(self.display_image, (x, y), next_point, (255, 0, 0), 2)
        
        # ç»˜åˆ¶æ‹–æ‹½çº¿ï¼ˆæ‹–æ‹½æ¨¡å¼ï¼‰
        if self.drawing and self.drag_start and self.end_point:
            # è½¬æ¢ç»ˆç‚¹åæ ‡
            end_x, end_y = self.convert_display_to_image_coords(self.end_point.x(), self.end_point.y())
            cv2.line(self.display_image, 
                    self.drag_start,
                    (end_x, end_y),
                    (255, 0, 0), 2)
        
        # ç»˜åˆ¶éšœç¢ç‰©æ¡†
        for i, annotation in enumerate(self.annotations):
            if annotation['type'] == 'obstacle_box':
                x_min, y_min, x_max, y_max = annotation['box']
                cv2.rectangle(self.display_image, (x_min, y_min), (x_max, y_max), (0, 0, 255), self.line_width)
                cv2.putText(self.display_image, f"B{i+1}", (x_min, y_min-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)
        # ç»˜åˆ¶æ­£åœ¨æ‹–æ‹½çš„éšœç¢ç‰©æ¡†
        if self.drawing and self.drawing_mode == "box" and self.box_start and self.box_end:
            x1, y1 = self.box_start
            x2, y2 = self.box_end
            cv2.rectangle(self.display_image, (x1, y1), (x2, y2), (0, 0, 255), 2)
        
        # ç»˜åˆ¶å·²ä¿å­˜çš„çº¿æ®µæ ‡æ³¨
        for i, annotation in enumerate(self.annotations):
            if annotation['type'] == 'blind_path_line':
                start = annotation['start']
                end = annotation['end']
                cv2.line(self.display_image, start, end, (0, 255, 0), self.line_width)
                cv2.putText(self.display_image, f"L{i+1}", start, cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        
        # æ˜¾ç¤ºå›¾åƒ
        height, width, channel = self.display_image.shape
        bytes_per_line = 3 * width
        q_image = QImage(self.display_image.data, width, height, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)
        
        scaled_pixmap = pixmap.scaled(
            self.image_display.size(), 
            Qt.KeepAspectRatio, 
            Qt.SmoothTransformation
        )
        
        # è®°å½•æ˜¾ç¤ºå°ºå¯¸
        self.display_size = (scaled_pixmap.width(), scaled_pixmap.height())
        
        self.image_display.setPixmap(scaled_pixmap)
        self.image_display.setStyleSheet("border: none;")
        
    def update_annotation_list(self):
        """æ›´æ–°æ ‡æ³¨åˆ—è¡¨"""
        self.annotation_list.clear()
        
        # æ·»åŠ çº¿æ®µ
        for i, annotation in enumerate(self.annotations):
            if annotation['type'] == 'blind_path_line':
                start = annotation['start']
                end = annotation['end']
                self.annotation_list.addItem(f"ç›²é“çº¿æ®µ {i+1}: ({start[0]},{start[1]}) -> ({end[0]},{end[1]})")
            elif annotation['type'] == 'obstacle_box':
                x_min, y_min, x_max, y_max = annotation['box']
                self.annotation_list.addItem(f"éšœç¢ç‰©æ¡† {i+1}: ({x_min},{y_min}) -> ({x_max},{y_max})")
                
    def save_annotations(self):
        """ä¿å­˜æ ‡æ³¨"""
        if not self.current_image_path:
            QMessageBox.warning(self, "è­¦å‘Š", "æ²¡æœ‰åŠ è½½å›¾åƒ")
            return
            
        # ä¿å­˜æ ‡æ³¨æ•°æ®
        image_name = os.path.basename(self.current_image_path)
        annotation_data = {
            'image_path': self.current_image_path,
            'annotations': self.annotations,
            'timestamp': time.time()
        }
        
        # åˆ›å»ºæ ‡æ³¨ç›®å½•
        os.makedirs('annotations', exist_ok=True)
        
        # ä¿å­˜ä¸ºJSONæ–‡ä»¶
        annotation_file = f"annotations/{image_name.replace('.', '_')}_annotations.json"
        with open(annotation_file, 'w', encoding='utf-8') as f:
            json.dump(annotation_data, f, ensure_ascii=False, indent=2)
            
        QMessageBox.information(self, "æˆåŠŸ", f"æ ‡æ³¨å·²ä¿å­˜åˆ°: {annotation_file}")
        
        # å¦‚æœæœ‰ä¸‹ä¸€å¼ å›¾åƒï¼Œè¯¢é—®æ˜¯å¦è·³è½¬
        if self.image_files and self.current_image_index < len(self.image_files) - 1:
            reply = QMessageBox.question(self, "ç»§ç»­æ ‡æ³¨", 
                                       "æ˜¯å¦è·³è½¬åˆ°ä¸‹ä¸€å¼ å›¾åƒç»§ç»­æ ‡æ³¨ï¼Ÿ",
                                       QMessageBox.Yes | QMessageBox.No)
            if reply == QMessageBox.Yes:
                self.load_next_image()
                
        # ä¿å­˜ä¸ºYOLOæ ¼å¼txtï¼ˆåªä¿å­˜éšœç¢ç‰©æ¡†ï¼Œç±»åˆ«1ï¼‰
        yolo_label_dir = r"yolo_dataset/labels"
        os.makedirs(yolo_label_dir, exist_ok=True)
        txt_name = os.path.splitext(os.path.basename(self.current_image_path))[0] + ".txt"
        txt_path = os.path.join(yolo_label_dir, txt_name)
        img = cv2.imread(self.current_image_path)
        h, w = img.shape[:2]
        with open(txt_path, 'w') as f:
            for ann in self.annotations:
                if ann['type'] == 'obstacle_box':
                    x_min, y_min, x_max, y_max = ann['box']
                    # è½¬YOLOæ ¼å¼
                    x_center = (x_min + x_max) / 2 / w
                    y_center = (y_min + y_max) / 2 / h
                    bw = (x_max - x_min) / w
                    bh = (y_max - y_min) / h
                    f.write(f"1 {x_center:.6f} {y_center:.6f} {bw:.6f} {bh:.6f}\n")
                
    def clear_annotations(self):
        """æ¸…é™¤å½“å‰æ ‡æ³¨"""
        self.annotations = []
        self.clear_temp_points()
        self.annotation_list.clear()
        if hasattr(self, 'original_image'):
            self.update_display()
            
    def delete_selected_annotation(self):
        """åˆ é™¤é€‰ä¸­çš„æ ‡æ³¨"""
        current_row = self.annotation_list.currentRow()
        if current_row >= 0 and current_row < len(self.annotations):
            del self.annotations[current_row]
            self.update_display()
            self.update_annotation_list()

    def undo_last_annotation(self):
        if self.annotations:
            self.annotations.pop()
            self.update_annotation_list()
            self.update_display()

    def analyze_environment(self, frame):
        """åˆ†æç¯å¢ƒ"""
        if not self.env_detector:
            return None
        
        try:
            # è·å–å½“å‰å¸§çš„æ£€æµ‹ç»“æœ
            detections = self.detect_objects_in_frame(frame)
            
            # è½¬æ¢æ£€æµ‹æ ¼å¼
            detection_objects = []
            for detection in detections:
                if 'bbox' in detection:
                    detection_objects.append({
                        'bbox': detection['bbox'],
                        'confidence': detection.get('confidence', 0.8),
                        'class': detection.get('class_id', 0)
                    })
            
            # æ‰§è¡Œç¯å¢ƒæ£€æµ‹
            env_result = self.env_detector.detect_environment(frame, detection_objects)
            
            # å®æ—¶è¯­éŸ³æ’­æŠ¥ç¯å¢ƒä¿¡æ¯
            if env_result and self.voice_enabled:
                self.real_time_environment_voice_announce(env_result, detections)
            
            return env_result
        except Exception as e:
            print(f"ç¯å¢ƒæ£€æµ‹å¤±è´¥: {e}")
            return None
    
    def predict_trajectory(self, frame):
        """é¢„æµ‹è½¨è¿¹"""
        if not self.trajectory_predictor:
            return None
        
        try:
            # è½¬æ¢æ£€æµ‹æ ¼å¼
            detections = []
            for annotation in self.annotations:
                if 'bbox' in annotation:
                    bbox = annotation['bbox']
                    detections.append([
                        bbox[0], bbox[1], bbox[2], bbox[3],  # x1, y1, x2, y2
                        0.8,  # confidence
                        0     # class
                    ])
            
            # æ‰§è¡Œè½¨è¿¹é¢„æµ‹
            result = self.trajectory_predictor.process_frame(frame, detections)
            
            # æ›´æ–°ç•Œé¢æ˜¾ç¤º
            self.update_trajectory_display(result)
            
            return result
        except Exception as e:
            print(f"è½¨è¿¹é¢„æµ‹å¤±è´¥: {e}")
            return None
    
    def update_environment_display(self, env_result, detections):
        """æ›´æ–°ç¯å¢ƒæ£€æµ‹æ˜¾ç¤º"""
        if not env_result:
            return
        
        # æ›´æ–°ç¯å¢ƒå®‰å…¨çŠ¶æ€
        overall_safety = env_result.get('overall_safety_level', 'safe')
        safety_score = env_result.get('safety_score', 1.0)
        safety_percentage = int(safety_score * 100)
        
        # ç¯å¢ƒå®‰å…¨çŠ¶æ€æ˜¾ç¤º
        if overall_safety == 'high_risk':
            self.env_safety_label.setText(f"ç¯å¢ƒå®‰å…¨: é«˜é£é™©")
            self.env_safety_label.setStyleSheet("font-weight: bold; color: #d32f2f; padding: 8px; background-color: #ffebee; border-radius: 5px;")
        elif overall_safety == 'medium_risk':
            self.env_safety_label.setText(f"ç¯å¢ƒå®‰å…¨: ä¸­ç­‰é£é™©")
            self.env_safety_label.setStyleSheet("font-weight: bold; color: #f57c00; padding: 8px; background-color: #fff3e0; border-radius: 5px;")
        else:
            self.env_safety_label.setText(f"ç¯å¢ƒå®‰å…¨: å®‰å…¨")
            self.env_safety_label.setStyleSheet("font-weight: bold; color: #4caf50; padding: 8px; background-color: #e8f5e8; border-radius: 5px;")
        
        # æ›´æ–°å®‰å…¨è¯„åˆ†
        self.env_score_label.setText(f"å®‰å…¨è¯„åˆ†: {safety_percentage}%")
        if safety_percentage >= 80:
            self.env_score_label.setStyleSheet("font-weight: bold; color: #4caf50; padding: 8px; background-color: #e8f5e8; border-radius: 5px;")
        elif safety_percentage >= 60:
            self.env_score_label.setStyleSheet("font-weight: bold; color: #f57c00; padding: 8px; background-color: #fff3e0; border-radius: 5px;")
        else:
            self.env_score_label.setStyleSheet("font-weight: bold; color: #d32f2f; padding: 8px; background-color: #ffebee; border-radius: 5px;")
        
        # æ˜¾ç¤ºè¯¦ç»†ç¯å¢ƒä¿¡æ¯
        env_details = self.get_environment_details(env_result, detections)
        if env_details:
            self.env_details_text.setPlainText(env_details)
        else:
            self.env_details_text.setPlainText("æš‚æ— ç¯å¢ƒæ£€æµ‹è¯¦æƒ…")
        
        # æ›´æ–°è­¦å‘Šä¿¡æ¯
        warnings = env_result.get('warnings', [])
        emergency_alerts = env_result.get('emergency_alerts', [])
        
        warning_text = ""
        if emergency_alerts:
            warning_text += "ğŸš¨ ç´§æ€¥è­¦æŠ¥:\n"
            for alert in emergency_alerts[:3]:
                warning_text += f"â€¢ {alert}\n"
        
        if warnings:
            if warning_text:
                warning_text += "\n"
            warning_text += "âš ï¸ è­¦å‘Šä¿¡æ¯:\n"
            for warning in warnings[:3]:
                warning_text += f"â€¢ {warning}\n"
        
        if warning_text:
            self.env_warnings_text.setPlainText(warning_text)
        else:
            self.env_warnings_text.setPlainText("æš‚æ— è­¦å‘Šä¿¡æ¯")
        
        # ç”Ÿæˆç¯å¢ƒæ’­æŠ¥æ–‡æœ¬
        env_voice_content = self.generate_environment_voice_content(detections, env_result)
        
        # è¯­éŸ³æ’­æŠ¥
        if env_voice_content:
            priority = 5 if overall_safety == 'high_risk' else 3 if overall_safety == 'medium_risk' else 2
            category = "ç´§æ€¥" if overall_safety == 'high_risk' else "è­¦å‘Š" if overall_safety == 'medium_risk' else "æ£€æµ‹"
            self.voice_announce(env_voice_content, priority=priority, category=category)
        
        # æ›´æ–°çŠ¶æ€æ ç¯å¢ƒé£é™©è¯„ä¼°
        if overall_safety == 'high_risk':
            self.env_risk_bar_label.setText("ç¯å¢ƒ: é«˜é£é™©")
            self.env_risk_bar_label.setStyleSheet("color: #d32f2f; font-weight: bold;")
        elif overall_safety == 'medium_risk':
            self.env_risk_bar_label.setText("ç¯å¢ƒ: ä¸­ç­‰é£é™©")
            self.env_risk_bar_label.setStyleSheet("color: #f57c00; font-weight: bold;")
        else:
            self.env_risk_bar_label.setText("ç¯å¢ƒ: å®‰å…¨")
    
    def get_environment_details(self, env_result, detections=None):
        """è·å–ç¯å¢ƒæ£€æµ‹è¯¦ç»†ä¿¡æ¯"""
        details = []
        
        # æ£€æµ‹åˆ°çš„ç¯å¢ƒäº‹ç‰©
        if detections:
            details.append("ğŸ” æ£€æµ‹åˆ°çš„ç¯å¢ƒäº‹ç‰©:")
            for i, detection in enumerate(detections, 1):
                obj_type = detection.get('class_name', 'æœªçŸ¥ç‰©ä½“')
                confidence = detection.get('confidence', 0)
                bbox = detection.get('bbox', [0, 0, 0, 0])
                x1, y1, x2, y2 = bbox
                width = x2 - x1
                height = y2 - y1
                
                # åˆ¤æ–­ç‰©ä½“ä½ç½®
                position = self.get_object_position(x1, y1, x2, y2)
                
                details.append(f"  {i}. {obj_type} ({position}, ç½®ä¿¡åº¦: {confidence:.2f}, å¤§å°: {width}x{height})")
            
            if not detections:
                details.append("  æš‚æ— æ£€æµ‹åˆ°çš„ç¯å¢ƒäº‹ç‰©")
        else:
            details.append("ğŸ” æ£€æµ‹åˆ°çš„ç¯å¢ƒäº‹ç‰©: æš‚æ— ")
        
        # å¤©æ°”æ¡ä»¶
        weather_info = env_result.get('weather_conditions')
        if weather_info:
            weather_type = weather_info.get('weather_type', 'clear')
            visibility = weather_info.get('visibility_level', 'good')
            safety_impact = weather_info.get('safety_impact', 'low')
            details.append(f"\nğŸŒ¤ï¸ å¤©æ°”æ¡ä»¶: {weather_type} (èƒ½è§åº¦: {visibility}, å½±å“: {safety_impact})")
        
        # å…‰ç…§æ¡ä»¶
        lighting_info = env_result.get('lighting_conditions')
        if lighting_info:
            lighting_level = lighting_info.get('lighting_level', 'normal')
            visibility_quality = lighting_info.get('visibility_quality', 'good')
            safety_impact = lighting_info.get('safety_impact', 'low')
            details.append(f"ğŸ’¡ å…‰ç…§æ¡ä»¶: {lighting_level} (è´¨é‡: {visibility_quality}, å½±å“: {safety_impact})")
        
        # è·¯é¢æ¡ä»¶
        surface_info = env_result.get('surface_conditions')
        if surface_info:
            surface_type = surface_info.get('surface_type', 'smooth')
            safety_level = surface_info.get('safety_level', 'safe')
            walking_difficulty = surface_info.get('walking_difficulty', 'easy')
            details.append(f"ğŸ›£ï¸ è·¯é¢æ¡ä»¶: {surface_type} (å®‰å…¨: {safety_level}, éš¾åº¦: {walking_difficulty})")
        
        # æ–½å·¥åŒºåŸŸ
        construction_info = env_result.get('construction_zone')
        if construction_info and construction_info.get('is_construction_zone'):
            zone_type = construction_info.get('zone_type', 'unknown')
            safety_level = construction_info.get('safety_level', 'safe')
            confidence = construction_info.get('confidence', 0)
            details.append(f"ğŸš§ æ–½å·¥åŒºåŸŸ: {zone_type} (å®‰å…¨: {safety_level}, ç½®ä¿¡åº¦: {confidence:.2f})")
        
        # åå­—è·¯å£
        intersection_info = env_result.get('intersection')
        if intersection_info and intersection_info.get('is_intersection'):
            traffic_light = intersection_info.get('traffic_light_state', 'unknown')
            crosswalk = intersection_info.get('crosswalk_detected', False)
            details.append(f"ğŸš¦ åå­—è·¯å£: äº¤é€šç¯({traffic_light}), æ–‘é©¬çº¿({'æ˜¯' if crosswalk else 'å¦'})")
        
        # æ‹¥æŒ¤ç¨‹åº¦
        crowd_info = env_result.get('crowd_density')
        if crowd_info:
            density_level = crowd_info.get('density_level', 'low')
            navigation_difficulty = crowd_info.get('navigation_difficulty', 'easy')
            details.append(f"ğŸ‘¥ æ‹¥æŒ¤ç¨‹åº¦: {density_level} (å¯¼èˆªéš¾åº¦: {navigation_difficulty})")
        
        return "\n".join(details) if details else "æš‚æ— ç¯å¢ƒæ£€æµ‹è¯¦æƒ…"
    
    def generate_environment_voice_content(self, detections, env_result):
        """ç”Ÿæˆç¯å¢ƒæ£€æµ‹è¯­éŸ³æ’­æŠ¥å†…å®¹"""
        content_parts = []
        
        # æ£€æµ‹åˆ°çš„ç‰©ä½“æ’­æŠ¥
        if detections:
            dynamic_objects = [d for d in detections if d.get('class_id') == 1]  # åŠ¨æ€éšœç¢
            static_objects = [d for d in detections if d.get('class_id') == 0]  # é™æ€éšœç¢
            ground_hazards = [d for d in detections if d.get('class_id') == 2]  # åœ°é¢å±é™©
            
            if dynamic_objects:
                for obj in dynamic_objects:
                    obj_name = obj.get('class_name', 'ç‰©ä½“')
                    bbox = obj.get('bbox', [0, 0, 0, 0])
                    x1, y1, x2, y2 = bbox
                    position = self.get_object_position(x1, y1, x2, y2)
                    content_parts.append(f"å‰æ–¹{position}æ£€æµ‹åˆ°åŠ¨æ€éšœç¢ç‰©{obj_name}")
            
            if ground_hazards:
                for obj in ground_hazards:
                    obj_name = obj.get('class_name', 'ç‰©ä½“')
                    bbox = obj.get('bbox', [0, 0, 0, 0])
                    x1, y1, x2, y2 = bbox
                    position = self.get_object_position(x1, y1, x2, y2)
                    content_parts.append(f"å‰æ–¹{position}æ£€æµ‹åˆ°åœ°é¢å±é™©{obj_name}")
            
            if static_objects:
                for obj in static_objects:
                    obj_name = obj.get('class_name', 'ç‰©ä½“')
                    bbox = obj.get('bbox', [0, 0, 0, 0])
                    x1, y1, x2, y2 = bbox
                    position = self.get_object_position(x1, y1, x2, y2)
                    content_parts.append(f"å‰æ–¹{position}æ£€æµ‹åˆ°é™æ€éšœç¢ç‰©{obj_name}")
        
        # ç¯å¢ƒé£é™©æ’­æŠ¥
        overall_safety = env_result.get('overall_safety_level', 'safe')
        safety_score = env_result.get('safety_score', 1.0)
        safety_percentage = int(safety_score * 100)
        
        if overall_safety == 'high_risk':
            content_parts.append(f"ç¯å¢ƒé«˜é£é™©ï¼Œå®‰å…¨è¯„åˆ†{safety_percentage}%ï¼Œè¯·å°å¿ƒ")
        elif overall_safety == 'medium_risk':
            content_parts.append(f"ç¯å¢ƒä¸­ç­‰é£é™©ï¼Œå®‰å…¨è¯„åˆ†{safety_percentage}%ï¼Œè¯·æ³¨æ„")
        else:
            content_parts.append(f"ç¯å¢ƒå®‰å…¨ï¼Œå®‰å…¨è¯„åˆ†{safety_percentage}%")
        
        # å¤©æ°”æ¡ä»¶æ’­æŠ¥
        weather_info = env_result.get('weather_conditions')
        if weather_info:
            weather_type = weather_info.get('weather_type', 'clear')
            if weather_type == 'rain':
                content_parts.append("æ£€æµ‹åˆ°é›¨å¤©ï¼Œè·¯é¢å¯èƒ½æ¹¿æ»‘")
            elif weather_type == 'fog':
                content_parts.append("æ£€æµ‹åˆ°é›¾å¤©ï¼Œèƒ½è§åº¦è¾ƒä½")
            elif weather_type == 'snow':
                content_parts.append("æ£€æµ‹åˆ°é›ªå¤©ï¼Œè·¯é¢å¯èƒ½ç»“å†°")
        
        # å…‰ç…§æ¡ä»¶æ’­æŠ¥
        lighting_info = env_result.get('lighting_conditions')
        if lighting_info:
            lighting_level = lighting_info.get('lighting_level', 'normal')
            if lighting_level == 'very_dark':
                content_parts.append("ç¯å¢ƒå¾ˆæš—ï¼Œè¯·å°å¿ƒè¡Œèµ°")
            elif lighting_level == 'dark':
                content_parts.append("ç¯å¢ƒè¾ƒæš—ï¼Œè¯·æ³¨æ„å®‰å…¨")
            elif lighting_level == 'very_bright':
                content_parts.append("ç¯å¢ƒå¾ˆäº®ï¼Œå¯èƒ½å½±å“è§†çº¿")
        
        # è·¯é¢æ¡ä»¶æ’­æŠ¥
        surface_info = env_result.get('surface_conditions')
        if surface_info:
            surface_type = surface_info.get('surface_type', 'smooth')
            if surface_type == 'wet':
                content_parts.append("è·¯é¢æ¹¿æ»‘ï¼Œè¯·å°å¿ƒè¡Œèµ°")
            elif surface_type == 'uneven':
                content_parts.append("è·¯é¢ä¸å¹³ï¼Œè¯·æ³¨æ„è„šä¸‹")
            elif surface_type == 'rough':
                content_parts.append("è·¯é¢ç²—ç³™ï¼Œè¡Œèµ°æ—¶è¯·æ³¨æ„")
        
        # æ–½å·¥åŒºåŸŸæ’­æŠ¥
        construction_info = env_result.get('construction_zone')
        if construction_info and construction_info.get('is_construction_zone'):
            content_parts.append("å‰æ–¹æ–½å·¥åŒºåŸŸï¼Œè¯·ç»•è¡Œ")
        
        # åå­—è·¯å£æ’­æŠ¥
        intersection_info = env_result.get('intersection')
        if intersection_info and intersection_info.get('is_intersection'):
            content_parts.append("å‰æ–¹åå­—è·¯å£ï¼Œè¯·æ³¨æ„äº¤é€šä¿¡å·")
        
        # æ‹¥æŒ¤ç¨‹åº¦æ’­æŠ¥
        crowd_info = env_result.get('crowd_density')
        if crowd_info:
            density_level = crowd_info.get('density_level', 'low')
            if density_level == 'high':
                content_parts.append("äººç¾¤æ‹¥æŒ¤ï¼Œè¯·å°å¿ƒé¿è®©")
            elif density_level == 'medium':
                content_parts.append("äººç¾¤è¾ƒå¤šï¼Œè¯·æ³¨æ„å®‰å…¨")
        
        # ç´§æ€¥è­¦æŠ¥æ’­æŠ¥
        emergency_alerts = env_result.get('emergency_alerts', [])
        if emergency_alerts:
            content_parts.append("ç´§æ€¥è­¦æŠ¥ï¼š" + "ï¼›".join(emergency_alerts[:2]))  # æœ€å¤šæ’­æŠ¥2ä¸ªç´§æ€¥è­¦æŠ¥
        
        # ç¯å¢ƒå»ºè®®æ’­æŠ¥
        guidance = env_result.get('navigation_guidance', [])
        if guidance:
            content_parts.extend(guidance[:2])  # æœ€å¤šæ’­æŠ¥2ä¸ªå»ºè®®
        
        return "ï¼›".join(content_parts) if content_parts else "ç¯å¢ƒå®‰å…¨"
    
    def get_object_position(self, x1, y1, x2, y2):
        """è·å–ç‰©ä½“ä½ç½®æè¿°"""
        center_x = (x1 + x2) / 2
        center_y = (y1 + y2) / 2
        
        if center_x < 200:
            return "å·¦ä¾§"
        elif center_x > 440:
            return "å³ä¾§"
        elif center_y < 150:
            return "ä¸Šæ–¹"
        elif center_y > 330:
            return "ä¸‹æ–¹"
        else:
            return "ä¸­å¤®"
    
    def format_environment_details(self, env_result):
        """æ ¼å¼åŒ–ç¯å¢ƒè¯¦æƒ…"""
        details = []
        
        # æ–½å·¥åŒºåŸŸä¿¡æ¯
        construction = env_result.get('construction_zone')
        if construction and construction.get('is_construction_zone'):
            details.append(f"æ–½å·¥åŒºåŸŸ: {construction.get('zone_type', 'unknown')}")
            details.append(f"å®‰å…¨ç­‰çº§: {construction.get('safety_level', 'unknown')}")
            if construction.get('bypass_path'):
                details.append("å»ºè®®ç»•è¡Œ")
        
        # è·¯å£ä¿¡æ¯
        intersection = env_result.get('intersection')
        if intersection and intersection.get('is_intersection'):
            details.append(f"è·¯å£æ£€æµ‹: æ˜¯")
            if intersection.get('traffic_light_state') != 'unknown':
                details.append(f"äº¤é€šç¯: {intersection.get('traffic_light_state')}")
            if intersection.get('crosswalk_detected'):
                details.append("æ–‘é©¬çº¿: æ£€æµ‹åˆ°")
        
        # æ‹¥æŒ¤ç¨‹åº¦ä¿¡æ¯
        crowd = env_result.get('crowd_density')
        if crowd:
            details.append(f"æ‹¥æŒ¤ç¨‹åº¦: {crowd.get('density_level', 'unknown')}")
            details.append(f"å¯¼èˆªéš¾åº¦: {crowd.get('navigation_difficulty', 'unknown')}")
        
        return '\n'.join(details) if details else "ç¯å¢ƒæ£€æµ‹æ­£å¸¸"
    
    def update_trajectory_display(self, result):
        """æ›´æ–°è½¨è¿¹é¢„æµ‹æ˜¾ç¤º"""
        if not result:
            return
        
        # æ›´æ–°è½¨è¿¹çŠ¶æ€
        if result.get('blind_path'):
            blind_path = result['blind_path']
            confidence = blind_path.get('confidence', 0)
            if confidence > 0.7:
                self.trajectory_status_label.setText("è½¨è¿¹çŠ¶æ€: ç›²é“æ¸…æ™°")
                self.trajectory_status_label.setStyleSheet("color: #4caf50; padding: 8px; background-color: #e8f5e8; border-radius: 5px; font-size: 14px;")
                self.voice_announce("ç›²é“æ¸…æ™°ï¼Œå»ºè®®æ²¿ç›²é“å‰è¿›", priority=1, category="æŒ‡å¯¼")
            elif confidence > 0.4:
                self.trajectory_status_label.setText("è½¨è¿¹çŠ¶æ€: ç›²é“éƒ¨åˆ†å¯è§")
                self.trajectory_status_label.setStyleSheet("color: #ff9800; padding: 8px; background-color: #fff3e0; border-radius: 5px; font-size: 14px;")
                self.voice_announce("ç›²é“éƒ¨åˆ†å¯è§ï¼Œè¯·è°¨æ…å‰è¿›", priority=2, category="è­¦å‘Š")
            else:
                self.trajectory_status_label.setText("è½¨è¿¹çŠ¶æ€: ç›²é“ä¸æ¸…æ™°")
                self.trajectory_status_label.setStyleSheet("color: #f44336; padding: 8px; background-color: #ffebee; border-radius: 5px; font-size: 14px;")
                self.voice_announce("ç›²é“ä¸æ¸…æ™°ï¼Œå»ºè®®ä½¿ç”¨å…¶ä»–å¯¼èˆªæ–¹å¼", priority=3, category="è­¦å‘Š")
        else:
            self.trajectory_status_label.setText("è½¨è¿¹çŠ¶æ€: æœªæ£€æµ‹åˆ°ç›²é“")
            self.trajectory_status_label.setStyleSheet("color: #666; padding: 8px; background-color: #f5f5f5; border-radius: 5px; font-size: 14px;")
        
        # æ›´æ–°ç¢°æ’é£é™©
        collision_risks = result.get('collision_risks', {})
        if collision_risks:
            max_risk = max(collision_risks.values()) if collision_risks else 0
            if max_risk > 0.7:
                self.collision_risk_label.setText("ç¢°æ’é£é™©: é«˜")
                self.collision_risk_label.setStyleSheet("color: #d32f2f; padding: 8px; background-color: #ffebee; border-radius: 5px; font-size: 14px;")
                self.voice_announce("æ£€æµ‹åˆ°é«˜é£é™©éšœç¢ç‰©ï¼Œè¯·ç«‹å³åœæ­¢", priority=5, category="ç´§æ€¥")
            elif max_risk > 0.4:
                self.collision_risk_label.setText("ç¢°æ’é£é™©: ä¸­")
                self.collision_risk_label.setStyleSheet("color: #f57c00; padding: 8px; background-color: #fff3e0; border-radius: 5px; font-size: 14px;")
                self.voice_announce("å­˜åœ¨ä¸­ç­‰é£é™©éšœç¢ç‰©ï¼Œè¯·å‡é€Ÿæ…¢è¡Œ", priority=3, category="è­¦å‘Š")
            else:
                self.collision_risk_label.setText("ç¢°æ’é£é™©: ä½")
                self.collision_risk_label.setStyleSheet("color: #4caf50; padding: 8px; background-color: #e8f5e8; border-radius: 5px; font-size: 14px;")
        else:
            self.collision_risk_label.setText("ç¢°æ’é£é™©: ä½")
            self.collision_risk_label.setStyleSheet("color: #4caf50; padding: 8px; background-color: #e8f5e8; border-radius: 5px; font-size: 14px;")
        
        # æ›´æ–°å®‰å…¨å»ºè®®
        recommendations = result.get('safety_recommendations', [])
        if recommendations:
            self.safety_recommendations_label.setText(f"å®‰å…¨å»ºè®®: {', '.join(recommendations)}")
            self.safety_recommendations_label.setStyleSheet("color: #ff9800; padding: 8px; background-color: #fff3e0; border-radius: 5px; font-size: 14px;")
            # æ’­æŠ¥å®‰å…¨å»ºè®®
            for rec in recommendations:
                self.voice_announce(rec, priority=2, category="å»ºè®®")
        else:
            self.safety_recommendations_label.setText("å®‰å…¨å»ºè®®: æ— ")
            self.safety_recommendations_label.setStyleSheet("color: #666; padding: 8px; background-color: #f5f5f5; border-radius: 5px; font-size: 14px;")
        
        # æ›´æ–°è½¨è¿¹è¯¦æƒ…
        trajectory_details = self.format_trajectory_details(result)
        self.trajectory_details_text.setPlainText(trajectory_details)
        
        # æ›´æ–°çŠ¶æ€æ è½¨è¿¹é¢„æµ‹çŠ¶æ€
        if result.get('blind_path'):
            confidence = result['blind_path'].get('confidence', 0)
            if confidence > 0.7:
                self.trajectory_status_bar_label.setText("è½¨è¿¹: æ¸…æ™°")
                self.trajectory_status_bar_label.setStyleSheet("color: #4caf50;")
            elif confidence > 0.4:
                self.trajectory_status_bar_label.setText("è½¨è¿¹: æ¨¡ç³Š")
                self.trajectory_status_bar_label.setStyleSheet("color: #f57c00;")
            else:
                self.trajectory_status_bar_label.setText("è½¨è¿¹: ä¸æ¸…æ™°")
                self.trajectory_status_bar_label.setStyleSheet("color: #d32f2f;")
        else:
            self.trajectory_status_bar_label.setText("è½¨è¿¹: æœªæ£€æµ‹")
            self.trajectory_status_bar_label.setStyleSheet("color: #666;")
    
    def format_trajectory_details(self, result):
        """æ ¼å¼åŒ–è½¨è¿¹è¯¦æƒ…"""
        details = []
        
        # ç›²é“ä¿¡æ¯
        blind_path = result.get('blind_path')
        if blind_path:
            details.append(f"ç›²é“ç½®ä¿¡åº¦: {blind_path.get('confidence', 0):.2f}")
            if blind_path.get('predicted_trajectory'):
                details.append(f"é¢„æµ‹è½¨è¿¹ç‚¹: {len(blind_path['predicted_trajectory'])}ä¸ª")
        
        # è·Ÿè¸ªç›®æ ‡ä¿¡æ¯
        tracked_objects = result.get('tracked_objects', [])
        if tracked_objects:
            details.append(f"è·Ÿè¸ªç›®æ ‡: {len(tracked_objects)}ä¸ª")
            for obj in tracked_objects:
                obj_id = obj.get('id', 'unknown')
                class_id = obj.get('class_id', 0)
                details.append(f"  ç›®æ ‡{obj_id}: ç±»åˆ«{class_id}")
        
        # ç¢°æ’é£é™©è¯¦æƒ…
        collision_risks = result.get('collision_risks', {})
        if collision_risks:
            high_risk_count = sum(1 for risk in collision_risks.values() if risk > 0.7)
            if high_risk_count > 0:
                details.append(f"é«˜é£é™©ç›®æ ‡: {high_risk_count}ä¸ª")
        
        return '\n'.join(details) if details else "è½¨è¿¹é¢„æµ‹æ­£å¸¸"
    
    def toggle_camera_detection(self):
        """åˆ‡æ¢æ‘„åƒå¤´æ£€æµ‹çŠ¶æ€"""
        if not self.camera_active:
            self.start_camera_detection()
        else:
            self.stop_camera_detection()
    
    def start_camera_detection(self):
        """å¼€å§‹æ‘„åƒå¤´æ£€æµ‹"""
        try:
            self.cap = cv2.VideoCapture(0)
            if not self.cap.isOpened():
                QMessageBox.warning(self, "é”™è¯¯", "æ— æ³•æ‰“å¼€æ‘„åƒå¤´ï¼Œè¯·æ£€æŸ¥æ‘„åƒå¤´æƒé™")
                return
            
            self.camera_active = True
            self.camera_start_btn.setText("ğŸ“¹ åœæ­¢æ‘„åƒå¤´æ£€æµ‹")
            self.camera_start_btn.setStyleSheet("QPushButton { background-color: #f44336; color: white; font-weight: bold; padding: 12px; font-size: 16px; }")
            self.camera_status_label.setText("æ‘„åƒå¤´çŠ¶æ€: è¿è¡Œä¸­")
            self.camera_status_label.setStyleSheet("color: #4caf50; padding: 8px; background-color: #e8f5e8; border-radius: 5px; font-size: 14px;")
            self.detection_status_label.setText("æ£€æµ‹çŠ¶æ€: æ£€æµ‹ä¸­")
            self.detection_status_label.setStyleSheet("color: #4caf50; padding: 5px; background-color: #e8f5e8; border-radius: 3px;")
            
            # å¯åŠ¨å®šæ—¶å™¨
            self.camera_timer.start(33)  # çº¦30FPS
            
            # æ›´æ–°çŠ¶æ€æ 
            self.detection_status_bar_label.setText("æ£€æµ‹: è¿è¡Œä¸­")
            self.detection_status_bar_label.setStyleSheet("color: #4caf50; font-weight: bold;")
            
            # è¯­éŸ³æ’­æŠ¥
            self.voice_announce("æ‘„åƒå¤´æ£€æµ‹å·²å¯åŠ¨", priority=1, category="ç³»ç»Ÿ")
            
        except Exception as e:
            QMessageBox.critical(self, "é”™è¯¯", f"å¯åŠ¨æ‘„åƒå¤´æ£€æµ‹å¤±è´¥: {e}")
    
    def stop_camera_detection(self):
        """åœæ­¢æ‘„åƒå¤´æ£€æµ‹"""
        self.camera_active = False
        self.camera_timer.stop()
        
        if self.cap:
            self.cap.release()
            self.cap = None
        
        self.camera_start_btn.setText("ğŸ“¹ å¼€å¯æ‘„åƒå¤´æ£€æµ‹")
        self.camera_start_btn.setStyleSheet("QPushButton { background-color: #4caf50; color: white; font-weight: bold; padding: 12px; font-size: 16px; }")
        self.camera_status_label.setText("æ‘„åƒå¤´çŠ¶æ€: å·²åœæ­¢")
        self.camera_status_label.setStyleSheet("color: #666; padding: 8px; background-color: #f0f0f0; border-radius: 5px; font-size: 14px;")
        self.detection_status_label.setText("æ£€æµ‹çŠ¶æ€: å·²åœæ­¢")
        self.detection_status_label.setStyleSheet("color: #666; padding: 5px; background-color: #f0f0f0; border-radius: 3px;")
        
        self.camera_display.setText("æ‘„åƒå¤´æ£€æµ‹å·²åœæ­¢")
        
        # æ›´æ–°çŠ¶æ€æ 
        self.detection_status_bar_label.setText("æ£€æµ‹: å·²åœæ­¢")
        self.detection_status_bar_label.setStyleSheet("color: #666;")
        
        # è¯­éŸ³æ’­æŠ¥
        self.voice_announce("æ‘„åƒå¤´æ£€æµ‹å·²åœæ­¢", priority=1, category="ç³»ç»Ÿ")
    
    def update_camera_frame(self):
        """æ›´æ–°æ‘„åƒå¤´å¸§"""
        if not self.cap or not self.camera_active:
            return
        
        ret, frame = self.cap.read()
        if not ret:
            return
        
        # è¿›è¡Œç‰©ä½“æ£€æµ‹
        detections = self.detect_objects_in_frame(frame)
        
        # ç¯å¢ƒæ£€æµ‹å’Œè½¨è¿¹é¢„æµ‹
        env_result = None
        trajectory_result = None
        
        # å®æ—¶ç¯å¢ƒæ£€æµ‹
        if self.env_detector and self.env_detection_enabled:
            env_result = self.analyze_environment(frame)
        
        if self.trajectory_predictor:
            trajectory_result = self.predict_trajectory(frame)
        
        # ç»˜åˆ¶æ£€æµ‹ç»“æœ
        if self.show_detection_btn.isChecked():
            frame = self.draw_detection_boxes(frame, detections)
        
        if self.show_trajectory_btn.isChecked() and trajectory_result:
            frame = self.draw_trajectory_predictions(frame, trajectory_result)
        
        # æ˜¾ç¤ºå¸§
        self.display_camera_frame(frame)
        
        # æ›´æ–°æ£€æµ‹ä¿¡æ¯
        self.update_detection_info(detections, env_result, trajectory_result)
        
        # æ£€æµ‹éšœç¢ç‰©å˜åŒ–
        detection_changes = self.detect_obstacle_changes(detections)
        
        # æ›´æ–°ç¯å¢ƒæ£€æµ‹å’Œè½¨è¿¹é¢„æµ‹æ˜¾ç¤º
        if env_result:
            self.update_environment_display(env_result, detections)
        else:
            # å¦‚æœæ²¡æœ‰ç¯å¢ƒæ£€æµ‹ç»“æœï¼Œæ˜¾ç¤ºé»˜è®¤çŠ¶æ€
            self.env_safety_label.setText("ç¯å¢ƒå®‰å…¨: æ£€æµ‹ä¸­...")
            self.env_safety_label.setStyleSheet("font-weight: bold; color: #666; padding: 8px; background-color: #f5f5f5; border-radius: 5px;")
            self.env_score_label.setText("å®‰å…¨è¯„åˆ†: --")
            self.env_score_label.setStyleSheet("font-weight: bold; color: #666; padding: 8px; background-color: #f5f5f5; border-radius: 5px;")
            self.env_details_text.setPlainText("ç¯å¢ƒæ£€æµ‹ä¸­ï¼Œè¯·ç¨å€™...")
            self.env_warnings_text.setPlainText("æš‚æ— è­¦å‘Šä¿¡æ¯")
        
        if trajectory_result:
            self.update_trajectory_display(trajectory_result, detections)
        
        # æ ¹æ®å˜åŒ–è¿›è¡Œè¯­éŸ³æ’­æŠ¥
        if detection_changes:
            self.announce_detection_changes(detection_changes)
        
        # æ›´æ–°ä¸Šä¸€å¸§æ£€æµ‹ç»“æœ
        self.previous_detections = detections.copy()
    
    def detect_obstacle_changes(self, current_detections):
        """æ£€æµ‹éšœç¢ç‰©å˜åŒ–"""
        changes = {
            'new_obstacles': [],      # æ–°å‡ºç°çš„éšœç¢ç‰©
            'disappeared_obstacles': [],  # æ¶ˆå¤±çš„éšœç¢ç‰©
            'moved_obstacles': [],    # ç§»åŠ¨çš„éšœç¢ç‰©
            'changed_obstacles': []   # å˜åŒ–çš„éšœç¢ç‰©
        }
        
        current_time = time.time()
        
        # æ£€æŸ¥å†·å´æ—¶é—´
        if current_time - self.last_announcement_time < self.announcement_cooldown:
            return changes
        
        # å¦‚æœæ²¡æœ‰ä¸Šä¸€å¸§æ•°æ®ï¼Œè·³è¿‡å˜åŒ–æ£€æµ‹
        if not self.previous_detections:
            return changes
        
        # æ£€æµ‹æ–°å‡ºç°çš„éšœç¢ç‰©
        for current_obj in current_detections:
            is_new = True
            for prev_obj in self.previous_detections:
                if self.is_same_object(current_obj, prev_obj):
                    is_new = False
                    break
            if is_new:
                changes['new_obstacles'].append(current_obj)
        
        # æ£€æµ‹æ¶ˆå¤±çš„éšœç¢ç‰©
        for prev_obj in self.previous_detections:
            still_exists = False
            for current_obj in current_detections:
                if self.is_same_object(prev_obj, current_obj):
                    still_exists = True
                    break
            if not still_exists:
                changes['disappeared_obstacles'].append(prev_obj)
        
        # æ£€æµ‹ç§»åŠ¨çš„éšœç¢ç‰©
        for current_obj in current_detections:
            for prev_obj in self.previous_detections:
                if self.is_same_object(current_obj, prev_obj):
                    if self.has_moved_significantly(current_obj, prev_obj):
                        changes['moved_obstacles'].append({
                            'previous': prev_obj,
                            'current': current_obj
                        })
                    break
        
        # å¦‚æœæœ‰ä»»ä½•å˜åŒ–ï¼Œæ›´æ–°æ’­æŠ¥æ—¶é—´
        if any(changes.values()):
            self.last_announcement_time = current_time
        
        return changes
    
    def is_same_object(self, obj1, obj2):
        """åˆ¤æ–­æ˜¯å¦ä¸ºåŒä¸€ä¸ªç‰©ä½“"""
        # åŸºäºç±»åˆ«å’Œä½ç½®åˆ¤æ–­
        if obj1.get('class_name') != obj2.get('class_name'):
            return False
        
        # è®¡ç®—è¾¹ç•Œæ¡†é‡å åº¦
        bbox1 = obj1.get('bbox', [0, 0, 0, 0])
        bbox2 = obj2.get('bbox', [0, 0, 0, 0])
        
        overlap = self.calculate_bbox_overlap(bbox1, bbox2)
        return overlap > 0.3  # é‡å åº¦é˜ˆå€¼
    
    def calculate_bbox_overlap(self, bbox1, bbox2):
        """è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„é‡å åº¦"""
        x1_1, y1_1, x2_1, y2_1 = bbox1
        x1_2, y1_2, x2_2, y2_2 = bbox2
        
        # è®¡ç®—äº¤é›†
        x1_i = max(x1_1, x1_2)
        y1_i = max(y1_1, y1_2)
        x2_i = min(x2_1, x2_2)
        y2_i = min(y2_1, y2_2)
        
        if x2_i <= x1_i or y2_i <= y1_i:
            return 0.0
        
        intersection = (x2_i - x1_i) * (y2_i - y1_i)
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0
    
    def has_moved_significantly(self, current_obj, prev_obj):
        """åˆ¤æ–­ç‰©ä½“æ˜¯å¦æ˜¾è‘—ç§»åŠ¨"""
        bbox1 = current_obj.get('bbox', [0, 0, 0, 0])
        bbox2 = prev_obj.get('bbox', [0, 0, 0, 0])
        
        # è®¡ç®—ä¸­å¿ƒç‚¹è·ç¦»
        center1_x = (bbox1[0] + bbox1[2]) / 2
        center1_y = (bbox1[1] + bbox1[3]) / 2
        center2_x = (bbox2[0] + bbox2[2]) / 2
        center2_y = (bbox2[1] + bbox2[3]) / 2
        
        distance = ((center1_x - center2_x) ** 2 + (center1_y - center2_y) ** 2) ** 0.5
        
        # ç§»åŠ¨è·ç¦»é˜ˆå€¼ï¼ˆåƒç´ ï¼‰
        return distance > 50
    
    def announce_detection_changes(self, changes):
        """æ’­æŠ¥æ£€æµ‹å˜åŒ–"""
        current_time = time.time()
        
        # æ’­æŠ¥æ–°å‡ºç°çš„éšœç¢ç‰©
        for obj in changes['new_obstacles']:
            obj_name = obj.get('class_name', 'ç‰©ä½“')
            bbox = obj.get('bbox', [0, 0, 0, 0])
            x1, y1, x2, y2 = bbox
            position = self.get_object_position(x1, y1, x2, y2)
            class_id = obj.get('class_id', 0)
            
            if class_id == 1:  # åŠ¨æ€éšœç¢
                message = f"{position}å‡ºç°åŠ¨æ€éšœç¢ç‰©{obj_name}ï¼Œè¯·æ³¨æ„"
                self.voice_announce(message, priority=4, category="æ£€æµ‹")
            elif class_id == 2:  # åœ°é¢å±é™©
                message = f"{position}å‡ºç°åœ°é¢å±é™©{obj_name}ï¼Œå»ºè®®ç»•è¡Œ"
                self.voice_announce(message, priority=3, category="æ£€æµ‹")
            else:  # é™æ€éšœç¢
                message = f"{position}å‡ºç°é™æ€éšœç¢ç‰©{obj_name}ï¼Œæ³¨æ„é¿è®©"
                self.voice_announce(message, priority=2, category="æ£€æµ‹")
        
        # æ’­æŠ¥æ¶ˆå¤±çš„éšœç¢ç‰©
        for obj in changes['disappeared_obstacles']:
            obj_name = obj.get('class_name', 'ç‰©ä½“')
            bbox = obj.get('bbox', [0, 0, 0, 0])
            x1, y1, x2, y2 = bbox
            position = self.get_object_position(x1, y1, x2, y2)
            class_id = obj.get('class_id', 0)
            
            if class_id == 1:  # åŠ¨æ€éšœç¢
                message = f"{position}çš„åŠ¨æ€éšœç¢ç‰©{obj_name}å·²ç¦»å¼€"
                self.voice_announce(message, priority=1, category="ä¿¡æ¯")
        
        # æ’­æŠ¥ç§»åŠ¨çš„éšœç¢ç‰©
        for move_info in changes['moved_obstacles']:
            current_obj = move_info['current']
            prev_obj = move_info['previous']
            obj_name = current_obj.get('class_name', 'ç‰©ä½“')
            
            # è®¡ç®—ç§»åŠ¨æ–¹å‘
            bbox1 = current_obj.get('bbox', [0, 0, 0, 0])
            bbox2 = prev_obj.get('bbox', [0, 0, 0, 0])
            
            center1_x = (bbox1[0] + bbox1[2]) / 2
            center2_x = (bbox2[0] + bbox2[2]) / 2
            
            if center1_x > center2_x + 20:
                direction = "å‘å³ç§»åŠ¨"
            elif center1_x < center2_x - 20:
                direction = "å‘å·¦ç§»åŠ¨"
            else:
                direction = "ä½ç½®å˜åŒ–"
            
            message = f"åŠ¨æ€éšœç¢ç‰©{obj_name}{direction}"
            self.voice_announce(message, priority=3, category="æ£€æµ‹")
    
    def detect_objects_in_frame(self, frame):
        """æ£€æµ‹å¸§ä¸­çš„ç‰©ä½“"""
        detections = []
        
        try:
            # ä½¿ç”¨YOLOæ¨¡å‹è¿›è¡Œæ£€æµ‹
            if self.yolo_available and self.yolo_model:
                # è¿è¡ŒYOLOæ£€æµ‹
                results = self.yolo_model(frame, conf=self.detection_confidence_threshold, 
                                        iou=self.detection_nms_threshold, verbose=False)
                
                for result in results:
                    boxes = result.boxes
                    if boxes is not None:
                        for box in boxes:
                            # è·å–è¾¹ç•Œæ¡†åæ ‡
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            confidence = box.conf[0].cpu().numpy()
                            class_id = int(box.cls[0].cpu().numpy())
                            
                            # æ ¹æ®ç±»åˆ«IDç¡®å®šç±»åˆ«åç§°
                            class_names = {
                                0: 'äºº',          # person
                                1: 'è‡ªè¡Œè½¦',      # bicycle
                                2: 'æ±½è½¦',        # car
                                3: 'æ‘©æ‰˜è½¦',      # motorcycle
                                4: 'å…¬äº¤è½¦',      # bus
                                5: 'å¡è½¦',        # truck
                                6: 'äº¤é€šç¯',      # traffic_light
                                7: 'åœè½¦æ ‡å¿—',    # stop_sign
                                8: 'é•¿æ¤…',        # bench
                                9: 'æ¤…å­',        # chair
                                10: 'æ¡Œå­',       # table
                                11: 'ç“¶å­',       # bottle
                                12: 'æ¯å­',       # cup
                                13: 'ç¬”è®°æœ¬ç”µè„‘', # laptop
                                14: 'ä¹¦',         # book
                                15: 'å‰ªåˆ€',       # scissors
                                16: 'æ³°è¿ªç†Š',     # teddy_bear
                                17: 'å¹é£æœº',     # hair_drier
                                18: 'ç‰™åˆ·',       # toothbrush
                                19: 'åƒåœ¾æ¡¶',     # trash_can
                                20: 'èŠ±ç›†',       # potted_plant
                                21: 'æ²™å‘',       # couch
                                22: 'åºŠ',         # bed
                                23: 'ç”µè§†',       # tv
                                24: 'æ‰‹æœº',       # cell_phone
                                25: 'é”®ç›˜',       # keyboard
                                26: 'é¼ æ ‡',       # mouse
                                27: 'é¥æ§å™¨',     # remote
                                28: 'æ—¶é’Ÿ',       # clock
                                29: 'èŠ±ç“¶',       # vase
                                30: 'æ»‘æ¿',       # skateboard
                                31: 'å†²æµªæ¿',     # surfboard
                                32: 'ç½‘çƒæ‹',     # tennis_racket
                                33: 'æ£’çƒ',       # baseball
                                34: 'æ£’çƒæ£’',     # baseball_bat
                                35: 'æ£’çƒæ‰‹å¥—',   # baseball_glove
                                36: 'æ»‘æ¿è½¦',     # skateboard
                                37: 'æ»‘æ¿',       # skateboard
                                38: 'æ»‘æ¿',       # skateboard
                                39: 'æ»‘æ¿'        # skateboard
                            }
                            
                            class_name = class_names.get(class_id, 'unknown')
                            
                            # æ ¹æ®ç±»åˆ«ç¡®å®šéšœç¢ç‰©ç±»å‹
                            if class_id in [0]:  # äºº
                                obstacle_type = 1  # åŠ¨æ€éšœç¢
                            elif class_id in [1, 2, 3, 4, 5]:  # è½¦è¾†
                                obstacle_type = 1  # åŠ¨æ€éšœç¢
                            elif class_id in [8, 9, 10]:  # é•¿æ¤…ã€æ¤…å­ã€æ¡Œå­
                                obstacle_type = 0  # é™æ€éšœç¢
                            else:
                                obstacle_type = 0  # é™æ€éšœç¢
                            
                            detections.append({
                                'bbox': [int(x1), int(y1), int(x2), int(y2)],
                                'class_name': class_name,
                                'confidence': float(confidence),
                                'class_id': obstacle_type
                            })
            
            else:
                # å¦‚æœæ²¡æœ‰YOLOæ¨¡å‹ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ£€æµ‹ç»“æœ
                if np.random.random() > 0.8:  # é™ä½æ£€æµ‹é¢‘ç‡ï¼Œæé«˜ç²¾åº¦
                    h, w = frame.shape[:2]
                    x1 = int(w * 0.2)
                    y1 = int(h * 0.3)
                    x2 = int(w * 0.4)
                    y2 = int(h * 0.7)
                    
                    detections.append({
                        'bbox': [x1, y1, x2, y2],
                        'class_name': 'obstacle',
                        'confidence': 0.85,
                        'class_id': 0  # 0: é™æ€éšœç¢, 1: åŠ¨æ€éšœç¢, 2: åœ°é¢å±é™©
                    })
        
        except Exception as e:
            print(f"âš ï¸ ç‰©ä½“æ£€æµ‹å¤±è´¥: {e}")
        
        return detections
    
    def draw_detection_boxes(self, frame, detections):
        """ç»˜åˆ¶æ£€æµ‹æ¡†"""
        for detection in detections:
            bbox = detection['bbox']
            class_name = detection['class_name']
            confidence = detection['confidence']
            class_id = detection.get('class_id', 0)
            
            x1, y1, x2, y2 = map(int, bbox)
            
            # æ ¹æ®ç±»åˆ«é€‰æ‹©é¢œè‰²
            colors = {
                0: (0, 255, 0),    # ç»¿è‰² - é™æ€éšœç¢
                1: (0, 0, 255),    # çº¢è‰² - åŠ¨æ€éšœç¢
                2: (255, 0, 0),    # è“è‰² - åœ°é¢å±é™©
            }
            color = colors.get(class_id, (255, 255, 0))
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{class_name}: {confidence:.2f}"
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
            cv2.rectangle(frame, (x1, y1 - label_size[1] - 10), (x1 + label_size[0], y1), color, -1)
            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        return frame
    
    def draw_trajectory_predictions(self, frame, trajectory_result):
        """ç»˜åˆ¶è½¨è¿¹é¢„æµ‹"""
        # ç»˜åˆ¶ç›²é“è½¨è¿¹
        if trajectory_result.get('blind_path') and trajectory_result['blind_path'].get('predicted_trajectory'):
            trajectory = trajectory_result['blind_path']['predicted_trajectory']
            for i, point in enumerate(trajectory):
                cv2.circle(frame, point, 3, (0, 255, 255), -1)
                if i > 0:
                    cv2.line(frame, trajectory[i-1], point, (0, 255, 255), 2)
        
        # ç»˜åˆ¶ç›®æ ‡è½¨è¿¹
        for obj in trajectory_result.get('tracked_objects', []):
            if obj.get('predicted_trajectory'):
                trajectory = obj['predicted_trajectory']
                for i, point in enumerate(trajectory):
                    cv2.circle(frame, point, 2, (255, 0, 255), -1)
                    if i > 0:
                        cv2.line(frame, trajectory[i-1], point, (255, 0, 255), 1)
        
        return frame
    
    def display_camera_frame(self, frame):
        """æ˜¾ç¤ºæ‘„åƒå¤´å¸§"""
        height, width, channel = frame.shape
        bytes_per_line = 3 * width
        q_image = QImage(frame.data, width, height, bytes_per_line, QImage.Format_RGB888).rgbSwapped()
        
        pixmap = QPixmap.fromImage(q_image)
        scaled_pixmap = pixmap.scaled(self.camera_display.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation)
        self.camera_display.setPixmap(scaled_pixmap)
    
    def update_detection_info(self, detections, env_result, trajectory_result):
        """æ›´æ–°æ£€æµ‹ä¿¡æ¯"""
        # æ›´æ–°æ£€æµ‹æ•°é‡
        self.detection_count_label.setText(f"æ£€æµ‹æ•°é‡: {len(detections)}")
        
        # æ›´æ–°FPSï¼ˆç®€å•è®¡ç®—ï¼‰
        current_time = time.time()
        if not hasattr(self, 'last_fps_time'):
            self.last_fps_time = current_time
            self.frame_count = 0
        else:
            self.frame_count += 1
            if current_time - self.last_fps_time >= 1.0:
                fps = self.frame_count / (current_time - self.last_fps_time)
                self.fps_label.setText(f"FPS: {fps:.1f}")
                self.last_fps_time = current_time
                self.frame_count = 0
    
    def announce_detection_results(self, detections, env_result, trajectory_result):
        """è¯­éŸ³æ’­æŠ¥æ£€æµ‹ç»“æœ"""
        # æ’­æŠ¥æ£€æµ‹åˆ°çš„éšœç¢ç‰©
        for detection in detections:
            class_name = detection['class_name']
            confidence = detection['confidence']
            class_id = detection.get('class_id', 0)
            bbox = detection.get('bbox', [0, 0, 0, 0])
            x1, y1, x2, y2 = bbox
            
            # åˆ¤æ–­ç‰©ä½“ä½ç½®
            center_x = (x1 + x2) / 2
            if center_x < 200:
                position = "å·¦ä¾§"
            elif center_x > 440:
                position = "å³ä¾§"
            else:
                position = "å‰æ–¹"
            
            # æ ¹æ®ç±»åˆ«ç¡®å®šä¼˜å…ˆçº§å’Œæ’­æŠ¥å†…å®¹
            if class_id == 1:  # åŠ¨æ€éšœç¢
                priority = 4
                message = f"{position}æ£€æµ‹åˆ°åŠ¨æ€éšœç¢ç‰©{class_name}ï¼Œè¯·æ³¨æ„é¿è®©"
            elif class_id == 2:  # åœ°é¢å±é™©
                priority = 3
                message = f"{position}æ£€æµ‹åˆ°åœ°é¢å±é™©{class_name}ï¼Œå»ºè®®ç»•è¡Œ"
            else:  # é™æ€éšœç¢
                priority = 2
                message = f"{position}æ£€æµ‹åˆ°é™æ€éšœç¢ç‰©{class_name}ï¼Œæ³¨æ„é¿è®©"
            
            self.voice_announce(message, priority=priority, category="æ£€æµ‹")
        
        # æ’­æŠ¥ç¯å¢ƒé£é™©è¯„ä¼°
        if env_result:
            overall_safety = env_result.get('overall_safety_level', 'safe')
            if overall_safety == 'high_risk':
                self.voice_announce("ç¯å¢ƒé£é™©æé«˜ï¼Œè¯·ç«‹å³åœæ­¢å‰è¿›", priority=5, category="ç´§æ€¥")
            elif overall_safety == 'medium_risk':
                self.voice_announce("ç¯å¢ƒå­˜åœ¨é£é™©ï¼Œè¯·æé«˜è­¦æƒ•", priority=3, category="è­¦å‘Š")
        
        # æ’­æŠ¥è½¨è¿¹é¢„æµ‹æç¤º
        if trajectory_result:
            blind_path = trajectory_result.get('blind_path')
            if blind_path:
                confidence = blind_path.get('confidence', 0)
                if confidence > 0.7:
                    self.voice_announce("ç›²é“æ¸…æ™°ï¼Œå»ºè®®æ²¿ç›²é“å‰è¿›", priority=1, category="æŒ‡å¯¼")
                elif confidence > 0.4:
                    self.voice_announce("ç›²é“éƒ¨åˆ†å¯è§ï¼Œè¯·è°¨æ…å‰è¿›", priority=2, category="è­¦å‘Š")
                else:
                    self.voice_announce("ç›²é“ä¸æ¸…æ™°ï¼Œå»ºè®®ä½¿ç”¨å…¶ä»–å¯¼èˆªæ–¹å¼", priority=3, category="è­¦å‘Š")
            
            # æ’­æŠ¥ç¢°æ’é£é™©
            collision_risks = trajectory_result.get('collision_risks', {})
            if collision_risks:
                max_risk = max(collision_risks.values())
                if max_risk > 0.7:
                    self.voice_announce("æ£€æµ‹åˆ°é«˜é£é™©éšœç¢ç‰©ï¼Œè¯·ç«‹å³åœæ­¢", priority=5, category="ç´§æ€¥")
                elif max_risk > 0.4:
                    self.voice_announce("å­˜åœ¨ä¸­ç­‰é£é™©éšœç¢ç‰©ï¼Œè¯·å‡é€Ÿæ…¢è¡Œ", priority=3, category="è­¦å‘Š")
    
    def toggle_show_detection(self):
        """åˆ‡æ¢æ˜¾ç¤ºæ£€æµ‹æ¡†"""
        pass  # çŠ¶æ€å·²åœ¨update_camera_frameä¸­ä½¿ç”¨
    
    def toggle_show_trajectory(self):
        """åˆ‡æ¢æ˜¾ç¤ºè½¨è¿¹"""
        pass  # çŠ¶æ€å·²åœ¨update_camera_frameä¸­ä½¿ç”¨
    
    def change_detection_accuracy(self, accuracy):
        """æ”¹å˜æ£€æµ‹ç²¾åº¦"""
        self.detection_accuracy = accuracy
        print(f"æ£€æµ‹ç²¾åº¦å·²åˆ‡æ¢ä¸º: {accuracy}")
        
        # æ ¹æ®ç²¾åº¦è°ƒæ•´æ£€æµ‹å‚æ•°
        if accuracy == "é«˜ç²¾åº¦":
            self.detection_confidence_threshold = 0.3
            self.detection_nms_threshold = 0.4
        elif accuracy == "å¹³è¡¡":
            self.detection_confidence_threshold = 0.5
            self.detection_nms_threshold = 0.5
        else:  # å¿«é€Ÿ
            self.detection_confidence_threshold = 0.7
            self.detection_nms_threshold = 0.6
    
    def toggle_show_detection_switch(self):
        """åˆ‡æ¢æ˜¾ç¤ºæ£€æµ‹æ¡†å¼€å…³"""
        if self.show_boxes_switch.isChecked():
            self.show_boxes_switch.setText("æ˜¾ç¤ºæ£€æµ‹æ¡†")
            self.show_boxes_switch.setStyleSheet("QPushButton { background-color: #4caf50; color: white; font-weight: bold; padding: 8px; }")
        else:
            self.show_boxes_switch.setText("æ˜¾ç¤ºæ£€æµ‹æ¡†")
            self.show_boxes_switch.setStyleSheet("QPushButton { background-color: #f44336; color: white; font-weight: bold; padding: 8px; }")
    
    def toggle_show_trajectory_switch(self):
        """åˆ‡æ¢æ˜¾ç¤ºè½¨è¿¹å¼€å…³"""
        if self.show_trajectory_switch.isChecked():
            self.show_trajectory_switch.setText("æ˜¾ç¤ºè½¨è¿¹")
            self.show_trajectory_switch.setStyleSheet("QPushButton { background-color: #4caf50; color: white; font-weight: bold; padding: 8px; }")
        else:
            self.show_trajectory_switch.setText("æ˜¾ç¤ºè½¨è¿¹")
            self.show_trajectory_switch.setStyleSheet("QPushButton { background-color: #f44336; color: white; font-weight: bold; padding: 8px; }")
    
    def toggle_show_environment_switch(self):
        """åˆ‡æ¢ç¯å¢ƒæ£€æµ‹å¼€å…³"""
        if self.show_environment_switch.isChecked():
            self.show_environment_switch.setText("ç¯å¢ƒæ£€æµ‹")
            self.show_environment_switch.setStyleSheet("QPushButton { background-color: #4caf50; color: white; font-weight: bold; padding: 8px; }")
        else:
            self.show_environment_switch.setText("ç¯å¢ƒæ£€æµ‹")
            self.show_environment_switch.setStyleSheet("QPushButton { background-color: #f44336; color: white; font-weight: bold; padding: 8px; }")
    
    def start_mobile_test(self):
        """å¯åŠ¨æ‰‹æœºæµ‹è¯•åŠŸèƒ½"""
        try:
            from mobile_app_android import MobileApp
            mobile_app = MobileApp()
            if mobile_app.initialize():
                print("ğŸ“± æ‰‹æœºæµ‹è¯•åŠŸèƒ½å·²å¯åŠ¨")
                self.voice_announce("æ‰‹æœºæµ‹è¯•åŠŸèƒ½å·²å¯åŠ¨", priority=1, category="ç³»ç»Ÿ")
            else:
                QMessageBox.warning(self, "é”™è¯¯", "æ‰‹æœºæµ‹è¯•åŠŸèƒ½å¯åŠ¨å¤±è´¥")
        except ImportError:
            QMessageBox.information(self, "æç¤º", "æ‰‹æœºæµ‹è¯•åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...")
        except Exception as e:
            QMessageBox.critical(self, "é”™è¯¯", f"å¯åŠ¨æ‰‹æœºæµ‹è¯•å¤±è´¥: {e}")
    
    def toggle_environment_detection(self):
        """åˆ‡æ¢ç¯å¢ƒæ£€æµ‹å¼€å…³"""
        if self.env_detection_btn.isChecked():
            self.env_detection_btn.setText("ğŸŒ ç¯å¢ƒæ£€æµ‹: å¼€å¯")
            self.env_detection_btn.setStyleSheet("QPushButton { background-color: #ff9800; color: white; font-weight: bold; padding: 10px; font-size: 14px; }")
            self.env_detection_enabled = True
            self.voice_announce("ç¯å¢ƒæ£€æµ‹å·²å¼€å¯", priority=1, category="ç³»ç»Ÿ")
        else:
            self.env_detection_btn.setText("ğŸŒ ç¯å¢ƒæ£€æµ‹: å…³é—­")
            self.env_detection_btn.setStyleSheet("QPushButton { background-color: #666; color: white; font-weight: bold; padding: 10px; font-size: 14px; }")
            self.env_detection_enabled = False
            self.voice_announce("ç¯å¢ƒæ£€æµ‹å·²å…³é—­", priority=1, category="ç³»ç»Ÿ")
    
    def change_env_mode(self, mode):
        """æ”¹å˜ç¯å¢ƒæ£€æµ‹æ¨¡å¼"""
        self.voice_announce(f"ç¯å¢ƒæ£€æµ‹æ¨¡å¼å·²åˆ‡æ¢ä¸º{mode}", priority=1, category="ç³»ç»Ÿ")
        print(f"ç¯å¢ƒæ£€æµ‹æ¨¡å¼åˆ‡æ¢ä¸º: {mode}")
    
    def test_environment_detection(self):
        """æµ‹è¯•ç¯å¢ƒæ£€æµ‹åŠŸèƒ½"""
        try:
            if not self.env_detector:
                QMessageBox.warning(self, "è­¦å‘Š", "ç¯å¢ƒæ£€æµ‹æ¨¡å—æœªåŠ è½½")
                return
            
            # åˆ›å»ºæµ‹è¯•å›¾åƒ
            import numpy as np
            test_frame = np.ones((480, 640, 3), dtype=np.uint8) * 128
            mock_detections = [{'bbox': [100, 100, 200, 200], 'confidence': 0.8, 'class': 0}]
            
            # æ‰§è¡Œç¯å¢ƒæ£€æµ‹
            import time
            start_time = time.time()
            result = self.env_detector.detect_environment(test_frame, mock_detections)
            detection_time = time.time() - start_time
            
            # æ˜¾ç¤ºç»“æœ
            overall_safety = result.get('overall_safety_level', 'unknown')
            safety_score = result.get('safety_score', 0)
            safety_percentage = int(safety_score * 100)
            
            result_text = f"""ç¯å¢ƒæ£€æµ‹æµ‹è¯•ç»“æœ:
            
æ£€æµ‹è€—æ—¶: {detection_time:.3f}ç§’
å®‰å…¨ç­‰çº§: {overall_safety}
å®‰å…¨è¯„åˆ†: {safety_percentage}%"""
            
            # æ·»åŠ è¯¦ç»†ä¿¡æ¯
            weather_info = result.get('weather_conditions')
            if weather_info:
                weather_type = weather_info.get('weather_type', 'unknown')
                result_text += f"\nå¤©æ°”æ¡ä»¶: {weather_type}"
            
            lighting_info = result.get('lighting_conditions')
            if lighting_info:
                lighting_level = lighting_info.get('lighting_level', 'unknown')
                result_text += f"\nå…‰ç…§æ¡ä»¶: {lighting_level}"
            
            surface_info = result.get('surface_conditions')
            if surface_info:
                surface_type = surface_info.get('surface_type', 'unknown')
                result_text += f"\nè·¯é¢æ¡ä»¶: {surface_type}"
            
            warnings = result.get('warnings', [])
            if warnings:
                result_text += f"\nè­¦å‘Šæ•°é‡: {len(warnings)}"
                for i, warning in enumerate(warnings[:3], 1):
                    result_text += f"\n  {i}. {warning}"
            
            # æ›´æ–°ç¯å¢ƒæ£€æµ‹ç»“æœæ˜¾ç¤º
            self.update_environment_display(result, mock_detections)
            
            QMessageBox.information(self, "ç¯å¢ƒæ£€æµ‹æµ‹è¯•", result_text)
            self.voice_announce(f"ç¯å¢ƒæ£€æµ‹æµ‹è¯•å®Œæˆï¼Œå®‰å…¨ç­‰çº§{overall_safety}ï¼Œå®‰å…¨è¯„åˆ†{safety_percentage}%", priority=2, category="æµ‹è¯•")
            
        except Exception as e:
            QMessageBox.critical(self, "é”™è¯¯", f"ç¯å¢ƒæ£€æµ‹æµ‹è¯•å¤±è´¥: {e}")
    
    def voice_announce_environment(self):
        """è¯­éŸ³æ’­æŠ¥å½“å‰ç¯å¢ƒä¿¡æ¯"""
        try:
            if not self.env_detector:
                QMessageBox.warning(self, "è­¦å‘Š", "ç¯å¢ƒæ£€æµ‹æ¨¡å—æœªåŠ è½½")
                return
            
            # è·å–å½“å‰æ‘„åƒå¤´å¸§
            if not self.cap or not self.camera_active:
                QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆå¼€å¯æ‘„åƒå¤´æ£€æµ‹")
                return
            
            ret, frame = self.cap.read()
            if not ret:
                QMessageBox.warning(self, "è­¦å‘Š", "æ— æ³•è·å–æ‘„åƒå¤´å›¾åƒ")
                return
            
            # è¿›è¡Œç¯å¢ƒæ£€æµ‹
            detections = self.detect_objects_in_frame(frame)
            env_result = self.analyze_environment(frame)
            
            if not env_result:
                QMessageBox.warning(self, "è­¦å‘Š", "ç¯å¢ƒæ£€æµ‹å¤±è´¥")
                return
            
            # ç”Ÿæˆç¯å¢ƒè¯­éŸ³æ’­æŠ¥å†…å®¹
            voice_content = self.generate_environment_voice_content(detections, env_result)
            
            if voice_content:
                # è¯­éŸ³æ’­æŠ¥
                overall_safety = env_result.get('overall_safety_level', 'safe')
                priority = 5 if overall_safety == 'high_risk' else 3 if overall_safety == 'medium_risk' else 2
                category = "ç´§æ€¥" if overall_safety == 'high_risk' else "è­¦å‘Š" if overall_safety == 'medium_risk' else "æ£€æµ‹"
                self.voice_announce(voice_content, priority=priority, category=category)
                
                # æ˜¾ç¤ºæ’­æŠ¥å†…å®¹
                QMessageBox.information(self, "è¯­éŸ³æ’­æŠ¥ç¯å¢ƒ", f"æ­£åœ¨æ’­æŠ¥ç¯å¢ƒä¿¡æ¯:\n\n{voice_content}")
            else:
                QMessageBox.information(self, "è¯­éŸ³æ’­æŠ¥ç¯å¢ƒ", "å½“å‰ç¯å¢ƒå®‰å…¨ï¼Œæ— éœ€ç‰¹æ®Šæ’­æŠ¥")
            
        except Exception as e:
            QMessageBox.critical(self, "é”™è¯¯", f"è¯­éŸ³æ’­æŠ¥ç¯å¢ƒå¤±è´¥: {e}")
    
    def real_time_environment_voice_announce(self, env_result, detections):
        """å®æ—¶ç¯å¢ƒè¯­éŸ³æ’­æŠ¥"""
        try:
            # æ£€æŸ¥æ’­æŠ¥å†·å´æ—¶é—´
            current_time = time.time()
            if current_time - self.last_voice_time < self.voice_cooldown:
                return
            
            # è·å–ç¯å¢ƒå®‰å…¨ç­‰çº§
            overall_safety = env_result.get('overall_safety_level', 'safe')
            safety_score = env_result.get('safety_score', 1.0)
            safety_percentage = int(safety_score * 100)
            
            # æ ¹æ®å®‰å…¨ç­‰çº§å†³å®šæ’­æŠ¥å†…å®¹
            if overall_safety == 'high_risk':
                # é«˜é£é™©ç¯å¢ƒï¼Œç«‹å³æ’­æŠ¥
                voice_content = f"ç¯å¢ƒé«˜é£é™©ï¼Œå®‰å…¨è¯„åˆ†{safety_percentage}%ï¼Œè¯·ç«‹å³åœæ­¢å‰è¿›"
                priority = 5
                category = "ç´§æ€¥"
                self.voice_announce(voice_content, priority=priority, category=category)
                self.last_voice_time = current_time
                
            elif overall_safety == 'medium_risk':
                # ä¸­ç­‰é£é™©ç¯å¢ƒï¼Œæ’­æŠ¥è­¦å‘Š
                voice_content = f"ç¯å¢ƒä¸­ç­‰é£é™©ï¼Œå®‰å…¨è¯„åˆ†{safety_percentage}%ï¼Œè¯·å°å¿ƒå‰è¡Œ"
                priority = 3
                category = "è­¦å‘Š"
                self.voice_announce(voice_content, priority=priority, category=category)
                self.last_voice_time = current_time
                
            else:
                # å®‰å…¨ç¯å¢ƒï¼Œå®šæœŸæ’­æŠ¥çŠ¶æ€
                if current_time - self.last_voice_time > 10:  # æ¯10ç§’æ’­æŠ¥ä¸€æ¬¡å®‰å…¨çŠ¶æ€
                    voice_content = f"ç¯å¢ƒå®‰å…¨ï¼Œå®‰å…¨è¯„åˆ†{safety_percentage}%"
                    priority = 1
                    category = "æ£€æµ‹"
                    self.voice_announce(voice_content, priority=priority, category=category)
                    self.last_voice_time = current_time
            
            # æ£€æµ‹åˆ°é‡è¦ç¯å¢ƒäº‹ç‰©æ—¶æ’­æŠ¥
            if detections:
                for detection in detections:
                    obj_type = detection.get('class_name', 'æœªçŸ¥ç‰©ä½“')
                    confidence = detection.get('confidence', 0)
                    
                    # åªæ’­æŠ¥é«˜ç½®ä¿¡åº¦çš„æ£€æµ‹ç»“æœ
                    if confidence > 0.7:
                        bbox = detection.get('bbox', [0, 0, 0, 0])
                        x1, y1, x2, y2 = bbox
                        position = self.get_object_position(x1, y1, x2, y2)
                        
                        # æ ¹æ®ç‰©ä½“ç±»å‹å†³å®šæ’­æŠ¥å†…å®¹
                        if obj_type in ['äºº', 'person', 'è¡Œäºº']:
                            voice_content = f"å‰æ–¹{position}æ£€æµ‹åˆ°è¡Œäºº"
                        elif obj_type in ['è½¦', 'car', 'è½¦è¾†']:
                            voice_content = f"å‰æ–¹{position}æ£€æµ‹åˆ°è½¦è¾†"
                        elif obj_type in ['éšœç¢ç‰©', 'obstacle']:
                            voice_content = f"å‰æ–¹{position}æ£€æµ‹åˆ°éšœç¢ç‰©"
                        else:
                            voice_content = f"å‰æ–¹{position}æ£€æµ‹åˆ°{obj_type}"
                        
                        # æ’­æŠ¥æ£€æµ‹åˆ°çš„ç‰©ä½“
                        self.voice_announce(voice_content, priority=2, category="æ£€æµ‹")
                        self.last_voice_time = current_time
                        break  # ä¸€æ¬¡åªæ’­æŠ¥ä¸€ä¸ªç‰©ä½“ï¼Œé¿å…é‡å¤
            
        except Exception as e:
            print(f"å®æ—¶ç¯å¢ƒè¯­éŸ³æ’­æŠ¥å¤±è´¥: {e}")
    
    def update_voice_status(self):
        """æ›´æ–°è¯­éŸ³æ’­æŠ¥çŠ¶æ€æ˜¾ç¤º"""
        if self.voice_enabled:
            if self.voice_mode == "é™é»˜æ¨¡å¼":
                self.voice_status_display.setText("è¯­éŸ³æ’­æŠ¥: é™é»˜æ¨¡å¼")
                self.voice_status_display.setStyleSheet("color: #666; font-weight: bold; font-size: 14px; padding: 8px;")
            elif self.voice_mode == "ç®€æ´æ¨¡å¼":
                self.voice_status_display.setText("è¯­éŸ³æ’­æŠ¥: ç®€æ´æ¨¡å¼")
                self.voice_status_display.setStyleSheet("color: #ff9800; font-weight: bold; font-size: 14px; padding: 8px;")
            else:  # è¯¦ç»†æ¨¡å¼
                self.voice_status_display.setText("è¯­éŸ³æ’­æŠ¥: è¯¦ç»†æ¨¡å¼")
                self.voice_status_display.setStyleSheet("color: #4caf50; font-weight: bold; font-size: 14px; padding: 8px;")
        else:
            self.voice_status_display.setText("è¯­éŸ³æ’­æŠ¥: å·²ç¦ç”¨")
            self.voice_status_display.setStyleSheet("color: #f44336; font-weight: bold; font-size: 14px; padding: 8px;")
    
    def open_camera_detect(self):
        """ä¿ç•™åŸæœ‰æ–¹æ³•ä»¥å…¼å®¹æ€§"""
        self.toggle_camera_detection()

class TwoPointImageLabel(QLabel):
    """ä¸¤ç‚¹æ¨¡å¼å›¾åƒæ ‡ç­¾ï¼Œæ”¯æŒé¼ æ ‡äº‹ä»¶"""
    mouse_pressed = pyqtSignal(QMouseEvent)
    mouse_moved = pyqtSignal(QMouseEvent)
    mouse_released = pyqtSignal(QMouseEvent)
    
    def __init__(self, text="è¯·é€‰æ‹©å›¾åƒè¿›è¡Œæ ‡æ³¨"):
        super().__init__(text)
        self.setAcceptDrops(True)
        self.setAlignment(Qt.AlignCenter)
        self.setStyleSheet("""
            QLabel {
                border: 2px dashed #cccccc;
                border-radius: 10px;
                background-color: #f9f9f9;
                color: #666666;
                font-size: 16px;
                padding: 20px;
            }
            QLabel:hover {
                border-color: #0078d4;
                background-color: #f0f8ff;
            }
        """)
        
    def mousePressEvent(self, event: QMouseEvent):
        self.mouse_pressed.emit(event)
        
    def mouseMoveEvent(self, event: QMouseEvent):
        self.mouse_moved.emit(event)
        
    def mouseReleaseEvent(self, event: QMouseEvent):
        self.mouse_released.emit(event)

# å¢å¼ºç‰ˆæ‘„åƒå¤´æ£€æµ‹çª—å£
class EnhancedCameraDetectWindow(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.parent = parent
        self.setWindowTitle("å¢å¼ºç‰ˆæ‘„åƒå¤´å®æ—¶æ£€æµ‹")
        self.setGeometry(100, 100, 1400, 1000)
        self.setWindowFlags(self.windowFlags() | Qt.WindowMaximizeButtonHint)
        
        # æ£€æµ‹çŠ¶æ€
        self.is_detecting = False
        self.cap = None
        self.timer = QTimer()
        self.timer.timeout.connect(self.update_frame)
        
        # æ£€æµ‹ç»“æœ
        self.current_detections = []
        self.current_environment = None
        self.current_trajectory = None
        
        self.init_ui()
        
    def init_ui(self):
        """åˆå§‹åŒ–ç•Œé¢"""
        layout = QVBoxLayout(self)
        
        # æ§åˆ¶é¢æ¿
        control_layout = QHBoxLayout()
        
        self.start_btn = QPushButton("å¼€å§‹æ£€æµ‹")
        self.start_btn.clicked.connect(self.toggle_detection)
        self.start_btn.setStyleSheet("QPushButton { background-color: #4caf50; color: white; font-weight: bold; padding: 10px; }")
        control_layout.addWidget(self.start_btn)
        
        self.show_boxes_btn = QPushButton("æ˜¾ç¤ºæ£€æµ‹æ¡†")
        self.show_boxes_btn.setCheckable(True)
        self.show_boxes_btn.setChecked(True)
        self.show_boxes_btn.clicked.connect(self.toggle_show_boxes)
        control_layout.addWidget(self.show_boxes_btn)
        
        self.show_trajectory_btn = QPushButton("æ˜¾ç¤ºè½¨è¿¹")
        self.show_trajectory_btn.setCheckable(True)
        self.show_trajectory_btn.setChecked(True)
        self.show_trajectory_btn.clicked.connect(self.toggle_show_trajectory)
        control_layout.addWidget(self.show_trajectory_btn)
        
        control_layout.addStretch()
        
        # çŠ¶æ€æ˜¾ç¤º
        self.status_label = QLabel("çŠ¶æ€: æœªå¯åŠ¨")
        self.status_label.setStyleSheet("color: #666; padding: 5px; background-color: #f0f0f0; border-radius: 3px;")
        control_layout.addWidget(self.status_label)
        
        layout.addLayout(control_layout)
        
        # ä¸»æ˜¾ç¤ºåŒºåŸŸ
        main_layout = QHBoxLayout()
        
        # æ‘„åƒå¤´æ˜¾ç¤ºåŒºåŸŸ
        self.camera_label = QLabel("ç‚¹å‡»'å¼€å§‹æ£€æµ‹'å¯åŠ¨æ‘„åƒå¤´")
        self.camera_label.setMinimumSize(800, 600)
        self.camera_label.setStyleSheet("""
            QLabel {
                border: 2px solid #ddd;
                border-radius: 10px;
                background-color: #f9f9f9;
                color: #666;
                font-size: 16px;
                padding: 20px;
            }
        """)
        self.camera_label.setAlignment(Qt.AlignCenter)
        main_layout.addWidget(self.camera_label)
        
        # æ£€æµ‹ä¿¡æ¯é¢æ¿
        info_panel = QWidget()
        info_panel.setMaximumWidth(300)
        info_layout = QVBoxLayout(info_panel)
        
        # æ£€æµ‹ç»“æœ
        detection_group = QGroupBox("æ£€æµ‹ç»“æœ")
        detection_layout = QVBoxLayout(detection_group)
        
        self.detection_count_label = QLabel("æ£€æµ‹æ•°é‡: 0")
        detection_layout.addWidget(self.detection_count_label)
        
        self.detection_list = QListWidget()
        self.detection_list.setMaximumHeight(150)
        detection_layout.addWidget(self.detection_list)
        
        info_layout.addWidget(detection_group)
        
        # ç¯å¢ƒä¿¡æ¯
        env_group = QGroupBox("ç¯å¢ƒä¿¡æ¯")
        env_layout = QVBoxLayout(env_group)
        
        self.env_status_label = QLabel("ç¯å¢ƒ: æœªæ£€æµ‹")
        env_layout.addWidget(self.env_status_label)
        
        self.env_warnings_label = QLabel("è­¦å‘Š: æ— ")
        env_layout.addWidget(self.env_warnings_label)
        
        info_layout.addWidget(env_group)
        
        # è½¨è¿¹ä¿¡æ¯
        trajectory_group = QGroupBox("è½¨è¿¹ä¿¡æ¯")
        trajectory_layout = QVBoxLayout(trajectory_group)
        
        self.trajectory_status_label = QLabel("è½¨è¿¹: æœªé¢„æµ‹")
        trajectory_layout.addWidget(self.trajectory_status_label)
        
        self.collision_risk_label = QLabel("ç¢°æ’é£é™©: ä½")
        trajectory_layout.addWidget(self.collision_risk_label)
        
        info_layout.addWidget(trajectory_group)
        
        main_layout.addWidget(info_panel)
        layout.addLayout(main_layout)
        
    def toggle_detection(self):
        """åˆ‡æ¢æ£€æµ‹çŠ¶æ€"""
        if not self.is_detecting:
            self.start_detection()
        else:
            self.stop_detection()
    
    def start_detection(self):
        """å¼€å§‹æ£€æµ‹"""
        try:
            self.cap = cv2.VideoCapture(0)
            if not self.cap.isOpened():
                QMessageBox.warning(self, "é”™è¯¯", "æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
                return
            
            self.is_detecting = True
            self.start_btn.setText("åœæ­¢æ£€æµ‹")
            self.start_btn.setStyleSheet("QPushButton { background-color: #f44336; color: white; font-weight: bold; padding: 10px; }")
            self.status_label.setText("çŠ¶æ€: æ£€æµ‹ä¸­")
            self.status_label.setStyleSheet("color: #4caf50; padding: 5px; background-color: #e8f5e8; border-radius: 3px;")
            
            self.timer.start(33)  # çº¦30FPS
            
        except Exception as e:
            QMessageBox.critical(self, "é”™è¯¯", f"å¯åŠ¨æ£€æµ‹å¤±è´¥: {e}")
    
    def stop_detection(self):
        """åœæ­¢æ£€æµ‹"""
        self.is_detecting = False
        self.timer.stop()
        
        if self.cap:
            self.cap.release()
            self.cap = None
        
        self.start_btn.setText("å¼€å§‹æ£€æµ‹")
        self.start_btn.setStyleSheet("QPushButton { background-color: #4caf50; color: white; font-weight: bold; padding: 10px; }")
        self.status_label.setText("çŠ¶æ€: å·²åœæ­¢")
        self.status_label.setStyleSheet("color: #666; padding: 5px; background-color: #f0f0f0; border-radius: 3px;")
        
        self.camera_label.setText("æ£€æµ‹å·²åœæ­¢")
    
    def update_frame(self):
        """æ›´æ–°å¸§"""
        if not self.cap or not self.is_detecting:
            return
        
        ret, frame = self.cap.read()
        if not ret:
            return
        
        # è¿›è¡Œæ£€æµ‹
        detections = self.detect_objects(frame)
        
        # ç¯å¢ƒæ£€æµ‹å’Œè½¨è¿¹é¢„æµ‹
        if self.parent and self.parent.env_detector and self.parent.trajectory_predictor:
            # ç¯å¢ƒæ£€æµ‹
            env_result = self.parent.analyze_environment(frame)
            if env_result:
                self.current_environment = env_result
                self.update_environment_display(env_result)
            
            # è½¨è¿¹é¢„æµ‹
            trajectory_result = self.parent.predict_trajectory(frame)
            if trajectory_result:
                self.current_trajectory = trajectory_result
                self.update_trajectory_display(trajectory_result)
        
        # ç»˜åˆ¶æ£€æµ‹ç»“æœ
        if self.show_boxes_btn.isChecked():
            frame = self.draw_detections(frame, detections)
        
        if self.show_trajectory_btn.isChecked() and self.current_trajectory:
            frame = self.draw_trajectory(frame, self.current_trajectory)
        
        # æ˜¾ç¤ºå¸§
        self.display_frame(frame)
        
        # æ›´æ–°æ£€æµ‹ä¿¡æ¯
        self.update_detection_info(detections)
    
    def detect_objects(self, frame):
        """æ£€æµ‹ç‰©ä½“"""
        # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„æ£€æµ‹æ¨¡å‹
        # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿç»“æœ
        detections = []
        
        # æ¨¡æ‹Ÿæ£€æµ‹ç»“æœ
        if np.random.random() > 0.7:
            h, w = frame.shape[:2]
            x1 = int(w * 0.2)
            y1 = int(h * 0.3)
            x2 = int(w * 0.4)
            y2 = int(h * 0.7)
            
            detections.append({
                'bbox': [x1, y1, x2, y2],
                'class_name': 'obstacle',
                'confidence': 0.85,
                'class_id': 0
            })
        
        return detections
    
    def draw_detections(self, frame, detections):
        """ç»˜åˆ¶æ£€æµ‹æ¡†"""
        for detection in detections:
            bbox = detection['bbox']
            class_name = detection['class_name']
            confidence = detection['confidence']
            class_id = detection.get('class_id', 0)
            
            x1, y1, x2, y2 = map(int, bbox)
            
            # æ ¹æ®ç±»åˆ«é€‰æ‹©é¢œè‰²
            colors = {
                0: (0, 255, 0),    # ç»¿è‰² - é™æ€éšœç¢
                1: (0, 0, 255),    # çº¢è‰² - åŠ¨æ€éšœç¢
                2: (255, 0, 0),    # è“è‰² - åœ°é¢å±é™©
            }
            color = colors.get(class_id, (255, 255, 0))
            
            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{class_name}: {confidence:.2f}"
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
            cv2.rectangle(frame, (x1, y1 - label_size[1] - 10), (x1 + label_size[0], y1), color, -1)
            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        return frame
    
    def draw_trajectory(self, frame, trajectory_result):
        """ç»˜åˆ¶è½¨è¿¹é¢„æµ‹"""
        # ç»˜åˆ¶ç›²é“è½¨è¿¹
        if trajectory_result.get('blind_path') and trajectory_result['blind_path'].get('predicted_trajectory'):
            trajectory = trajectory_result['blind_path']['predicted_trajectory']
            for i, point in enumerate(trajectory):
                cv2.circle(frame, point, 3, (0, 255, 255), -1)
                if i > 0:
                    cv2.line(frame, trajectory[i-1], point, (0, 255, 255), 2)
        
        # ç»˜åˆ¶ç›®æ ‡è½¨è¿¹
        for obj in trajectory_result.get('tracked_objects', []):
            if obj.get('predicted_trajectory'):
                trajectory = obj['predicted_trajectory']
                for i, point in enumerate(trajectory):
                    cv2.circle(frame, point, 2, (255, 0, 255), -1)
                    if i > 0:
                        cv2.line(frame, trajectory[i-1], point, (255, 0, 255), 1)
        
        return frame
    
    def display_frame(self, frame):
        """æ˜¾ç¤ºå¸§"""
        height, width, channel = frame.shape
        bytes_per_line = 3 * width
        q_image = QImage(frame.data, width, height, bytes_per_line, QImage.Format_RGB888).rgbSwapped()
        
        pixmap = QPixmap.fromImage(q_image)
        scaled_pixmap = pixmap.scaled(self.camera_label.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation)
        self.camera_label.setPixmap(scaled_pixmap)
    
    def update_detection_info(self, detections):
        """æ›´æ–°æ£€æµ‹ä¿¡æ¯"""
        self.current_detections = detections
        self.detection_count_label.setText(f"æ£€æµ‹æ•°é‡: {len(detections)}")
        
        # æ›´æ–°æ£€æµ‹åˆ—è¡¨
        self.detection_list.clear()
        for i, detection in enumerate(detections):
            class_name = detection['class_name']
            confidence = detection['confidence']
            item_text = f"{i+1}. {class_name} ({confidence:.2f})"
            self.detection_list.addItem(item_text)
    
    def update_environment_display(self, env_result):
        """æ›´æ–°ç¯å¢ƒæ˜¾ç¤º"""
        overall_safety = env_result.get('overall_safety_level', 'safe')
        if overall_safety == 'high_risk':
            self.env_status_label.setText("ç¯å¢ƒ: é«˜é£é™©")
            self.env_status_label.setStyleSheet("color: #d32f2f;")
        elif overall_safety == 'medium_risk':
            self.env_status_label.setText("ç¯å¢ƒ: ä¸­ç­‰é£é™©")
            self.env_status_label.setStyleSheet("color: #f57c00;")
        else:
            self.env_status_label.setText("ç¯å¢ƒ: å®‰å…¨")
            self.env_status_label.setStyleSheet("color: #4caf50;")
        
        warnings = env_result.get('warnings', [])
        if warnings:
            self.env_warnings_label.setText(f"è­¦å‘Š: {len(warnings)}ä¸ª")
            self.env_warnings_label.setStyleSheet("color: #d32f2f;")
        else:
            self.env_warnings_label.setText("è­¦å‘Š: æ— ")
            self.env_warnings_label.setStyleSheet("color: #4caf50;")
    
    def update_trajectory_display(self, result, detections):
        """æ›´æ–°è½¨è¿¹æ˜¾ç¤º"""
        # æ›´æ–°åŠ¨æ€éšœç¢ç‰©è½¨è¿¹
        dynamic_objects = [d for d in detections if d.get('class_id') == 1]  # åŠ¨æ€éšœç¢
        if dynamic_objects:
            trajectory_text = ""
            for i, obj in enumerate(dynamic_objects, 1):
                obj_name = obj.get('class_name', 'ç‰©ä½“')
                bbox = obj.get('bbox', [0, 0, 0, 0])
                x1, y1, x2, y2 = bbox
                position = self.get_object_position(x1, y1, x2, y2)
                
                # é¢„æµ‹ä¸‹ä¸€æ­¥è¡Œä¸º
                predicted_action = self.predict_object_behavior(obj)
                trajectory_text += f"{i}. {obj_name} ({position}) - é¢„æµ‹è¡Œä¸º: {predicted_action}\n"
            
            self.dynamic_objects_list.setPlainText(trajectory_text)
        else:
            self.dynamic_objects_list.setPlainText("æ— åŠ¨æ€éšœç¢ç‰©")
        
        # æ›´æ–°ç”¨æˆ·è½¨è¿¹å»ºè®®
        user_suggestions = self.generate_user_trajectory_suggestions(detections, result)
        self.user_trajectory_list.setPlainText(user_suggestions)
        
        # ç”Ÿæˆè½¨è¿¹æ’­æŠ¥æ–‡æœ¬
        trajectory_voice_content = self.generate_trajectory_voice_content(detections, result)
        self.trajectory_voice_text.setPlainText(trajectory_voice_content)
        
        # è¯­éŸ³æ’­æŠ¥
        if trajectory_voice_content:
            self.voice_announce(trajectory_voice_content, priority=3, category="è½¨è¿¹")
        
        # æ›´æ–°è½¨è¿¹çŠ¶æ€
        if result.get('blind_path'):
            confidence = result['blind_path'].get('confidence', 0)
            if confidence > 0.7:
                self.trajectory_status_label.setText("è½¨è¿¹: æ¸…æ™°")
                self.trajectory_status_label.setStyleSheet("color: #4caf50;")
            else:
                self.trajectory_status_label.setText("è½¨è¿¹: æ¨¡ç³Š")
                self.trajectory_status_label.setStyleSheet("color: #ff9800;")
        else:
            self.trajectory_status_label.setText("è½¨è¿¹: æœªæ£€æµ‹")
            self.trajectory_status_label.setStyleSheet("color: #666;")
        
        # æ›´æ–°ç¢°æ’é£é™©
        collision_risks = result.get('collision_risks', {})
        if collision_risks:
            max_risk = max(collision_risks.values())
            if max_risk > 0.7:
                self.collision_risk_label.setText("ç¢°æ’é£é™©: é«˜")
                self.collision_risk_label.setStyleSheet("color: #d32f2f;")
            elif max_risk > 0.4:
                self.collision_risk_label.setText("ç¢°æ’é£é™©: ä¸­")
                self.collision_risk_label.setStyleSheet("color: #f57c00;")
            else:
                self.collision_risk_label.setText("ç¢°æ’é£é™©: ä½")
                self.collision_risk_label.setStyleSheet("color: #4caf50;")
        else:
            self.collision_risk_label.setText("ç¢°æ’é£é™©: ä½")
            self.collision_risk_label.setStyleSheet("color: #4caf50;")
    
    def predict_object_behavior(self, obj):
        """é¢„æµ‹ç‰©ä½“è¡Œä¸º"""
        obj_name = obj.get('class_name', 'ç‰©ä½“')
        bbox = obj.get('bbox', [0, 0, 0, 0])
        x1, y1, x2, y2 = bbox
        center_x = (x1 + x2) / 2
        center_y = (y1 + y2) / 2
        
        # æ ¹æ®ç‰©ä½“ç±»å‹å’Œä½ç½®é¢„æµ‹è¡Œä¸º
        if obj_name in ['person', 'äºº']:
            if center_x < 200:
                return "å¯èƒ½å‘å·¦ç§»åŠ¨"
            elif center_x > 440:
                return "å¯èƒ½å‘å³ç§»åŠ¨"
            else:
                return "å¯èƒ½ç»§ç»­ç›´è¡Œ"
        elif obj_name in ['car', 'æ±½è½¦', 'truck', 'å¡è½¦', 'bus', 'å…¬äº¤è½¦']:
            if center_x < 200:
                return "å¯èƒ½å‘å·¦è½¬å‘"
            elif center_x > 440:
                return "å¯èƒ½å‘å³è½¬å‘"
            else:
                return "å¯èƒ½ç»§ç»­ç›´è¡Œ"
        elif obj_name in ['bicycle', 'è‡ªè¡Œè½¦', 'motorcycle', 'æ‘©æ‰˜è½¦']:
            return "å¯èƒ½å¿«é€Ÿç§»åŠ¨ï¼Œæ³¨æ„é¿è®©"
        else:
            return "ä½ç½®ç›¸å¯¹ç¨³å®š"
    
    def generate_user_trajectory_suggestions(self, detections, result):
        """ç”Ÿæˆç”¨æˆ·è½¨è¿¹å»ºè®®"""
        suggestions = []
        
        # åˆ†æåŠ¨æ€éšœç¢ç‰©
        dynamic_objects = [d for d in detections if d.get('class_id') == 1]
        if dynamic_objects:
            for obj in dynamic_objects:
                obj_name = obj.get('class_name', 'ç‰©ä½“')
                bbox = obj.get('bbox', [0, 0, 0, 0])
                x1, y1, x2, y2 = bbox
                position = self.get_object_position(x1, y1, x2, y2)
                
                if position == "å·¦ä¾§":
                    suggestions.append(f"å»ºè®®å‘å³åç§»ï¼Œé¿å¼€å·¦ä¾§{obj_name}")
                elif position == "å³ä¾§":
                    suggestions.append(f"å»ºè®®å‘å·¦åç§»ï¼Œé¿å¼€å³ä¾§{obj_name}")
                elif position == "ä¸­å¤®":
                    suggestions.append(f"å»ºè®®å‡é€Ÿæˆ–åœæ­¢ï¼Œå‰æ–¹æœ‰{obj_name}")
                else:
                    suggestions.append(f"æ³¨æ„{position}çš„{obj_name}")
        
        # åˆ†æé™æ€éšœç¢ç‰©
        static_objects = [d for d in detections if d.get('class_id') == 0]
        if static_objects:
            for obj in static_objects:
                obj_name = obj.get('class_name', 'ç‰©ä½“')
                bbox = obj.get('bbox', [0, 0, 0, 0])
                x1, y1, x2, y2 = bbox
                position = self.get_object_position(x1, y1, x2, y2)
                
                if position == "å·¦ä¾§":
                    suggestions.append(f"å»ºè®®å‘å³ç»•è¡Œï¼Œé¿å¼€å·¦ä¾§{obj_name}")
                elif position == "å³ä¾§":
                    suggestions.append(f"å»ºè®®å‘å·¦ç»•è¡Œï¼Œé¿å¼€å³ä¾§{obj_name}")
                elif position == "ä¸­å¤®":
                    suggestions.append(f"å»ºè®®å¯»æ‰¾ç»•è¡Œè·¯å¾„ï¼Œå‰æ–¹æœ‰{obj_name}")
        
        # åˆ†æåœ°é¢å±é™©
        ground_hazards = [d for d in detections if d.get('class_id') == 2]
        if ground_hazards:
            for obj in ground_hazards:
                obj_name = obj.get('class_name', 'ç‰©ä½“')
                bbox = obj.get('bbox', [0, 0, 0, 0])
                x1, y1, x2, y2 = bbox
                position = self.get_object_position(x1, y1, x2, y2)
                suggestions.append(f"æ³¨æ„{position}çš„åœ°é¢å±é™©{obj_name}ï¼Œå»ºè®®ç»•è¡Œ")
        
        if not suggestions:
            suggestions.append("è·¯å¾„æ¸…æ™°ï¼Œå¯ä»¥æ­£å¸¸å‰è¿›")
        
        return "\n".join(suggestions)
    
    def generate_trajectory_voice_content(self, detections, result):
        """ç”Ÿæˆè½¨è¿¹é¢„æµ‹è¯­éŸ³æ’­æŠ¥å†…å®¹"""
        content_parts = []
        
        # åŠ¨æ€éšœç¢ç‰©è½¨è¿¹æ’­æŠ¥
        dynamic_objects = [d for d in detections if d.get('class_id') == 1]
        if dynamic_objects:
            for obj in dynamic_objects:
                obj_name = obj.get('class_name', 'ç‰©ä½“')
                bbox = obj.get('bbox', [0, 0, 0, 0])
                x1, y1, x2, y2 = bbox
                position = self.get_object_position(x1, y1, x2, y2)
                predicted_action = self.predict_object_behavior(obj)
                content_parts.append(f"å‰æ–¹{position}çš„{obj_name}ï¼Œ{predicted_action}")
        
        # ç”¨æˆ·è½¨è¿¹å»ºè®®æ’­æŠ¥
        user_suggestions = self.generate_user_trajectory_suggestions(detections, result)
        if user_suggestions and "è·¯å¾„æ¸…æ™°" not in user_suggestions:
            # åªæ’­æŠ¥æœ€é‡è¦çš„å»ºè®®
            first_suggestion = user_suggestions.split('\n')[0]
            content_parts.append(first_suggestion)
        
        return "ï¼›".join(content_parts) if content_parts else "è·¯å¾„å®‰å…¨"
    
    def toggle_show_boxes(self):
        """åˆ‡æ¢æ˜¾ç¤ºæ£€æµ‹æ¡†"""
        pass  # çŠ¶æ€å·²åœ¨update_frameä¸­ä½¿ç”¨
    
    def toggle_show_trajectory(self):
        """åˆ‡æ¢æ˜¾ç¤ºè½¨è¿¹"""
        pass  # çŠ¶æ€å·²åœ¨update_frameä¸­ä½¿ç”¨
    
    def closeEvent(self, event):
        """å…³é—­äº‹ä»¶"""
        self.stop_detection()
        event.accept()

# æ–°å¢ï¼šæ‘„åƒå¤´æ£€æµ‹çª—å£
class CameraDetectWindow(QDialog):
    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("æ‘„åƒå¤´å®æ—¶æ£€æµ‹")
        self.setGeometry(100, 100, 1280, 960)
        self.layout = QVBoxLayout(self)
        
        # æ‘„åƒå¤´æ˜¾ç¤ºåŒºåŸŸ
        self.image_label = QLabel("æ­£åœ¨æ‰“å¼€æ‘„åƒå¤´...")
        self.image_label.setAlignment(Qt.AlignCenter)
        self.image_label.setMinimumSize(800, 600)
        self.layout.addWidget(self.image_label)
        
        # çŠ¶æ€æ˜¾ç¤ºåŒºåŸŸ
        self.status_label = QLabel("")
        self.status_label.setStyleSheet("""
            QLabel {
                background-color: #f0f0f0;
                border: 1px solid #ccc;
                padding: 5px;
                font-size: 14px;
                color: #333;
            }
        """)
        self.layout.addWidget(self.status_label)
        
        # è¯­éŸ³æ§åˆ¶é¢æ¿
        self.create_voice_control_panel()
        
        # åˆå§‹åŒ–å˜é‡
        self.timer = None
        self.cap = None
        self.model = None
        self.baidu_client = None
        self.tts_lock = None
        self.last_alert_time = 0
        self.is_running = False
        
        # è¯­éŸ³ç›¸å…³
        self.voice_system = None
        
        # è¯­éŸ³åº“
        self.voice_library = None
        if VOICE_LIBRARY_AVAILABLE:
            self.voice_library = VoiceLibrary()
            print("âœ… è¯­éŸ³åº“åˆå§‹åŒ–æˆåŠŸ")
        else:
            print("âš ï¸ è¯­éŸ³åº“ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤è¯­éŸ³æç¤º")
        
        # è·ç¦»å˜åŒ–æ£€æµ‹
        self.last_distance = None
        self.last_direction = None
        self.last_label = None
        
        # è½¨è¿¹é¢„æµ‹
        self.trajectory_predictor = None
        if TRAJECTORY_PREDICTOR_AVAILABLE:
            self.trajectory_predictor = TrajectoryPredictor()
            print("âœ… è½¨è¿¹é¢„æµ‹æ¨¡å—åˆå§‹åŒ–æˆåŠŸ")
        else:
            print("âš ï¸ è½¨è¿¹é¢„æµ‹æ¨¡å—ä¸å¯ç”¨ï¼Œè½¨è¿¹é¢„æµ‹åŠŸèƒ½å°†ä¸å¯ç”¨")
        
        # åˆå§‹åŒ–æ‘„åƒå¤´
        self.init_camera()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.load_model()
        
        # åˆå§‹åŒ–è¯­éŸ³API
        self.init_voice_api()
        
        # å¯åŠ¨å®šæ—¶å™¨
        self.start_timer()
    
    def create_voice_control_panel(self):
        """åˆ›å»ºè¯­éŸ³æ§åˆ¶é¢æ¿"""
        # åˆ›å»ºä¸»æ§åˆ¶é¢æ¿
        control_panel = QHBoxLayout()
        
        # è¯­éŸ³æ§åˆ¶é¢æ¿
        voice_panel = QGroupBox("è¯­éŸ³æ§åˆ¶")
        voice_panel.setStyleSheet("""
            QGroupBox {
                font-weight: bold;
                border: 2px solid #0078d4;
                border-radius: 5px;
                margin-top: 10px;
                padding-top: 10px;
            }
            QGroupBox::title {
                subcontrol-origin: margin;
                left: 10px;
                padding: 0 5px 0 5px;
            }
        """)
        
        voice_layout = QHBoxLayout()
        
        # è¯­éŸ³å¼€å…³æŒ‰é’®
        self.voice_toggle_btn = QPushButton("è¯­éŸ³æ’­æŠ¥: å¼€å¯")
        self.voice_toggle_btn.setCheckable(True)
        self.voice_toggle_btn.setChecked(True)
        self.voice_toggle_btn.clicked.connect(self.toggle_voice)
        self.voice_toggle_btn.setStyleSheet("""
            QPushButton {
                background-color: #0078d4;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 4px;
                font-weight: bold;
            }
            QPushButton:checked {
                background-color: #28a745;
            }
            QPushButton:pressed {
                background-color: #005a9e;
            }
        """)
        
        # éŸ³é‡æ§åˆ¶
        volume_label = QLabel("éŸ³é‡:")
        self.volume_slider = QSpinBox()
        self.volume_slider.setRange(0, 100)
        self.volume_slider.setValue(80)
        self.volume_slider.valueChanged.connect(self.change_volume)
        
        # æµ‹è¯•è¯­éŸ³æŒ‰é’®
        test_voice_btn = QPushButton("æµ‹è¯•è¯­éŸ³")
        test_voice_btn.clicked.connect(self.test_voice_system)
        test_voice_btn.setStyleSheet("""
            QPushButton {
                background-color: #ffc107;
                color: #333;
                border: none;
                padding: 8px 16px;
                border-radius: 4px;
                font-weight: bold;
            }
            QPushButton:pressed {
                background-color: #e0a800;
            }
        """)
        
        # è¯­éŸ³çŠ¶æ€æ˜¾ç¤º
        self.voice_status_label = QLabel("è¯­éŸ³ç³»ç»Ÿå°±ç»ª")
        self.voice_status_label.setStyleSheet("""
            QLabel {
                color: #28a745;
                font-weight: bold;
                padding: 5px;
            }
        """)
        
        voice_layout.addWidget(self.voice_toggle_btn)
        voice_layout.addWidget(volume_label)
        voice_layout.addWidget(self.volume_slider)
        voice_layout.addWidget(test_voice_btn)
        voice_layout.addWidget(self.voice_status_label)
        voice_layout.addStretch()
        
        voice_panel.setLayout(voice_layout)
        
        # è½¨è¿¹é¢„æµ‹æ§åˆ¶é¢æ¿
        trajectory_panel = QGroupBox("è½¨è¿¹é¢„æµ‹æ§åˆ¶")
        trajectory_panel.setStyleSheet("""
            QGroupBox {
                font-weight: bold;
                border: 2px solid #28a745;
                border-radius: 5px;
                margin-top: 10px;
                padding-top: 10px;
            }
            QGroupBox::title {
                subcontrol-origin: margin;
                left: 10px;
                padding: 0 5px 0 5px;
            }
        """)
        
        trajectory_layout = QHBoxLayout()
        
        # è½¨è¿¹é¢„æµ‹å¼€å…³
        self.trajectory_toggle_btn = QPushButton("è½¨è¿¹é¢„æµ‹: å¼€å¯")
        self.trajectory_toggle_btn.setCheckable(True)
        self.trajectory_toggle_btn.setChecked(True)
        self.trajectory_toggle_btn.clicked.connect(self.toggle_trajectory)
        self.trajectory_toggle_btn.setStyleSheet("""
            QPushButton {
                background-color: #28a745;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 4px;
                font-weight: bold;
            }
            QPushButton:checked {
                background-color: #28a745;
            }
            QPushButton:!checked {
                background-color: #6c757d;
            }
            QPushButton:pressed {
                background-color: #1e7e34;
            }
        """)
        
        # è½¨è¿¹é¢„æµ‹çŠ¶æ€æ˜¾ç¤º
        self.trajectory_status_label = QLabel("è½¨è¿¹é¢„æµ‹å°±ç»ª")
        self.trajectory_status_label.setStyleSheet("""
            QLabel {
                color: #28a745;
                font-weight: bold;
                padding: 5px;
            }
        """)
        
        # ç›²é“çŠ¶æ€æ˜¾ç¤º
        self.blind_path_status_label = QLabel("ç›²é“: æœªæ£€æµ‹")
        self.blind_path_status_label.setStyleSheet("""
            QLabel {
                color: #6c757d;
                font-weight: bold;
                padding: 5px;
            }
        """)
        
        # ç¢°æ’é£é™©æ˜¾ç¤º
        self.collision_risk_label = QLabel("ç¢°æ’é£é™©: ä½")
        self.collision_risk_label.setStyleSheet("""
            QLabel {
                color: #28a745;
                font-weight: bold;
                padding: 5px;
            }
        """)
        
        trajectory_layout.addWidget(self.trajectory_toggle_btn)
        trajectory_layout.addWidget(self.trajectory_status_label)
        trajectory_layout.addWidget(self.blind_path_status_label)
        trajectory_layout.addWidget(self.collision_risk_label)
        trajectory_layout.addStretch()
        
        trajectory_panel.setLayout(trajectory_layout)
        
        # å°†ä¸¤ä¸ªé¢æ¿æ·»åŠ åˆ°ä¸»æ§åˆ¶é¢æ¿
        control_panel.addWidget(voice_panel)
        control_panel.addWidget(trajectory_panel)
        
        # å°†ä¸»æ§åˆ¶é¢æ¿æ·»åŠ åˆ°å¸ƒå±€
        self.layout.addLayout(control_panel)

    def init_camera(self):
        """åˆå§‹åŒ–æ‘„åƒå¤´"""
        try:
            self.cap = cv2.VideoCapture(0)
            if not self.cap.isOpened():
                # å°è¯•å…¶ä»–æ‘„åƒå¤´ç´¢å¼•
                for i in range(1, 5):
                    self.cap = cv2.VideoCapture(i)
                    if self.cap.isOpened():
                        break
                
                if not self.cap.isOpened():
                    raise Exception("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
                    
            self.status_label.setText("æ‘„åƒå¤´åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            self.status_label.setText(f"æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥: {e}")
            QMessageBox.warning(self, "æ‘„åƒå¤´é”™è¯¯", f"æ— æ³•æ‰“å¼€æ‘„åƒå¤´: {e}")

    def init_voice_api(self):
        """åˆå§‹åŒ–è¯­éŸ³API"""
        try:
            print("ğŸ”§ å¼€å§‹åˆå§‹åŒ–è¯­éŸ³API...")
            
            # åˆå§‹åŒ–ç®€åŒ–è¯­éŸ³ç³»ç»Ÿ
            self.voice_system = SimpleVoiceSystem()
            print("âœ… è¯­éŸ³ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            
            self.status_label.setText("è¯­éŸ³APIåˆå§‹åŒ–æˆåŠŸ")
            print("âœ… è¯­éŸ³ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            
            # æµ‹è¯•è¯­éŸ³åŠŸèƒ½
            self.test_voice_system()
            
        except Exception as e:
            self.status_label.setText(f"è¯­éŸ³APIåˆå§‹åŒ–å¤±è´¥: {e}")
            print(f"âŒ è¯­éŸ³ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
    
    def test_voice_system(self):
        """æµ‹è¯•è¯­éŸ³ç³»ç»Ÿ"""
        try:
            print("ğŸ§ª å¼€å§‹æµ‹è¯•è¯­éŸ³ç³»ç»Ÿ...")
            test_text = "è¯­éŸ³ç³»ç»Ÿæµ‹è¯•æˆåŠŸ"
            self.speak(test_text)
            self.voice_status_label.setText("è¯­éŸ³æµ‹è¯•ä¸­...")
            self.voice_status_label.setStyleSheet("color: #ffc107; font-weight: bold; padding: 5px;")
            print("âœ… è¯­éŸ³æµ‹è¯•å®Œæˆ")
        except Exception as e:
            print(f"âŒ è¯­éŸ³æµ‹è¯•å¤±è´¥: {e}")
            self.voice_status_label.setText("è¯­éŸ³æµ‹è¯•å¤±è´¥")
            self.voice_status_label.setStyleSheet("color: #dc3545; font-weight: bold; padding: 5px;")
    
    def toggle_voice(self):
        """åˆ‡æ¢è¯­éŸ³æ’­æŠ¥å¼€å…³"""
        if self.voice_toggle_btn.isChecked():
            self.voice_toggle_btn.setText("è¯­éŸ³æ’­æŠ¥: å¼€å¯")
            self.voice_toggle_btn.setStyleSheet("""
                QPushButton {
                    background-color: #28a745;
                    color: white;
                    border: none;
                    padding: 8px 16px;
                    border-radius: 4px;
                    font-weight: bold;
                }
                QPushButton:pressed {
                    background-color: #1e7e34;
                }
            """)
            self.voice_status_label.setText("è¯­éŸ³æ’­æŠ¥å·²å¼€å¯")
            self.voice_status_label.setStyleSheet("color: #28a745; font-weight: bold; padding: 5px;")
        else:
            self.voice_toggle_btn.setText("è¯­éŸ³æ’­æŠ¥: å…³é—­")
            self.voice_toggle_btn.setStyleSheet("""
                QPushButton {
                    background-color: #dc3545;
                    color: white;
                    border: none;
                    padding: 8px 16px;
                    border-radius: 4px;
                    font-weight: bold;
                }
                QPushButton:pressed {
                    background-color: #c82333;
                }
            """)
            self.voice_status_label.setText("è¯­éŸ³æ’­æŠ¥å·²å…³é—­")
            self.voice_status_label.setStyleSheet("color: #dc3545; font-weight: bold; padding: 5px;")
    
    def change_volume(self, value):
        """æ”¹å˜éŸ³é‡"""
        if self.media_player:
            self.media_player.setVolume(value)
            print(f"ğŸ”Š éŸ³é‡è®¾ç½®ä¸º: {value}%")

    def start_timer(self):
        """å¯åŠ¨å®šæ—¶å™¨"""
        try:
            self.timer = QTimer(self)
            self.timer.timeout.connect(self.update_frame)
            self.timer.start(30)  # 30msé—´éš”
            self.is_running = True
        except Exception as e:
            self.status_label.setText(f"å®šæ—¶å™¨å¯åŠ¨å¤±è´¥: {e}")

    def speak(self, text):
        """è¯­éŸ³æ’­æŠ¥"""
        print(f"ğŸ¤ speakæ–¹æ³•è¢«è°ƒç”¨ï¼Œæ–‡æœ¬: {text}")
        
        # æ£€æŸ¥è¯­éŸ³å¼€å…³
        if not self.voice_toggle_btn.isChecked():
            print("ğŸ”‡ è¯­éŸ³æ’­æŠ¥å·²å…³é—­")
            return
            
        if not self.voice_system or not text:
            print("âŒ è¯­éŸ³æ’­æŠ¥å¤±è´¥: è¯­éŸ³ç³»ç»Ÿæˆ–æ–‡æœ¬ä¸ºç©º")
            return
        
        print(f"âœ… å‡†å¤‡æ’­æŠ¥è¯­éŸ³: {text}")
        
        # ç›´æ¥è°ƒç”¨è¯­éŸ³ç³»ç»Ÿ
        self.voice_system.speak(text)
        
        # æ›´æ–°çŠ¶æ€æ˜¾ç¤º
        self.voice_status_label.setText("æ­£åœ¨æ’­æŠ¥...")
        self.voice_status_label.setStyleSheet("color: #0078d4; font-weight: bold; padding: 5px;")
        
        # å»¶è¿Ÿæ¢å¤çŠ¶æ€
        QTimer.singleShot(2000, self.reset_voice_status)
    
    def reset_voice_status(self):
        """é‡ç½®è¯­éŸ³çŠ¶æ€"""
        if self.voice_toggle_btn.isChecked():
            self.voice_status_label.setText("è¯­éŸ³æ’­æŠ¥å·²å¼€å¯")
            self.voice_status_label.setStyleSheet("color: #28a745; font-weight: bold; padding: 5px;")
        else:
            self.voice_status_label.setText("è¯­éŸ³æ’­æŠ¥å·²å…³é—­")
            self.voice_status_label.setStyleSheet("color: #dc3545; font-weight: bold; padding: 5px;")
    
    def toggle_voice(self):
        """åˆ‡æ¢è¯­éŸ³æ’­æŠ¥å¼€å…³"""
        if self.voice_toggle_btn.isChecked():
            self.voice_toggle_btn.setText("è¯­éŸ³æ’­æŠ¥: å¼€å¯")
            self.voice_toggle_btn.setStyleSheet("""
                QPushButton {
                    background-color: #28a745;
                    color: white;
                    border: none;
                    padding: 8px 16px;
                    border-radius: 4px;
                    font-weight: bold;
                }
                QPushButton:pressed {
                    background-color: #1e7e34;
                }
            """)
            if self.voice_system:
                self.voice_system.enable()
            self.voice_status_label.setText("è¯­éŸ³æ’­æŠ¥å·²å¼€å¯")
            self.voice_status_label.setStyleSheet("color: #28a745; font-weight: bold; padding: 5px;")
        else:
            self.voice_toggle_btn.setText("è¯­éŸ³æ’­æŠ¥: å…³é—­")
            self.voice_toggle_btn.setStyleSheet("""
                QPushButton {
                    background-color: #dc3545;
                    color: white;
                    border: none;
                    padding: 8px 16px;
                    border-radius: 4px;
                    font-weight: bold;
                }
                QPushButton:pressed {
                    background-color: #c82333;
                }
            """)
            if self.voice_system:
                self.voice_system.disable()
            self.voice_status_label.setText("è¯­éŸ³æ’­æŠ¥å·²å…³é—­")
            self.voice_status_label.setStyleSheet("color: #dc3545; font-weight: bold; padding: 5px;")
    
    def change_volume(self, value):
        """æ”¹å˜éŸ³é‡ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        print(f"ğŸ”Š éŸ³é‡è®¾ç½®ä¸º: {value}%")
    
    def toggle_trajectory(self):
        """åˆ‡æ¢è½¨è¿¹é¢„æµ‹å¼€å…³"""
        if self.trajectory_toggle_btn.isChecked():
            self.trajectory_toggle_btn.setText("è½¨è¿¹é¢„æµ‹: å¼€å¯")
            self.trajectory_toggle_btn.setStyleSheet("""
                QPushButton {
                    background-color: #28a745;
                    color: white;
                    border: none;
                    padding: 8px 16px;
                    border-radius: 4px;
                    font-weight: bold;
                }
                QPushButton:pressed {
                    background-color: #1e7e34;
                }
            """)
            self.trajectory_status_label.setText("è½¨è¿¹é¢„æµ‹å·²å¼€å¯")
            self.trajectory_status_label.setStyleSheet("color: #28a745; font-weight: bold; padding: 5px;")
        else:
            self.trajectory_toggle_btn.setText("è½¨è¿¹é¢„æµ‹: å…³é—­")
            self.trajectory_toggle_btn.setStyleSheet("""
                QPushButton {
                    background-color: #6c757d;
                    color: white;
                    border: none;
                    padding: 8px 16px;
                    border-radius: 4px;
                    font-weight: bold;
                }
                QPushButton:pressed {
                    background-color: #545b62;
                }
            """)
            self.trajectory_status_label.setText("è½¨è¿¹é¢„æµ‹å·²å…³é—­")
            self.trajectory_status_label.setStyleSheet("color: #6c757d; font-weight: bold; padding: 5px;")
    
    def update_trajectory_ui(self, prediction_result):
        """æ›´æ–°è½¨è¿¹é¢„æµ‹UIæ˜¾ç¤º"""
        if not prediction_result:
            return
        
        # æ›´æ–°ç›²é“çŠ¶æ€
        blind_path_info = prediction_result.get('blind_path_info')
        if blind_path_info and blind_path_info.get('detected'):
            self.blind_path_status_label.setText("ç›²é“: å·²æ£€æµ‹")
            self.blind_path_status_label.setStyleSheet("color: #28a745; font-weight: bold; padding: 5px;")
        else:
            self.blind_path_status_label.setText("ç›²é“: æœªæ£€æµ‹")
            self.blind_path_status_label.setStyleSheet("color: #6c757d; font-weight: bold; padding: 5px;")
        
        # æ›´æ–°ç¢°æ’é£é™©
        collision_risks = prediction_result.get('collision_risks', {})
        if collision_risks:
            max_risk = max(collision_risks.values()) if collision_risks.values() else 0
            if max_risk > 0.7:
                risk_text = "ç¢°æ’é£é™©: é«˜"
                risk_color = "#dc3545"
            elif max_risk > 0.4:
                risk_text = "ç¢°æ’é£é™©: ä¸­"
                risk_color = "#ffc107"
            else:
                risk_text = "ç¢°æ’é£é™©: ä½"
                risk_color = "#28a745"
            
            self.collision_risk_label.setText(risk_text)
            self.collision_risk_label.setStyleSheet(f"color: {risk_color}; font-weight: bold; padding: 5px;")
        else:
            self.collision_risk_label.setText("ç¢°æ’é£é™©: ä½")
            self.collision_risk_label.setStyleSheet("color: #28a745; font-weight: bold; padding: 5px;")
    
    def handle_voice_command(self, command):
        """å¤„ç†è¯­éŸ³æŒ‡ä»¤"""
        try:
            command = command.lower()
            print(f"ğŸ¤ æ”¶åˆ°è¯­éŸ³æŒ‡ä»¤: {command}")
            
            if "åœæ­¢" in command or "æš‚åœ" in command:
                self.is_running = False
                self.timer.stop()
                self.status_label.setText("æ£€æµ‹å·²åœæ­¢")
                self.speak("æ£€æµ‹å·²åœæ­¢")
                
            elif "å¼€å§‹" in command or "å¯åŠ¨" in command:
                self.is_running = True
                self.timer.start(30)
                self.status_label.setText("æ£€æµ‹å·²å¯åŠ¨")
                self.speak("æ£€æµ‹å·²å¯åŠ¨")
                
            elif "è·ç¦»" in command:
                self.speak("å½“å‰æ£€æµ‹è·ç¦»ä¸º3åˆ°5ç±³")
                
            elif "å¸®åŠ©" in command or "è¯´æ˜" in command:
                self.speak("å¯ç”¨æŒ‡ä»¤ï¼šå¼€å§‹æ£€æµ‹ã€åœæ­¢æ£€æµ‹ã€è·ç¦»ä¿¡æ¯ã€å¸®åŠ©è¯´æ˜")
                
            else:
                self.speak(f"æ”¶åˆ°æŒ‡ä»¤ï¼š{command}")
                
        except Exception as e:
            print(f"âŒ å¤„ç†è¯­éŸ³æŒ‡ä»¤å¤±è´¥: {e}")

    def load_model(self):
        """åŠ è½½YOLOæ¨¡å‹"""
        if not YOLO_AVAILABLE:
            self.status_label.setText("YOLOåº“ä¸å¯ç”¨")
            return
            
        try:
            # ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹æ–‡ä»¶
            model_paths = [
                'models/yolov8n.pt',  # ä¼˜å…ˆä½¿ç”¨modelsç›®å½•ä¸‹çš„æ¨¡å‹
                'yolov8n.pt',         # å½“å‰ç›®å½•ä¸‹çš„æ¨¡å‹
                'models/yolo11n.pt'   # å¤‡ç”¨æ¨¡å‹
            ]
            
            model_path = None
            for path in model_paths:
                if os.path.exists(path):
                    model_path = path
                    break
            
            if model_path:
                print(f"ğŸ“¥ åŠ è½½æœ¬åœ°æ¨¡å‹: {model_path}")
                self.model = YOLO(model_path)
                self.status_label.setText("æ¨¡å‹åŠ è½½æˆåŠŸ")
            else:
                print("âš ï¸ æœ¬åœ°æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä¸‹è½½...")
                self.status_label.setText("æ­£åœ¨ä¸‹è½½æ¨¡å‹...")
                self.model = YOLO('yolov8n.pt')  # è¿™ä¼šè‡ªåŠ¨ä¸‹è½½
                self.status_label.setText("æ¨¡å‹ä¸‹è½½å¹¶åŠ è½½æˆåŠŸ")
                
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.status_label.setText(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.model = None

    def estimate_distance(self, box, known_height=1.5, focal_length=700):
        """è·ç¦»ä¼°ç®—"""
        try:
            pixel_height = abs(box[3] - box[1])
            if pixel_height == 0:
                return 99
            distance = (known_height * focal_length) / pixel_height
            return max(0.1, min(99, distance))  # é™åˆ¶è·ç¦»èŒƒå›´
        except:
            return 99

    def update_frame(self):
        """æ›´æ–°æ‘„åƒå¤´å¸§ - å¢å¼ºç‰ˆï¼ˆé›†æˆè½¨è¿¹é¢„æµ‹ï¼‰"""
        if not self.is_running or not self.cap or not self.cap.isOpened():
            return
            
        try:
            ret, frame = self.cap.read()
            if not ret:
                self.status_label.setText("æ— æ³•è·å–æ‘„åƒå¤´å¸§")
                return
                
            if self.model:
                # Step 1: YOLOv8æ£€æµ‹
                results = self.model(frame)
                detections = []
                
                for result in results:
                    if result.boxes is not None:
                        boxes = result.boxes.xyxy.cpu().numpy()
                        confs = result.boxes.conf.cpu().numpy()
                        clss = result.boxes.cls.cpu().numpy()
                        
                        for box, conf, cls in zip(boxes, confs, clss):
                            if conf > 0.5:  # ç½®ä¿¡åº¦é˜ˆå€¼
                                x1, y1, x2, y2 = box
                                detections.append([x1, y1, x2, y2, conf, int(cls)])
                
                # Step 2: è½¨è¿¹é¢„æµ‹å¤„ç†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                prediction_result = None
                if (self.trajectory_predictor and 
                    self.trajectory_toggle_btn.isChecked() and 
                    TRAJECTORY_PREDICTOR_AVAILABLE):
                    try:
                        prediction_result = self.trajectory_predictor.process_frame(frame, detections)
                        # æ›´æ–°è½¨è¿¹é¢„æµ‹UI
                        self.update_trajectory_ui(prediction_result)
                    except Exception as e:
                        print(f"è½¨è¿¹é¢„æµ‹å¤„ç†å¤±è´¥: {e}")
                
                # Step 3: ç»˜åˆ¶æ£€æµ‹ç»“æœå’Œè½¨è¿¹
                frame = self.draw_detections_and_trajectories(frame, detections, prediction_result)
                
                # Step 4: ä¼ ç»Ÿæ£€æµ‹é¢„è­¦ï¼ˆä¿æŒåŸæœ‰åŠŸèƒ½ï¼‰
                alert_info = None
                for detection in detections:
                    try:
                        x1, y1, x2, y2, conf, cls = detection
                        b = [int(x1), int(y1), int(x2), int(y2)]
                        
                        # è·å–ç±»åˆ«ä¿¡æ¯
                        if cls in CLASS_INFO:
                            label_name = CLASS_INFO[cls]
                            # ä¸ºä¸åŒç±»åˆ«è®¾ç½®ä¸åŒé¢œè‰²
                            if cls == 0:  # person
                                color = (0, 255, 0)  # ç»¿è‰²
                            elif cls == 39:  # bottle
                                color = (255, 0, 0)  # çº¢è‰²
                            elif cls == 38:  # tennis racket
                                color = (0, 0, 255)  # è“è‰²
                            elif cls == 41:  # cup
                                color = (255, 255, 0)  # é’è‰²
                            elif cls == 71:  # sink
                                color = (255, 0, 255)  # ç´«è‰²
                            elif cls == 78:  # toothbrush
                                color = (0, 255, 255)  # é»„è‰²
                            else:
                                color = DEFAULT_COLOR
                        else:
                            label_name = f"class{cls}"
                            color = DEFAULT_COLOR
                        
                        # è·ç¦»ä¼°ç®—
                        distance = self.estimate_distance(b)
                        
                        # è®¡ç®—æ–¹ä½
                        frame_width = frame.shape[1]
                        center_x = (b[0] + b[2]) / 2
                        position_ratio = center_x / frame_width
                        
                        if position_ratio < 0.33:
                            direction = "å·¦ä¾§"
                        elif position_ratio > 0.67:
                            direction = "å³ä¾§"
                        else:
                            direction = "æ­£å‰æ–¹"
                        
                        # åªå¯¹æœ€è¿‘çš„éšœç¢ç‰©é¢„è­¦
                        if alert_info is None or distance < alert_info["distance"]:
                            alert_info = {
                                "cls": cls, 
                                "distance": distance, 
                                "label_name": label_name,
                                "direction": direction
                            }
                    except Exception as e:
                        print(f"å¤„ç†æ£€æµ‹æ¡†æ—¶å‡ºé”™: {e}")
                        continue
                
                # é¢„è­¦åˆ†çº§
                if alert_info:
                    self.on_detected(alert_info["cls"], alert_info["distance"], alert_info["label_name"], alert_info["direction"])
                else:
                    self.status_label.setText("")
            
            # æ˜¾ç¤ºå›¾åƒ
            try:
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                h, w, ch = rgb_frame.shape
                bytes_per_line = ch * w
                qt_img = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)
                pixmap = QPixmap.fromImage(qt_img).scaled(
                    self.image_label.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation)
                self.image_label.setPixmap(pixmap)
            except Exception as e:
                print(f"æ˜¾ç¤ºå›¾åƒæ—¶å‡ºé”™: {e}")
                
        except Exception as e:
            print(f"æ›´æ–°å¸§æ—¶å‡ºé”™: {e}")
    

    
    def draw_detections_and_trajectories(self, frame, detections, prediction_result):
        """ç»˜åˆ¶æ£€æµ‹ç»“æœå’Œè½¨è¿¹"""
        try:
            # ç»˜åˆ¶æ£€æµ‹æ¡†
            for detection in detections:
                x1, y1, x2, y2, conf, cls = detection
                b = [int(x1), int(y1), int(x2), int(y2)]
                
                # è·å–ç±»åˆ«ä¿¡æ¯
                if cls in CLASS_INFO:
                    label_name = CLASS_INFO[cls]
                    # ä¸ºä¸åŒç±»åˆ«è®¾ç½®ä¸åŒé¢œè‰²
                    if cls == 0:  # person
                        color = (0, 255, 0)  # ç»¿è‰²
                    elif cls == 39:  # bottle
                        color = (255, 0, 0)  # çº¢è‰²
                    elif cls == 38:  # tennis racket
                        color = (0, 0, 255)  # è“è‰²
                    elif cls == 41:  # cup
                        color = (255, 255, 0)  # é’è‰²
                    elif cls == 71:  # sink
                        color = (255, 0, 255)  # ç´«è‰²
                    elif cls == 78:  # toothbrush
                        color = (0, 255, 255)  # é»„è‰²
                    else:
                        color = DEFAULT_COLOR
                else:
                    label_name = f"class{cls}"
                    color = DEFAULT_COLOR
                
                # ç»˜åˆ¶æ£€æµ‹æ¡†
                cv2.rectangle(frame, (b[0], b[1]), (b[2], b[3]), color, 2)
                label = f"{label_name} {conf:.2f}"
                cv2.putText(frame, label, (b[0], max(b[1]-10, 0)), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            
            # ç»˜åˆ¶è½¨è¿¹é¢„æµ‹ç»“æœ
            if prediction_result:
                # ç»˜åˆ¶ç›²é“è½®å»“
                blind_path_info = prediction_result.get('blind_path_info')
                if blind_path_info and blind_path_info.get('detected'):
                    contour = blind_path_info.get('contour')
                    if contour is not None:
                        cv2.drawContours(frame, [contour], -1, (0, 255, 0), 2)
                        # ç»˜åˆ¶ç›²é“ä¸­å¿ƒçº¿
                        center = blind_path_info.get('center')
                        if center:
                            cv2.circle(frame, center, 5, (0, 255, 0), -1)
                
                # ç»˜åˆ¶è·Ÿè¸ªå¯¹è±¡å’Œè½¨è¿¹
                tracked_objects = prediction_result.get('tracked_objects', [])
                for obj in tracked_objects:
                    obj_id = obj.get('id')
                    bbox = obj.get('bbox')
                    trajectory = obj.get('trajectory', [])
                    
                    if bbox:
                        x1, y1, x2, y2 = bbox
                        # ç»˜åˆ¶è·Ÿè¸ªæ¡†
                        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)
                        cv2.putText(frame, f"ID:{obj_id}", (int(x1), int(y1)-10), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
                    
                    # ç»˜åˆ¶å†å²è½¨è¿¹
                    if len(trajectory) > 1:
                        for i in range(1, len(trajectory)):
                            pt1 = trajectory[i-1]
                            pt2 = trajectory[i]
                            cv2.line(frame, pt1, pt2, (255, 255, 0), 2)
                
                # ç»˜åˆ¶é¢„æµ‹è½¨è¿¹
                predicted_trajectories = prediction_result.get('predicted_trajectories', {})
                for obj_id, trajectory in predicted_trajectories.items():
                    if len(trajectory) > 1:
                        for i in range(1, len(trajectory)):
                            pt1 = trajectory[i-1]
                            pt2 = trajectory[i]
                            cv2.line(frame, pt1, pt2, (0, 255, 255), 2, cv2.LINE_AA)
                
                # ç»˜åˆ¶ç¢°æ’é£é™©è­¦å‘Š
                collision_risks = prediction_result.get('collision_risks', {})
                for obj_id, risk in collision_risks.items():
                    if risk > 0.7:  # é«˜é£é™©
                        # æ‰¾åˆ°å¯¹åº”çš„è·Ÿè¸ªå¯¹è±¡
                        for obj in tracked_objects:
                            if obj.get('id') == obj_id:
                                bbox = obj.get('bbox')
                                if bbox:
                                    x1, y1, x2, y2 = bbox
                                    # ç»˜åˆ¶è­¦å‘Šæ¡†
                                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 3)
                                    cv2.putText(frame, "HIGH RISK", (int(x1), int(y1)-30), 
                                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                                break
            
        except Exception as e:
            print(f"ç»˜åˆ¶æ£€æµ‹ç»“æœå’Œè½¨è¿¹æ—¶å‡ºé”™: {e}")
        
        return frame

    def on_detected(self, cls, distance, label_name, direction):
        """æ£€æµ‹åˆ°éšœç¢ç‰©æ—¶çš„å¤„ç† - å¢å¼ºç‰ˆæ™ºèƒ½è¯­éŸ³åº“ç³»ç»Ÿ"""
        try:
                            # è·å–éšœç¢ç‰©çš„è¯¦ç»†ä¿¡æ¯
                obstacle_info = self.get_obstacle_info(cls, label_name)
                category = obstacle_info.get('category', 'unknown')
                obstacle_type = obstacle_info.get('type', label_name)
                risk_level = obstacle_info.get('risk_level', 1)
                
                print(f"ğŸ” æ£€æµ‹åˆ°éšœç¢ç‰©: {label_name} ({obstacle_type}), ç±»åˆ«: {category}, è·ç¦»: {distance:.1f}ç±³, æ–¹ä½: {direction}")
                print(f"ğŸ”§ è¯­éŸ³å¼€å…³çŠ¶æ€: {self.voice_toggle_btn.isChecked()}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ˜¾è‘—å˜åŒ–ï¼ˆè·ç¦»å˜åŒ–è¶…è¿‡0.5ç±³æˆ–æ–¹ä½å˜åŒ–ï¼‰
                distance_changed = (self.last_distance is None or 
                                  abs(distance - self.last_distance) > 0.5)
                direction_changed = (self.last_direction != direction)
                label_changed = (self.last_label != label_name)
                
                # æ›´æ–°è®°å½•
                self.last_distance = distance
                self.last_direction = direction
                self.last_label = label_name
                
                # åªæœ‰åœ¨æœ‰æ˜¾è‘—å˜åŒ–æ—¶æ‰æ’­æŠ¥è¯­éŸ³
                should_speak = distance_changed or direction_changed or label_changed
                
                # ä½¿ç”¨æ™ºèƒ½è¯­éŸ³æç¤ºç³»ç»Ÿ
                if should_speak:
                    msg = self.generate_smart_message(obstacle_type, distance, direction, category, risk_level)
                    self.status_label.setText(msg)
                    print(f"ğŸ“¢ æ™ºèƒ½è¯­éŸ³æç¤º: {msg}")
                    self.speak(msg)
                    
        except Exception as e:
            print(f"âŒ å¤„ç†æ£€æµ‹ç»“æœæ—¶å‡ºé”™: {e}")
    
    def get_obstacle_info(self, cls, label_name):
        """è·å–éšœç¢ç‰©çš„è¯¦ç»†ä¿¡æ¯"""
        try:
            # ä»COCOç±»åˆ«è·å–åŸºæœ¬ä¿¡æ¯
            if cls in CLASS_INFO:
                label_name = CLASS_INFO[cls]
                # æ ¹æ®ç±»åˆ«è®¾ç½®é£é™©ç­‰çº§å’Œåˆ†ç±»
                if cls == 0:  # person
                    category = "dynamic_pedestrian"
                    risk_level = 3
                elif cls in [39, 41, 71, 78]:  # bottle, cup, sink, toothbrush
                    category = "static_object"
                    risk_level = 2
                elif cls == 38:  # tennis racket
                    category = "sports_equipment"
                    risk_level = 2
                else:
                    category = "general_object"
                    risk_level = 1
            else:
                label_name = f"class{cls}"
                category = "unknown"
                risk_level = 1
            
            # ä»voice_config.jsonè·å–æ›´è¯¦ç»†çš„æ˜ å°„
            if hasattr(self, 'voice_library') and self.voice_library:
                class_mapping = self.voice_library.class_mapping
                mapping = class_mapping.get(str(cls), [])
                if len(mapping) >= 2:
                    category = mapping[0]
                    obstacle_type = mapping[1]
                else:
                    obstacle_type = label_name
            else:
                obstacle_type = label_name
            
            return {
                'category': category,
                'type': label_name,
                'name': label_name,
                'class_id': cls,
                'risk_level': risk_level
            }
        except Exception as e:
            print(f"âŒ è·å–éšœç¢ç‰©ä¿¡æ¯å¤±è´¥: {e}")
            return {
                'category': 'unknown',
                'type': label_name,
                'name': label_name,
                'class_id': cls,
                'risk_level': 1
            }
    
    def generate_smart_message(self, obstacle_type, distance, direction, category, risk_level):
        """ç”Ÿæˆæ™ºèƒ½è¯­éŸ³æ¶ˆæ¯"""
        try:
            # æ ¹æ®é£é™©ç­‰çº§å’Œè·ç¦»ç”Ÿæˆä¸åŒçš„æ¶ˆæ¯
            if risk_level >= 4:  # é«˜é£é™©
                if distance < 1.0:
                    return f"ç´§æ€¥ï¼{direction}{distance:.1f}ç±³æœ‰{obstacle_type}ï¼Œç«‹å³åœæ­¢ï¼"
                elif distance < 2.0:
                    return f"å±é™©ï¼{direction}{distance:.1f}ç±³æœ‰{obstacle_type}ï¼Œç«‹å³å‡é€Ÿï¼"
                else:
                    return f"æ³¨æ„ï¼{direction}{distance:.1f}ç±³æœ‰{obstacle_type}ï¼Œè¯·å°å¿ƒ"
            
            elif risk_level == 3:  # ä¸­é«˜é£é™©
                if distance < 1.5:
                    return f"å°å¿ƒï¼{direction}{distance:.1f}ç±³æœ‰{obstacle_type}ï¼Œè¯·å‡é€Ÿ"
                elif distance < 3.0:
                    return f"{direction}{distance:.1f}ç±³æœ‰{obstacle_type}ï¼Œè¯·æ³¨æ„"
                else:
                    return f"å‰æ–¹{distance:.1f}ç±³{direction}æœ‰{obstacle_type}"
            
            elif risk_level == 2:  # ä¸­ç­‰é£é™©
                if distance < 2.0:
                    return f"{direction}{distance:.1f}ç±³æœ‰{obstacle_type}ï¼Œè¯·æ³¨æ„"
                else:
                    return f"å‰æ–¹{distance:.1f}ç±³{direction}æœ‰{obstacle_type}"
            
            else:  # ä½é£é™©
                if distance < 1.0:
                    return f"{direction}{distance:.1f}ç±³æœ‰{obstacle_type}"
                else:
                    return f"å‰æ–¹{distance:.1f}ç±³{direction}æœ‰{obstacle_type}"
                    
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ™ºèƒ½æ¶ˆæ¯å¤±è´¥: {e}")
            return f"{direction}{distance:.1f}ç±³æœ‰{obstacle_type}"
    


    def closeEvent(self, event):
        """å…³é—­äº‹ä»¶å¤„ç†"""
        try:
            self.is_running = False
            
            # åœæ­¢å®šæ—¶å™¨
            if self.timer:
                self.timer.stop()
            
            # é‡Šæ”¾æ‘„åƒå¤´
            if self.cap and self.cap.isOpened():
                self.cap.release()
            
            # æ¸…ç†è¯­éŸ³ç³»ç»Ÿ
            if self.voice_system:
                self.voice_system.disable()
                print("âœ… è¯­éŸ³ç³»ç»Ÿå·²åœæ­¢")
                
            print("æ‘„åƒå¤´æ£€æµ‹çª—å£å·²å…³é—­ï¼Œèµ„æºå·²æ¸…ç†")
        except Exception as e:
            print(f"å…³é—­çª—å£æ—¶å‡ºé”™: {e}")
        finally:
            event.accept()

def main():
    app = QApplication(sys.argv)
    
    # è®¾ç½®åº”ç”¨æ ·å¼
    app.setStyle('Fusion')
    
    # åˆ›å»ºä¸»çª—å£
    window = TwoPointAnnotator()
    window.show()
    
    print("ä¸¤ç‚¹æ¨¡å¼å’Œæ‹–æ‹½æ¨¡å¼æ ‡æ³¨å·¥å…·å·²å¯åŠ¨ï¼")
    print("æ–°åŠŸèƒ½ï¼š")
    print("1. ä¸¤ç‚¹æ¨¡å¼ï¼šç‚¹å‡»ä¸¤ä¸ªç‚¹ï¼Œè‡ªåŠ¨ç”Ÿæˆç›´çº¿")
    print("2. æ‹–æ‹½æ¨¡å¼ï¼šç‚¹å‡»èµ·ç‚¹ï¼Œæ‹–æ‹½åˆ°ç»ˆç‚¹ï¼Œå½¢æˆç›´çº¿")
    print("3. æ”¯æŒæ¸…é™¤ä¸´æ—¶ç‚¹é‡æ–°å¼€å§‹")
    print("4. æ”¯æŒä½ çš„åŸå§‹å›¾ç‰‡")
    print("5. ä¿®å¤äº†åæ ‡æ¼‚ç§»é—®é¢˜")
    
    sys.exit(app.exec_())

if __name__ == "__main__":
    main() 